[
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Nguyễn Hồng Hiếu Tài\nSố điện thoại: 0707333797\nEmail: tainhhse182011@fpt.edu.vn\nTrường: Đại học FPT\nNgành: Công nghệ thông tin\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/08/2025 đến ngày 12/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": "Tối ưu hóa quy trình làm việc HPC với các cụm tự động mở rộng trong Ansys Gateway vận hành bởi AWS Bởi Dnyanesh Digraskar và Trent Andrus | Vào 22 tháng 4 năm 2025 | trong AWS ParallelCluster, High Performance Computing, Partner solutions.\nĐược đóng góp bởi Dnyanesh Digraskar, Kiến trúc sư Giải pháp Đối tác HPC tại AWS, và Trent Andrus, Chuyên gia Sản phẩm tại Ansys.\nAnsys Gateway vận hành bởi AWS là một giải pháp kỹ thuật đám mây (gọi tắt là “Ansys Gateway” trong phần còn lại của bài viết) được lưu trữ trên AWS Marketplace. Sản phẩm này cung cấp cho khách hàng giao diện liền mạch để chạy mô phỏng Ansys trong tài khoản Amazon Web Services (AWS) của mình. Khách hàng có thể triển khai nhanh các ứng dụng Ansys đã được xác thực, tinh chỉnh trên hạ tầng HPC mà AWS khuyến nghị. Groupama FDJ và Turntide Technologies sử dụng Ansys Gateway để tăng tốc các công việc thiết kế kỹ thuật và mô phỏng. So với hạ tầng on-premise, Groupama FDJ đạt tốc độ mô phỏng nhanh hơn 17 lần khi thiết kế xe đạp đua, còn Turntide Technologies tăng tốc mô phỏng thiết kế động cơ điện lên 7 lần.\nSau phiên bản phát hành đầu tiên của Ansys Gateway, một số phản hồi từ người dùng liên quan đến việc cần kiểm soát nhiều hơn trong quy trình tạo cụm HPC. Để giải quyết vấn đề này, Ansys Gateway nay đã tích hợp tính năng cụm tự động mở rộng từ phiên bản 2024 R2 trở đi. Điều này cho phép cấp phát tài nguyên tính toán động dựa trên hàng đợi công việc Slurm. Bên cạnh quy trình tạo cụm được nâng cấp, Ansys Gateway nay hỗ trợ các dịch vụ AWS như Amazon FSx for Lustre, Amazon FSx for OpenZFS và Amazon Elastic File System (EFS). Các dịch vụ này thường được sử dụng để hỗ trợ nhiều loại quy trình làm việc HPC khác nhau. Với khả năng tự mở rộng, EFS là lựa chọn khởi đầu tuyệt vời cho đa số khách hàng. Đối với các mô phỏng lớn có nhiều thao tác I/O, các hệ thống tệp chia sẻ hiệu năng cao như FSx for Lustre và OpenZFS giúp tránh nghẽn cổ chai I/O. Trong môi trường tính toán hỗn hợp Windows và Linux, OpenZFS có thể truy cập được từ cả hai nền tảng.\nMở rộng tài nguyên HPC cho các mô phỏng kỹ thuật là một thách thức phức tạp. Tính mở rộng phản ánh khả năng hạ tầng HPC cung cấp tài nguyên tính toán tỷ lệ thuận với nhu cầu khối lượng công việc. Thông thường, các mô phỏng gắn kết chặt chẽ như phần mềm mô phỏng chất lỏng Ansys Fluent, phần mềm mô phỏng động lực học phi tuyến Ansys LS-DYNA, hay phần mềm phân tích phần tử hữu hạn cấu trúc Ansys Mechanical đều có thể mở rộng trên nhiều lõi và đạt hiệu năng tuyến tính gần như tuyệt đối (tùy thuộc vào benchmark). Với các cụm tự động mở rộng, người dùng có thể quản lý tài nguyên hiệu quả dựa trên nhu cầu khối lượng công việc và loại bỏ các “nút thắt cổ chai” phần cứng trong lúc cao điểm.\nBài blog này mô tả kiến trúc, quy trình làm việc và các khuyến nghị về Amazon EC2 khi chạy các ứng dụng Ansys trong Ansys Gateway.\nCác thành phần kiến trúc Các thành phần kiến trúc của Ansys Gateway, bao gồm Mặt kiểm soát (Control Plane) và Mặt ứng dụng (Application Plane), đã được mô tả chi tiết trong bài blog năm 2023.\nTừ phiên bản này trở đi, Ansys Gateway tích hợp với AWS ParallelCluster, một công cụ quản lý cụm mã nguồn mở. Slurm được sử dụng như bộ điều phối công việc để tự động cấp phát các nút tính toán khi các công việc được xếp hàng đợi và giải phóng khi không còn cần thiết nữa. Hình 1 dưới đây minh họa sơ đồ kiến trúc triển khai AWS ParallelCluster trong VPC của khách hàng Ansys Gateway. Sơ đồ kiến trúc triển khai AWS ParallelCluster trong Amazon Virtual Private Cloud (VPC) của khách hàng Ansys Gateway được minh họa ở Hình 1.\nHình 1: Kiến trúc triển khai HPC của Ansys Gateway dựa trên AWS ParallelCluster. Đây là lớp ứng dụng được triển khai trong tài khoản AWS của khách hàng.\nThành phần chính của cụm HPC bao gồm: Nút quản lý (Head Node) – Quản lý quy trình công việc và trạng thái cụm. Bộ điều khiển Slurm – Bộ điều phối sử dụng Slurm workload manager. Các nút tính toán động – Được cung cấp và chấm dứt dựa trên nhu cầu khối lượng công việc. Ví dụ: khởi chạy các loại phiên bản Amazon EC2 như C6i, Hpc6a, Hpc7a cho khối lượng công việc dựa trên CPU và P5, G6e để tăng tốc GPU. Lưu trữ – Amazon EFS hoặc Amazon Elastic Block Store (EBS) để cài đặt ứng dụng và dữ liệu công việc liên tục có thể hoạt động như bộ gắn Hệ thống tệp mạng (NFS) hoặc Amazon FSx cho Lustre và Amazon FSx cho OpenZFS cho khối lượng công việc hiệu suất cao. Hàng đợi cụm – Hàng đợi công việc hỗ trợ nhiều loại phiên bản cho nhiều loại khối lượng công việc khác nhau, chẳng hạn như: hàng đợi phiên bản được tối ưu hóa điện toán để chạy mô phỏng CFD và sự cố; hàng đợi phiên bản được tối ưu hóa bộ nhớ để chạy mô phỏng FEA hoặc NVH; Hàng đợi phiên bản được tối ưu hóa GPU để chạy mô phỏng hướng đồ họa. Bạn nên chạy ứng dụng trên các loại phiên bản đồng nhất với tất cả các nút điện toán có thiết kế giống nhau để đạt được hiệu suất tối ưu. Mạng nâng cao – Amazon Elastic Fabric Adapter (EFA) là giao diện mạng nâng cao dành cho các phiên bản Amazon EC2 để chạy các ứng dụng yêu cầu liên lạc giữa các nút ở mức độ cao trên quy mô lớn. AWS ParallelCluster mang lại sự linh hoạt lớn cho Ansys Gateway trong định nghĩa tài nguyên tính toán và hàng đợi. Một hàng đợi có thể chứa nhiều tài nguyên tính toán, và mỗi tài nguyên lại có thể có nhiều loại instance EC2. Ví dụ: một hàng đợi có tài nguyên tính toán với các loại instance như r6i.32xlarge, r6in.32xlarge, r6id.32xlarge. Thông thường, cụm sẽ cố gắng cấp phát loại instance rẻ nhất trước, nếu không đủ thì chuyển sang loại kế tiếp. Đây là cách giúp giải quyết tạm thời vấn đề thiếu hụt tài nguyên.\nNhờ các cụm mở rộng động, người dùng Ansys Gateway giờ đây có thể có quy trình mô phỏng dựa trên job (theo hàng đợi) thay vì mỗi cluster cho một mô phỏng như truyền thống. Với cluster tĩnh, tài nguyên có thể lãng phí vào thời gian thấp điểm, dẫn đến chi phí không cần thiết. Cluster tĩnh cũng có thể không phù hợp với mọi loại công việc, khiến bạn phải resize hoặc tạo cluster mới với các loại instance khác nhau, gây downtime và chi phí ngoài dự kiến.\nQuy trình gửi công việc mô phỏng Phần này sẽ mô tả quy trình từng bước thực hiện trên giao diện Ansys Gateway để tạo các cụm HPC mở rộng động nhằm chạy các mô phỏng Ansys. Giả định rằng bạn đã đăng nhập vào Ansys Gateway và có quyền truy cập vào không gian làm việc để gửi các công việc mô phỏng.\nBước 1: Tạo cụm HPC Việc tạo cụm mở rộng động thực hiện theo các bước sau:\nChọn loại lưu trữ (giữa Amazon EFS, Amazon FSx for OpenZFS và Amazon FSx for Lustre) Chọn các gói ứng dụng Ansys cần cài đặt Định nghĩa các hàng đợi tính toán của cụm và chọn tài nguyên Cũng như khi tạo bất kỳ tài nguyên nào, bạn bắt đầu bằng cách chọn một tenant (tức là workspace đã đăng ký) trong Ansys Gateway như minh họa ở Hình 2a. Sau đó, hãy tạo mới hoặc chọn một project space chưa có cụm mở rộng động. Project space này phải có chỉ báo ở cột Releases là “24R2+” như minh họa ở Hình 2b.\nHình 2a: Trang chủ của Ansys Gateway. Người dùng có thể chọn một tenant để truy cập vào các project space của họ. Có hai tùy chọn tenant được hiển thị, mỗi tenant đều có tên và ID riêng.\nHình 2b: Trang chủ các project space của Ansys Gateway. Một project space có tiêu đề “Gateway Autoscaling Cluster Demonstration” được hiển thị.\nTrong project space này, hãy tạo một tài nguyên mới và chọn “Autoscaling Cluster” từ danh sách thả xuống như minh họa ở Hình 3.\nHình 3: Một project space trống với danh sách thả xuống đang mở, gợi ý người dùng tạo một máy tính để bàn ảo mới hoặc các cụm (clusters).\nSau khi chọn “Autoscaling Cluster” từ danh sách thả xuống, trình hướng dẫn tạo mới sẽ cho phép bạn thiết lập một số tính năng chính của cụm. Đầu tiên là loại lưu trữ, tiếp theo là các ứng dụng cần cài đặt, và cuối cùng là các hàng đợi tài nguyên tính toán. Theo mặc định, một ổ đĩa Amazon Elastic File System (EFS) sẽ được gắn vào cụm HPC và sẵn sàng cho các tài nguyên trong project space. Trong Hình 4, một vị trí lưu trữ thứ hai tùy chọn được định nghĩa cho đường dẫn cài đặt sản phẩm.\nHình 4: Các tùy chọn lưu trữ của trình hướng dẫn tạo cụm. Theo mặc định, một hệ thống tệp EFS sẽ được tạo và gắn vào cụm. Ngoài ra, một vùng lưu trữ thứ hai là Amazon FSx for OpenZFS cũng được thiết lập, với dung lượng 256 GiB và băng thông 2048 MiB/s/TiB. Tên lưu trữ và đường dẫn mount cũng được người dùng cung cấp.\nKhi đã xác định xong các tùy chọn lưu trữ, bạn có thể chọn các gói ứng dụng muốn cài đặt. Trong Hình 5, Ansys Structures được chọn.\nHình 5: Bước chọn các ứng dụng mô phỏng để cài đặt trong trình hướng dẫn tạo cụm.\nTrong quá trình tạo cụm, trình hướng dẫn có thể tự động triển khai một máy chủ chạy Ansys HPC Platform Services (HPS), như minh họa ở Hình 6. Khi sử dụng HPS, người dùng có thể đơn giản hóa đáng kể việc gửi công việc mô phỏng nhờ khả năng upload, submit, theo dõi và tải kết quả trực tiếp từ máy trạm mà không cần tự chuyển file lên đám mây hoặc viết script gửi công việc. Lưu ý rằng HPS được cung cấp dưới dạng container và sử dụng Docker để triển khai. Để biết thêm thông tin về thiết lập và sử dụng HPS, tham khảo tài liệu Ansys HPC Platform Services.\nVị trí cài đặt HPS cần trùng với nơi cài sản phẩm Ansys (ví dụ: đều cài trên ổ FSx for OpenZFS).\nHình 6: Bước thiết lập Ansys HPC Platform Services (HPS) trong trình hướng dẫn tạo cụm. Theo mặc định, một máy ảo nền tảng Linux sẽ được tạo cho người dùng và các dịch vụ HPS sẽ tự động được triển khai.\nTiếp theo, trình hướng dẫn giúp người dùng tạo hàng đợi gửi công việc. Người dùng có thể chỉ định cả số lượng nút tĩnh và động theo giới hạn hạn ngạch dịch vụ AWS của họ. Có thể xác định tối đa mười hàng đợi cho một cụm.\nHình 7: Sau khi nhấn nút “Add queue”, người dùng sẽ chọn ứng dụng cho hàng đợi này, đặt tên hàng đợi, chọn số lượng nút tĩnh (luôn sẵn sàng), số lượng nút động tối đa, các tùy chọn nâng cao (như EFA, placement group, v.v.), và cuối cùng là loại hoặc các loại instance muốn dùng. Quy trình này được lặp lại cho từng hàng đợi.\nỨng dụng liên kết với một hàng đợi được chọn từ danh sách thả xuống. Thông thường, nên đặt tên hàng đợi sao cho thể hiện rõ ứng dụng và phiên bản mà hàng đợi đó dùng, ví dụ như “mech242”.\nSau khi đã định nghĩa các hàng đợi mong muốn, bạn có thể đặt tên và tạo cụm. Khi quá trình tạo cụm hoàn tất, bạn sẽ thấy một huy hiệu “Running” báo hiệu rằng mọi tài nguyên và dịch vụ đã được triển khai. Các tài nguyên tính toán sẽ vẫn ở trạng thái offline cho đến khi có công việc được gửi. Từ project space, nhấp vào cụm sẽ hiển thị trang tổng quan với thông tin về head node, HPS node, các hàng đợi và các nút tính toán đã cấp phát. Xem Hình 8a và 8b để biết chi tiết về thông tin sau khi cụm được tạo.\nHình 8a: Trang tổng quan sau khi tạo cụm, hiển thị thông tin chi tiết về head node và HPS node.\nHình 8b: Trang tổng quan cụm hiển thị: các hàng đợi đang có theo tên (một hàng đợi có tên mech242), số lượng nút đã cấp phát (0/10), ứng dụng liên kết (Ansys Structure 2024 R2); danh sách các ứng dụng cùng vị trí cài đặt (Ansys Structures trên Amazon FSx for Open ZFS); danh sách các vị trí lưu trữ được gắn (EFS mặc định, OpenZFS) kèm tên, loại và đường dẫn mount.\nBước 2: Gửi công việc đến cụm Khi cụm đã được tạo, bạn có thể tận dụng quy trình gửi công việc đơn giản hóa mà HPS cung cấp. Ví dụ với Ansys Mechanical ở Hình 9, việc kết nối tới máy chủ HPS chỉ đơn giản là nhập địa chỉ IP của server HPS theo định dạng https://example.com:port/hps. Tham khảo Hình 9 để biết địa chỉ của máy chủ HPS.\nHình 9: Cửa sổ thiết lập quy trình giải bài toán (Solve Process Settings) của Ansys Mechanical.\nĐối với những người dùng quen thuộc với dòng lệnh Linux, bạn vẫn có thể gửi công việc bằng các lệnh Slurm tiêu chuẩn như srun, sbatch và salloc. Tham khảo tài liệu Ansys Help để biết thêm thông tin về cách gửi công việc bằng Slurm.\nBước 3: Theo dõi việc tự động mở rộng nút Sau khi submit job, người dùng truy cập giao diện giám sát công việc HPS trên trang cluster của Ansys Gateway để theo dõi trạng thái job (Pending, Running, Evaluated), xem file log và tải về file kết quả.\nHình 10: Giao diện giám sát công việc của HPS. Người dùng có thể truy cập giao diện này từ trình duyệt web để xem trạng thái công việc (Pending, Running, Evaluated), theo dõi các file log và tải về từng file riêng lẻ.\nSử dụng các lệnh Slurm để vận hành cụm (cluster operations)\nNhững người dùng quen thuộc với việc giám sát thông qua các lệnh Slurm vẫn có thể làm như vậy. Công việc được gửi qua HPS có thể nhìn thấy thông qua lệnh \u0026ldquo;squeue\u0026rdquo; trong Hình 11 (sau khi kết nối tới Linux VDI trong workspace). Nút được yêu cầu đang ở trạng thái configuring (CF), có nghĩa là nó đang được mở rộng quy mô.\nHình 11: Truy vấn Slurm bằng lệnh “squeue” trên dòng lệnh Linux. Lệnh này trả về danh sách các công việc kèm các thông tin như trạng thái công việc và tài nguyên được cấp phát.\nTương tự, có thể xem số lượng nút đã cấp phát bằng lệnh “sinfo -s” như trong Hình 12. A/I/O/T thể hiện số lượng nút Đang sẵn sàng/Đang chờ rỗi/Đang offline/Tổng số nút.\nHình 12: Truy vấn Slurm bằng lệnh “sinfo” để xem danh sách các hàng đợi đang có. Kết quả trả về gồm một hàng đợi kèm thông tin về tên và số lượng nút đang sử dụng.\nNgười dùng cũng có thể gửi công việc bằng các lệnh Slurm như “srun,” “sbatch,” và “salloc” như minh họa ở Hình 13. Script gửi công việc đã được tích hợp sẵn trong gói cài đặt ứng dụng trên Ansys Gateway.\nHình 13: Gửi công việc trực tiếp tới Slurm bằng lệnh “salloc” và theo dõi trạng thái bằng lệnh “squeue”.\nBước 4: Lấy kết quả và shutdown cụm Nếu gửi job bằng HPS, có thể tải file kết quả trực tiếp về máy cá nhân từ ổ lưu trữ chung của cụm. Nếu gửi bằng lệnh Slurm sử dụng ổ tạm trên instance, cần copy file kết quả về ổ lưu trữ khi job hoàn thành. Mặc định, các nút động sẽ online thêm 10 phút sau khi chạy xong, sau đó tự động dừng nếu không có việc mới.\nKhuyến nghị loại Amazon EC2 cho các ứng dụng Ansys Ansys Gateway hỗ trợ quy trình tạo cluster nâng cao cho các ứng dụng:\nAnsys Electronics Desktop Ansys Fluids Ansys LS-DYNA Ansys Lumerical Ansys Pathfinder-SC Ansys Speos Ansys Structures Ansys Totem-SC Các quy trình thiết lập chi tiết cho từng ứng dụng đều có trong tài liệu Ansys help Recommended Configurations by Application, thuộc phần Recommended Usage Guide. Sau khi đã tìm hiểu quy trình nâng cao để tạo cụm HPC trên Ansys Gateway, bạn hãy tham khảo Bảng 1 để biết các khuyến nghị chung về các loại instance Amazon EC2 thường dùng khi chạy các ứng dụng Ansys trên Ansys Gateway. Xem thêm danh sách chi tiết các loại instance được đề xuất tại Ansys Help page. Amazon EC2 Instances Specifications HPC6id HPC7a / HPC6a C6i* P5+ P4d+ G6e G5 Processor Intel Ice Lake AMD EPYC Intel Ice Lake NVIDIA H100 NVIDIA A100 L40S NVIDIA A10G Instance Size^ 32xlarge 96xlarge / 48xlarge 32xlarge 48xlarge 24xlarge 48xlarge 48xlarge Physical Cores 64 192 / 96 64 96 48 96 96 RAM per node (GiB) 1024 768 / 384 256 2048 1152 1536 768 Memory per core (GiB) 16 4 – 32 (HPC7a) / 4 (HPC6a) 4 24 24 16 8 EFA Bandwidth (GB/s) 200 300 / 100 50 3200 400 400 100 Number of GPUs 8 8 8 8 RAM per GPU (GB) 640 HBM3 40 HBM2 48 24 Target Ansys Apps^ Electronics Desktop, Fluids, LS-DYNA, Lumerical, Structures Fluids, LS-DYNA, Structures Electronics Desktop, Fluids, LS-DYNA, Lumerical, Pathfinder, Speos, Structures, Totem-SC Fluids Fluids Fluids, Structures, HFSS Fluids, Discovery Physics Description Implicit, Explicit, CFD codes Explicit, CFD codes Implicit, Explicit, CFD, Optics codes CFD codes Implicit, Explicit, CFD codes Implicit, Explicit, CFD codes Interactive modeling and simulations *Bật Elastic Fabric Adapter (EFA) để tăng tốc độ giao tiếp giữa các nút. Tắt Simultaneous Multithreading (SMT) nhằm đảm bảo hiệu suất CPU ổn định. ^ Các ứng dụng HPC thường sẽ hoạt động hiệu quả hơn khi sử dụng toàn bộ instance ở kích thước tối đa, nhờ có các tính năng như EFA. Không thể chạy ngay trên Ansys Gateway mà đòi hỏi người dùng phải cấu hình thêm các gói NVIDIA bổ sung. Bảng 1: Khuyến nghị loại instance Amazon EC2 cho các ứng dụng Ansys khác nhau.\nKết luận Ansys Gateway vận hành trên AWS hiện nay đã tích hợp với AWS ParallelCluster, giúp người dùng triển khai các cụm HPC theo nhu cầu để chạy mô phỏng Ansys trên AWS. Điều này cho phép các kỹ sư thực hiện các mô phỏng quy mô lớn một cách hiệu quả, đồng thời tối ưu hóa chi phí điện toán đám mây. Nhờ tự động điều chỉnh tài nguyên theo khối lượng công việc mô phỏng, Ansys Gateway giúp giảm thiểu thời gian máy tính nhàn rỗi và đảm bảo khả năng mở rộng tối ưu cho các tác vụ HPC.\nĐể bắt đầu với Ansys Gateway, hãy truy cập Ansys Gateway trên AWS Marketplace để triển khai môi trường HPC trên đám mây chỉ với vài cú nhấp chuột. Trải nghiệm ngay hôm nay để cảm nhận lợi ích của mô phỏng kỹ thuật hiệu năng cao, linh hoạt trên AWS.\nVề tác giả﻿ Dnyanesh Digraskar Dnyanesh Digraskar là Kiến trúc sư Giải pháp Đối tác HPC Cấp cao tại AWS. Anh phụ trách chiến lược triển khai HPC với các đối tác phần mềm độc lập (ISV) của AWS, nhằm hỗ trợ họ xây dựng các giải pháp có khả năng mở rộng và tuân theo kiến trúc tốt. Anh có hơn mười lăm năm kinh nghiệm trong các lĩnh vực CFD, CAE, mô phỏng số và HPC. Dnyanesh có bằng Thạc sĩ Kỹ thuật Cơ khí từ Đại học Massachusetts, Amherst. Trent Andrus Trent là Chuyên gia Sản phẩm tại Ansys, tập trung vào các chủ đề liên quan đến HPC và điện toán đám mây. Với niềm đam mê cập nhật các tiến bộ về hiệu năng phần cứng và phần mềm, anh hướng đến việc chuyển hóa kiến thức của mình thành những giải pháp giúp HPC trở nên dễ tiếp cận hơn cho mọi người dùng. Ngoài công việc, Trent là một người đam mê đạp xe và thường xuyên tập luyện để cải thiện hiệu suất của chính mình. "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": "Hiện đại hóa hạ tầng Kubernetes của Snowflake Corporate với Bottlerocket và Karpenter Bởi Sameeksha Garg, Gaurav Singodia, Jagdish Pawar, RK Sai (Ravikiran Koduri), và Sayan Moitra | ngày 18 tháng 4 năm 2025 | Trong Amazon Elastic Kubernetes Service, Customer Solutions, Open Source\nSnowflake Corporate IT Cloud Operations đã đạt đến một bước ngoặt quan trọng trong tiến trình phát triển hạ tầng điện toán đám mây. Việc quản lý các tải công việc dạng container trên Amazon Elastic Kubernetes Service (Amazon EKS) đòi hỏi một hệ điều hành hiện đại, an toàn và hiệu quả. Hệ thống hiện tại, sử dụng trên Amazon Linux 2 (AL2), vẫn hoạt động tốt nhưng lại xuất hiện một số thách thức. Việc tăng cường bảo mật đòi hỏi phải cập nhật thường xuyên, gây áp lực vận hành. Đảm bảo có những bản cập nhật an toàn và nhất quán trên quy mô lớn các node là điều khó khăn. Thêm vào đó, thời gian khởi động cho các node AL2 khá lâu, dẫn đến hiệu quả mở rộng thấp. Sau khi đánh giá toàn diện, Bottlerocket, hệ điều hành tối ưu cho container của AWS, đã được lựa chọn là giải pháp lý tưởng để giải quyết các khó khăn này.\nChiến lược di chuyển Việc chuyển từ AL2 sang Bottlerocket không đơn thuần là một thay đổi kỹ thuật mà còn là một quyết định chiến lược để đảm bảo hệ thống Kubernetes của Snowflake Corporate trong tương lai. Xét đến quy mô và độ phức tạp của các tải công việc, chiến lược di chuyển được thiết kế đảm bảo không có thời gian chết (zero downtime), ít gián đoạn, và mở rộng tự động liền mạch. Để đạt được, Snowflake Corporate đã lựa chọn Karpenter – bộ tự động mở rộng cluster Kubernetes mã nguồn mở, cùng với NodePool và NodeClass để hỗ trợ việc cấp phát node động. Quá trình di chuyển được thực hiện theo từng giai đoạn nhằm giảm thiểu các rủi ro và đảm bảo tính ổn định.\nCác bước di chuyển Quá trình di chuyển bắt đầu bằng việc chuẩn bị cụm (cluster). Các AMI Bottlerocket đã được tích hợp vào môi trường EKS bằng cách sửa đổi cấu hình NodePool và NodeClass để sử dụng Bottlerocket làm họ AMI mặc định. Các chính sách AWS Identity and Access Management (IAM) được tối ưu hóa để phù hợp với mô hình bảo mật của Bottlerocket, tuân thủ nguyên tắc phân quyền tối thiểu.\nSơ đồ kiến trúc này minh họa chiến lược di chuyển:\nTriển khai Karpenter đã thay thế phương pháp cấp phát tài nguyên tĩnh truyền thống, cho phép khởi tạo node đúng thời điểm cần thiết. Việc xác thực các tải công việc được thực hiện bằng cách sử dụng môi trường staging để kiểm thử trên các node Bottlerocket trước khi đưa vào production. Việc giám sát hiệu năng được triển khai thông qua Fluentd và Datadog nhằm theo dõi các chỉ số thời gian thực, đồng thời các kiểm tra tuân thủ bảo mật giúp đảm bảo hạ tầng bất biến của Bottlerocket phù hợp với các chính sách bảo mật của Snowflake Corporate.\nViệc triển khai được thực hiện theo từng giai đoạn, bắt đầu với các ứng dụng không trạng thái. Node affinity, pod anti-affinity và category được sử dụng để đảm bảo phân phối tải công việc tối ưu. Việc giới thiệu từ từ các node Bottlerocket giúp workload chuyển dịch suôn sẻ cùng với các instance AL2 hiện hữu. Quá trình cordon và drain các node hỗ trợ loại bỏ dần các instance AL2 mà không gây gián đoạn dịch vụ.\nCuối cùng, các giải pháp giám sát và tối ưu hóa nâng cao đã được triển khai. Việc tự động mở rộng với Karpenter giúp điều chỉnh động nhóm node của cluster. Điều chỉnh hiệu suất được thực hiện dựa trên các tải công việc thực tế, đồng thời cải tiến khả năng quan sát cung cấp các thông tin chi tiết về sức khỏe của hệ thống, cho phép phát hiện và xử lý chủ động các sự cố.\nVí dụ định nghĩa NodeClass và liên kết với NodePool:\napiVersion: karpenter.k8s.aws/v1alpha5 kind: NodeClass metadata: name: bottlerocket-nodeclass spec: amiFamily: Bottlerocket instanceProfile: \u0026#34;KarpenterNodeInstanceProfile\u0026#34; securityGroupSelector: aws-ids: [\u0026#34;sg-0123456789\u0026#34;] Example of defining a NodePool: apiVersion: karpenter.k8s.aws/v1alpha5 kind: NodePool metadata: name: bottlerocket-nodepool spec: template: spec: nodeClassRef: name: bottlerocket-nodeclass limits: resources: cpu: 1000 ttlSecondsAfterEmpty: 30  Example of applying node affinity to schedule workloads on Bottlerocket nodes: apiVersion: apps/v1 kind: Deployment metadata: name: bottlerocket-app spec: replicas: 3 selector: matchLabels: app: bottlerocket-app template: metadata: labels: app: bottlerocket-app spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: karpenter.k8s.aws/node-pool operator: In values: - bottlerocket-nodepool containers: - name: app image: my-app-image:latest Example of using pod anti-affinity to spread workloads across different nodes: apiVersion: apps/v1 kind: Deployment metadata: name: workload-deployment spec: replicas: 3 selector: matchLabels: app: critical-app template: metadata: labels: app: critical-app spec: affinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: app operator: In values: - critical-app topologyKey: \u0026#34;kubernetes.io/hostname\u0026#34; containers: - name: workload image: workload-image:latest Ví dụ định nghĩa NodePool:\napiVersion: karpenter.k8s.aws/v1alpha5 kind: NodePool metadata: name: bottlerocket-nodepool spec: template: spec: nodeClassRef: name: bottlerocket-nodeclass limits: resources: cpu: 1000 ttlSecondsAfterEmpty: 30 Ví dụ áp dụng node affinity để schedule workload lên node Bottlerocket:\napiVersion: apps/v1 kind: Deployment metadata: name: bottlerocket-app spec: replicas: 3 selector: matchLabels: app: bottlerocket-app template: metadata: labels: app: bottlerocket-app spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: karpenter.k8s.aws/node-pool operator: In values: - bottlerocket-nodepool containers: - name: app image: my-app-image:latest Ví dụ sử dụng pod anti-affinity để phân tán workload:\napiVersion: apps/v1 kind: Deployment metadata: name: workload-deployment spec: replicas: 3 selector: matchLabels: app: critical-app template: metadata: labels: app: critical-app spec: affinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: app operator: In values: - critical-app topologyKey: \u0026#34;kubernetes.io/hostname\u0026#34; containers: - name: workload image: workload-image:latest Những thách thức \u0026amp; cách khắc phục Mặc dù Bottlerocket mang lại nhiều lợi ích, quá trình di chuyển vẫn xuất hiện những thách thức nhất định. Một số workload ban đầu gặp vấn đề tương thích do hệ thống file bất biến của Bottlerocket. Để khắc phục, các image ứng dụng đã được chỉnh sửa để tuân thủ hoàn toàn tiêu chuẩn container và áp dụng cấu hình read-only khi phù hợp. Bottlerocket cũng yêu cầu cấu hình lại vai trò IAM để phù hợp với mô hình bảo mật mới; điều này được giải quyết bằng việc triển khai kiểm soát quyền truy cập chi tiết và tích hợp IAM với Karpenter. Để giảm thiểu rủi ro, workloads được di chuyển theo từng phần, đảm bảo hiệu năng ứng dụng duy trì ổn định trước khi loại bỏ hoàn toàn các node AL2.\nLợi ích chính Quá trình di chuyển đã mang lại sự cải thiện vượt trội về bảo mật, hiệu năng và hiệu quả vận hành. Bảo mật được nâng cao nhờ các node bất biến, ngăn chặn thay đổi trái phép và loại bỏ hiện tượng trôi cấu hình. Mức độ lỗ hổng được giảm mạnh nhờ loại bỏ các trình quản lý gói, truy cập shell và SSH, hạn chế nguy cơ tấn công. Cập nhật tự động và nguyên tử đảm bảo các node luôn được vá bảo mật mà không phải dừng hệ thống.\nThời gian khởi động node nhanh hơn nhờ tối ưu hóa quá trình khởi tạo, giúp các node mới gia nhập cluster nhanh chóng và tăng hiệu quả tự động mở rộng, bảo đảm workload được sắp lại nhanh hơn. Hiệu quả vận hành nâng cao thông qua việc scaling động với Karpenter, cấp phát tài nguyên đúng khi cần, tránh cấp phát dư thừa. Về chi phí, Bottlerocket với hệ điều hành nhẹ cùng khả năng cấp phát thông minh của Karpenter đã giúp tiết kiệm đáng kể nguồn lực.\nHiệu suất: Bottlerocket so với AL2 Bottlerocket nhất quán mang lại tốc độ node readiness nhanh hơn. Các benchmark sơ bộ cho thấy Bottlerocket rút ngắn thời gian node readiness khoảng 5 giây so với AL2. Ngoài ra, cơ chế native container image caching của Bottlerocket giúp giảm khoảng 36 giây cho mỗi pod trên một node mới, đồng thời các pod chưa thể lên lịch sẽ khởi chạy nhanh hơn so với AL2 khoảng 40 giây.\nTăng cường bảo mật: AL2 vs Bottlerocket So sánh trực tiếp về các cải tiến bảo mật cho thấy lý do vì sao Bottlerocket là lựa chọn vượt trội:\nBài học rút ra\nQuá trình di chuyển đã mang lại nhiều bài học giá trị. Bảo mật và hiệu quả vận hành luôn song hành; thiết kế bất biến của Bottlerocket giúp tăng cường bảo mật cho Snowflake Corporate. Việc tự động hóa đơn giản hóa quy trình, khi Karpenter hỗ trợ mở rộng thời gian thực đã loại bỏ nhu cầu can thiệp thủ công. Việc di chuyển theo từng bước giúp giảm rủi ro, đồng thời triển khai qua từng giai đoạn cho phép tinh chỉnh cấu hình mà không ảnh hưởng đến môi trường production.\nKết luận: Ý nghĩa rộng hơn cho doanh nghiệp vận hành EKS quy mô lớn Việc di chuyển thành công hạ tầng Kubernetes của Snowflake Corporate sang Bottlerocket và Karpenter đã tạo ra một mô hình tiêu chuẩn mới mà toàn ngành có thể tham khảo. Những lợi ích nổi bật như tăng cường bảo mật, rút ngắn thời gian khởi tạo node và tối ưu vận hành có thể được áp dụng rộng rãi tại các doanh nghiệp quản trị Kubernetes quy mô lớn. Trong tương lai, có thể tiếp tục nâng cấp với điều phối workload dựa trên AI, tích hợp sâu hơn với các công cụ quan sát hệ thống và khám phá Kubernetes serverless sử dụng Bottlerocket. Việc áp dụng Bottlerocket và Karpenter giúp Snowflake Corporate không chỉ nâng cao bảo mật mà còn tăng hiệu năng nhờ khả năng mở rộng động, nhấn mạnh sức mạnh của các giải pháp cloud-native hiện đại trong việc xây dựng môi trường Kubernetes hiệu suất cao, ổn định và bền vững.\nVề tác giả Sameeksha Garg Sameeksha Garg là Quản lý Tài khoản Kỹ thuật (Technical Account Manager) tại AWS, cam kết hỗ trợ và thúc đẩy hành trình lên đám mây cho các khách hàng doanh nghiệp toàn cầu của AWS. Cô có hơn 7 năm kinh nghiệm trong ngành, bao gồm các lĩnh vực như bảo mật đám mây, vận hành đám mây, quản lý cơ sở hạ tầng đám mây và chăm sóc khách hàng doanh nghiệp. Sameeksha đặc biệt đam mê các công nghệ bảo mật đám mây và luôn nỗ lực giúp khách hàng đảm bảo an toàn cho khối lượng công việc của họ trên nền tảng đám mây. Gaurav Singodia Gaurav Singodia là một lãnh đạo kỹ thuật cao cấp tại Snowflake với thành tích nổi bật trong việc thúc đẩy đổi mới sáng tạo và tăng trưởng nhờ tư duy khởi nghiệp. Hiện tại, ông dẫn dắt một tổ chức toàn cầu đa dạng bao gồm các nhóm SRE (Đảm bảo độ tin cậy của hệ thống), Kỹ sư hệ thống, Kỹ sư phần mềm, Hạ tầng dữ liệu, Nền tảng nhận diện, AI/ML và Phân tích, với trọng tâm lớn vào việc duy trì chất lượng cao và đạt được khả năng mở rộng trên tất cả các lĩnh vực. Jagdish Pawar Jagdish Pawar có hơn 18 năm kinh nghiệm lãnh đạo trong các công ty khởi nghiệp công nghệ, doanh nghiệp đang phát triển và các tập đoàn lớn. Ông có chuyên môn về xây dựng và dẫn dắt các nhóm liên chức năng, quản lý sản phẩm, kỹ thuật và quản lý vận hành điện toán đám mây với độ tin cậy cao, an toàn và khả năng mở rộng lớn. RK Sai (Ravikiran Koduri) RK Sai (Ravikiran Koduri) là Trưởng nhóm Hỗ trợ Doanh nghiệp tại AWS. Trong vai trò cố vấn kỹ thuật, ông giúp các Nhà cung cấp phần mềm độc lập (ISV) triển khai vận hành các khối lượng công việc với quy mô lớn. RK Sai là người truyền cảm hứng về AWS Deep Racer, các dịch vụ AI và Quản lý tài chính đám mây. Trong thời gian rảnh, ông luôn cố gắng biến ý nghĩa trừu tượng về sự viên mãn thành điều cụ thể trong cuộc sống. Sayan Moitra Sayan Moitra là kỹ sư DevOps cấp cao chuyên về kỹ thuật đám mây, DevOps và đảm bảo độ tin cậy hệ thống (SRE), với thế mạnh trong việc triển khai hạ tầng và ứng dụng. Anh sở hữu nhiều chứng chỉ AWS và CKAD, đồng thời được công nhận về chuyên môn trong lĩnh vực điện toán không máy chủ (serverless computing). Sayan có niềm đam mê học hỏi liên tục và giải quyết các vấn đề phức tạp. "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": "Di chuyển liền mạch: Chuyển đổi bảo mật các đội thiết bị IoT lớn sang AWS﻿ Bởi Andrea Sichel and Katja-Maja Kroedel | Ngày 15 tháng 4 năm 2025 | Trong các chủ đề: Advanced (300), AWS IoT Core, AWS IoT Device Management, Best Practices, Intermediate (200), Internet of Things, Migration, Technical How-to\nDi chuyển các đội thiết bị IoT quy mô lớn lên đám mây là một trong những chuyển đổi kỹ thuật phức tạp nhất mà các tổ chức ngày nay phải đối mặt. Mặc dù các lợi ích của việc di chuyển lên đám mây là rõ ràng, con đường dẫn đến triển khai thành công đòi hỏi phải lên kế hoạch và thực hiện cẩn thận. Trong một bài viết trước, chúng tôi đã phân tích các lý do chính để di chuyển sang AWS IoT Core. Bài viết này sẽ chia sẻ một chiến lược đã được kiểm nghiệm cho việc chuyển đổi các đội thiết bị IoT với hàng trăm triệu thiết bị sang AWS IoT Core, giải quyết các thách thức phổ biến, phác họa một kịch bản di chuyển cụ thể và đi sâu vào các tính năng của AWS IoT Core hỗ trợ các ca di chuyển phức tạp.\nCác thách thức với broker nhắn tin IoT tự quản lý﻿ Nhiều tổ chức bắt đầu hành trình IoT của mình với các broker nhắn tin tự quản lý. Dù phương pháp này mang lại sự kiểm soát và linh hoạt ban đầu, nó thường trở nên ngày càng thách thức hơn khi số lượng thiết bị tăng lên. Hiểu rõ các thách thức này là điều quan trọng trước khi bắt đầu quá trình di chuyển lên đám mây.\nChi phí cao﻿ Tác động tài chính của việc duy trì và vận hành hạ tầng IoT tự quản lý vượt xa chi phí lưu trữ cơ bản. Các tổ chức thường gặp khó khăn với việc lên kế hoạch năng lực không hiệu quả, cần đội ngũ kỹ sư riêng để quản lý hạ tầng. Những đội ngũ này phải luôn cân đối các ưu tiên giữa các phòng ban khác nhau và duy trì độ tin cậy của hệ thống. Chi phí cho việc giám sát, bảo mật và tuân thủ càng làm tình hình tài chính thêm phức tạp.\nPhù hợp năng lực tính toán﻿ Một trong những khía cạnh khó khăn nhất của việc quản lý hạ tầng IoT là đáp ứng tài nguyên tính toán với nhu cầu tải công việc. Các thời kỳ sử dụng cao điểm đòi hỏi phải có năng lực dư thừa để duy trì hiệu suất, trong khi các thời điểm sử dụng thấp dẫn đến phân bổ tài nguyên lãng phí. Thách thức này càng nghiêm trọng hơn với các triển khai toàn cầu, nơi các mô hình sử dụng khác nhau theo khu vực và múi giờ. Các tổ chức thường phải chọn giữa việc cấp phát dư thừa để đảm bảo độ tin cậy, hoặc mạo hiểm với các vấn đề hiệu suất khi xảy ra đột biến bất ngờ.\nCác thách thức bảo mật chưa được giải quyết﻿ Bảo mật có lẽ là thách thức quan trọng nhất trong việc triển khai IoT quy mô lớn. Quản lý hàng triệu thiết bị kết nối cần các giao thức bảo mật tinh vi, gồm quản lý chứng chỉ, phát hiện mối đe dọa theo thời gian thực, cơ chế cập nhật và truyền dữ liệu an toàn. Khi các yêu cầu quy định phát triển, các tổ chức buộc phải liên tục cập nhật thực tiễn bảo mật mà vẫn phải duy trì dịch vụ không gián đoạn. Yêu cầu này ngày càng phức tạp hơn khi đội thiết bị mở rộng và phân bố địa lý.\nSự đổi mới chậm lại﻿ Có lẽ chi phí tiềm ẩn lớn nhất từ broker tự quản là ảnh hưởng tới đổi mới. Các đội kỹ thuật dành quá nhiều thời gian để duy trì hạ tầng hiện có thay vì phát triển tính năng mới hoặc cải thiện trải nghiệm khách hàng. Gánh nặng duy trì này dẫn tới chậm ra mắt sản phẩm và bỏ lỡ cơ hội thị trường, ảnh hưởng đến vị thế cạnh tranh của tổ chức.\nKịch bản khách hàng và yêu cầu﻿ Hãy cùng xét một kịch bản di chuyển minh họa việc các môi trường IoT phức tạp cũng có thể chuyển đổi thành công sang AWS IoT Core.﻿\nHình 1: Kịch bản khách hàng trước khi di chuyển\nKiến trúc﻿ Hình dung một khách hàng với thiết lập sau, minh họa trong hình 1:﻿\n10 triệu thiết bị: Kết nối hàng ngày từ nhiều vị trí trên toàn thế giới.﻿\nGiải pháp triển khai tại chỗ: Thiết bị ban đầu kết nối broker và dịch vụ backend tại chỗ, thực hiện logic cho ứng dụng người dùng nội bộ hoặc hỗ trợ.﻿\nMáy chủ DNS: Được sử dụng để kết nối đến broker MQTT tự quản lý.﻿\nHơn 80 dịch vụ backend: Kiến trúc vi dịch vụ phân tán với 20–100 instance mỗi dịch vụ.﻿\nAPI Gateway: Các ứng dụng tiêu thụ dữ liệu tương tác với backend qua API gateway.﻿\nYêu cầu kỹ thuật cho giải pháp mới﻿ Giải pháp mới phải đáp ứng yêu cầu kỹ thuật nghiêm ngặt để đảm bảo chuyển đổi liền mạch:﻿\nCập nhật thiết bị không cần tương tác: Đội thiết bị phải chuyển đổi mà không cần thay đổi firmware hoặc tác động thủ công, vì không thể cập nhật trên hiện trường trong thời gian di chuyển mong đợi.\nKhả năng tương thích giao thức: Hỗ trợ liền mạch cả giao thức MQTT3 và MQTT5, do đội thiết bị gồm nhiều thế hệ phần cứng dùng các phiên bản giao thức khác nhau.\nPhân phối tin nhắn nâng cao: Dịch vụ backend cần chức năng subscription chia sẻ để cân bằng tải hiệu quả và đảm bảo xử lý tin nhắn nhất quán giữa các instance dịch vụ.\nTính năng của AWS IoT Core cho di chuyển phức tạp﻿ AWS IoT Core cung cấp bộ tính năng được thiết kế riêng để hỗ trợ các ca di chuyển phức tạp như đã minh họa ở trên.﻿\nAWS IoT Core vận hành dựa trên mô hình trách nhiệm chia sẻ, xác định ranh giới bảo mật và vận hành. AWS quản lý và bảo mật hạ tầng gốc, gồm trung tâm dữ liệu vật lý, bảo trì dịch vụ và độ sẵn sàng dịch vụ. Khách hàng chịu trách nhiệm bảo mật ứng dụng, triển khai bảo mật ở mức thiết bị, quản lý chứng chỉ và phát triển logic kinh doanh trên AWS IoT Core.\nHình 2: Các tính năng cốt lõi của AWS IoT\nDưới đây là một số khả năng chính (các dịch vụ được tô đậm là đặc biệt phù hợp với kiến trúc của khách hàng):\nDịch vụ nhận diện: Xác thực thiết bị nâng cao bằng chứng chỉ X.509, hỗ trợ các Tổ chức cấp chứng chỉ (CA) tùy chỉnh, và kiểm soát truy cập chi tiết thông qua các AWS IoT policies.\nGateway thiết bị: Khả năng kết nối mở rộng linh hoạt, hỗ trợ hàng triệu kết nối đồng thời, đa giao thức (HTTPS, MQTT, MQTT qua WebSockets, và LoRaWAN), cùng khả năng cân bằng tải tự động.\nBroker tin nhắn: Phân phối tin nhắn độ trễ thấp với hỗ trợ MQTT 3.1.1, MQTT 5, subscription chia sẻ, chức năng lưu trữ tin nhắn.﻿\nRegistry: Danh mục thiết bị toàn diện với quản lý metadata linh hoạt, nhóm thiết bị động, tích hợp với AWS IoT Device Management.﻿\nCác tính năng then chốt cho di chuyển phức tạp﻿ AWS IoT Core cung cấp một bộ tính năng mạnh mẽ giúp đơn giản hóa các quá trình di chuyển đội thiết bị IoT phức tạp, đồng thời giải quyết những thách thức thường gặp khi nâng cấp lên giải pháp AWS IoT Core do AWS quản lý. Một khía cạnh quan trọng của phương án di chuyển theo từng giai đoạn là các kỹ thuật này cho phép các dịch vụ backend và thiết bị thực hiện di chuyển theo tốc độ riêng của mình, từ đó giảm thiểu tối đa thời gian gián đoạn và ngừng hoạt động. Hãy cùng tìm hiểu chi tiết một số khả năng quan trọng, liên quan trực tiếp đến kịch bản di chuyển của khách hàng được nêu ở phần trước:\nCustom domain: Tính năng này nổi bật như một yếu tố then chốt cho việc migration quy mô lớn. Nó loại bỏ một trong những rào cản lớn nhất khi migration bằng cách cho phép tổ chức sử dụng domain hiện tại với endpoint AWS IoT Core. Điều này đồng nghĩa thiết bị có thể tiếp tục hoạt động với cấu hình sẵn có, từ đó giảm đáng kể rủi ro và độ phức tạp của quá trình migration. Ngoài ra, người dùng còn có thể cấu hình các policy và phiên bản TLS cũng như các giao thức, cổng kết nối cho endpoint sử dụng.\nHỗ trợ MQTT (MQTT 3 và MQTT 5): Trong các hệ thống IoT đa dạng, thiết bị thường sử dụng nhiều phiên bản MQTT khác nhau. AWS IoT Core hỗ trợ cả MQTT 3.1.1 và MQTT 5, cho phép các thiết bị sử dụng các phiên bản MQTT khác nhau vẫn có thể kết nối, đảm bảo quá trình migration diễn ra suôn sẻ mà không cần nâng cấp đồng loạt toàn bộ thiết bị lên chuẩn MQTT mới nhất ngay lập tức.\nBring your own certificate authority (CA): Việc giữ nguyên hạ tầng bảo mật hiện tại rất quan trọng trong quá trình migration. AWS IoT Core cho phép bạn đăng ký CA đang dùng lên AWS, tạo lập chuỗi tin cậy giữa thiết bị và AWS IoT Core mà không cần phải cấp lại certificate mới cho thiết bị. Điều này loại bỏ nhu cầu quay vòng certificate trong suốt quá trình migration.\nGần đây, AWS IoT Core cập nhật thêm các tính năng tăng cường quá trình di chuyển và nâng cao hiệu năng:﻿\nMessage enrichment with registry metadata: Lan truyền các thuộc tính thiết bị lưu trong registry cùng mỗi thông điệp gửi đi, giúp loại bỏ nhu cầu dùng AWS Lambda hoặc các instance xử lý để truy xuất thông tin này từ nguồn khác.\nThing-to-connection association: \u0026ldquo;thing\u0026rdquo; là một entry trong registry chứa các thuộc tính mô tả thiết bị. Chính sách xác định các thao tác mà thiết bị có thể thực hiện trên AWS IoT. Tính năng mới cho phép sử dụng biến trong chính sách với bất kỳ định dạng client ID, giải quyết được vấn đề migration khi client ID không tuân thủ quy tắc về tên \u0026ldquo;thing\u0026rdquo; của AWS IoT Core. Khi cấu hình xong, có thể sử dụng nhiều client ID cho mỗi certificate và \u0026ldquo;thing\u0026rdquo;, linh hoạt mà không cần thay đổi định danh hay cấu hình thiết bị đang có.\nClient ID in just-in-time registration (JITR): Thực hiện xác thực bảo mật bổ sung trong quá trình JITR nhờ nhận được thông tin client ID.\nCustom client certificate validation: Cho phép xác thực chứng chỉ khách hàng (client certificate) một cách tùy chỉnh thông qua hàm AWS Lambda khi thiết bị kết nối. Điều này hỗ trợ tích hợp với các dịch vụ kiểm tra chứng thực bên ngoài như OCSP (Online Certificate Status Protocol), giúp tăng cường kiểm soát bảo mật cho toàn bộ quá trình xác thực thiết bị.\nCustom authentication with X.509 client certificates: Mở rộng xác thực certificate bằng Lambda, cho phép chỉ định chính sách động cho thiết bị khi kết nối. Tính năng này bổ sung cho chức năng Custom Authorizer vốn đã hỗ trợ JWT token và username/password.\nALPN TLS extension removal: Extension ALPN của TLS không còn bắt buộc phải có trong quá trình bắt tay bảo mật (Transport Layer Security handshake) , giúp loại bỏ rào cản đối với những thiết bị không hỗ trợ ALPN.\nCác tính năng trên mang lại sự linh hoạt, bảo mật và hiệu quả cao hơn khi quản lý đội thiết bị IoT trên AWS IoT Core. Bằng cách tận dụng chúng, tổ chức có thể giảm tối đa độ phức tạp và rủi ro khi di chuyển đội thiết bị lớn, đảm bảo chuyển đổi liền mạch sang nền tảng IoT trên đám mây hiện đại, an toàn, mở rộng được.\nKiến trúc mục tiêu﻿ Kiến trúc mục tiêu gồm di chuyển 10 triệu thiết bị kết nối AWS IoT Core qua Amazon Route 53 (hoặc bất kỳ máy chủ DNS nào). Các dịch vụ backend, API gateway và ứng dụng tiêu thụ vẫn giữ nguyên.\nHình 3: Kiến trúc mục tiêu\nChiến lược di chuyển﻿ Ý tưởng là xây dựng chiến lược di chuyển dựa trên năm trụ cột chính nhằm đảm bảo quá trình chuyển đổi diễn ra suôn sẻ. Quá trình này bắt đầu bằng cách duy trì phương pháp tiếp cận không rủi ro thông qua việc lập kế hoạch và kiểm thử cẩn thận, đồng thời kiểm soát hoạt động với tài liệu và giám sát đầy đủ. Chiến lược nhấn mạnh việc giữ cho mức độ sai sót ở mức tối thiểu thông qua các bước thực hiện và xác nhận chính xác.\nPhù hợp với các nguyên tắc chiến lược đã nêu, nên áp dụng phương pháp tiếp cận theo từng giai đoạn.Mỗi giai đoạn có mục tiêu và các phụ thuộc cụ thể, cho phép theo dõi tiến độ một cách chặt chẽ và linh hoạt điều chỉnh khi cần thiết.\nHãy cùng đi sâu vào từng giai đoạn, làm rõ động lực các quyết định và minh hoạ thực tế.﻿\nGiai đoạn 0: Chuẩn bị﻿ Giai đoạn chuẩn bị đặt nền móng cho di chuyển thành công. Trọng tâm là thiết lập cầu nối giữa hạ tầng hiện tại và AWS IoT Core, đảm bảo vận hành liên tục trong suốt quá trình.\nTrung tâm của giai đoạn này là triển khai lớp chuyển tiếp (republish). Thành phần này đóng vai trò trung gian, hỗ trợ giao tiếp hai chiều giữa broker tự quản lý và AWS IoT Core — như một đường hầm bảo mật cho phép tin nhắn chuyển động liền mạch giữa hai hệ.\nHình 4: Kiến trúc của Giai đoạn Chuẩn bị\nLớp chuyển tiếp gồm hai thành phần chủ yếu:﻿ Thiết bị đến backend (Device to backend): Thành phần này thu nhận các thông điệp từ thiết bị đang kết nối với broker do bạn tự quản lý và chuyển tiếp chúng đến AWS IoT Core. Việc triển khai luồng này trước cho phép bắt đầu quá trình chuyển dịch các dịch vụ backend, trong khi thiết bị vẫn tiếp tục kết nối với broker hiện tại.\nBackend đến thiết bị (Backend to device): Được triển khai song song, thành phần này đảm bảo các thông điệp từ các dịch vụ backend mới đã được chuyển dịch vẫn đến được các thiết bị còn kết nối với broker tự quản lý. Khả năng truyền thông hai chiều này giúp duy trì tính toàn vẹn của hệ thống trong suốt quá trình chuyển đổi.\nKhuyên dùng triển khai lớp chuyển tiếp bằng dịch vụ container như Amazon Elastic Container Service (ECS) hoặc các phương án tính toán khác phù hợp. Mã nguồn thành phần này đơn giản: đăng ký một chủ đề trên broker rồi publish sang broker kia. Deployment bằng container giúp linh hoạt scale up/down tùy nhu cầu di chuyển.\nGiai đoạn 1: Di chuyển backend﻿ Giai đoạn này tập trung di chuyển dịch vụ backend từ broker tự quản lý sang AWS IoT Core. Hãy cùng xem cách tận dụng lớp chuyển tiếp để di chuyển backend từng bước mà không mất thông tin.\nLớp chuyển tiếp thiết bị đến backend﻿ Trong quá trình di chuyển backend, duy trì phân phối tin nhắn đều qua các subscription chia sẻ là tối quan trọng để tránh quá tải subscriber. Lớp chuyển tiếp tích hợp mượt mà với instance có sẵn, dùng mô hình subscription chia sẻ, đảm bảo phân phối tin nhắn cân bằng. Khi tin nhắn đi qua lớp này sang instances đã di chuyển, kiểm soát kỹ từng thành phần để ngăn quá tải. Tiến trình cẩn trọng giúp di chuyển từ từ, giữ nguyên mô hình phân phối tin nhắn và ổn định hệ thống.\nLớp chuyển tiếp backend đến thiết bị﻿ BTD triển khai cấp cluster ECS của Amazon, kết nối tới AWS IoT Core để tiêu thụ tin nhắn. Khác lớp DTB, tất cả instances BTD có thể triển khai đồng thời vì mỗi instance xử lý chủ đề thiết bị riêng biệt, không lo quá tải. Điều này giúp đẩy nhanh di chuyển backend mà vẫn đảm bảo tin nhắn tới thiết bị.\nHình 5: Kiến trúc trực quan hóa Lớp xuất bản lại thiết bị từ phía sau cho quá trình di chuyển dịch vụ A\nTrong quá trình di chuyển backend, khuyến nghị thiết lập AWS IoT Core rule để lưu tin nhắn vào Amazon S3 như lớp backup quan trọng. Việc lưu backup cho phép phục hồi và xử lý lại nếu có sự cố ngoài dự kiến, đảm bảo không mất dữ liệu từ thiết bị.\nVới lớp chuyển tiếp hoạt động ổn định, tiến trình di chuyển theo từng bước hệ thống như sau:﻿\nGiới thiệu instance DTB đầu tiên﻿\nKiểm tra luồng tin nhắn qua instance này đến AWS IoT Core và về thiết bị﻿\nLoại bỏ instance backend chưa di chuyển tương ứng﻿\nTiếp tục lần lượt với tất cả instance backend﻿\nPhương pháp này giúp chuyển đổi mượt mà toàn bộ dịch vụ backend sang AWS IoT Core. Chiến lược tương tự áp dụng cho các dịch vụ nền tảng khác, đảm bảo liên tục vận hành qua toàn bộ quá trình.\nHình 6: Kiến trúc trực quan hóa quá trình hoàn tất di chuyển phần phụ trợ sang AWS IoT\nGiai đoạn 2: Di chuyển thiết bị﻿ Giai đoạn này đặc biệt cần chú ý chi tiết vì ảnh hưởng trực tiếp đến trải nghiệm người dùng và kết nối thiết bị.﻿\nChìa khóa để di chuyển thiết bị thành công là chiến lược định tuyến DNS có trọng số (hay chiến lược tùy chọn), ví dụ dịch vụ Amazon Route 53 (hoặc bất kỳ DNS nào). Phương án này cho phép điều tiết chi tiết quá trình chuyển đổi:\nBắt đầu với tỷ lệ nhỏ (thường 1–2%) lưu lượng chuyển sang AWS IoT Core.﻿\nGiám sát kết nối thiết bị, chuyển giao tin nhắn, khả năng vượt ngưỡng throttling và tỷ lệ lỗi dựa vào metric AWS IoT và dimension trong Amazon CloudWatch.﻿\nTăng dần tỷ lệ dựa trên chỉ số hiệu năng.﻿\nDuy trì khả năng đảo ngược lưu lượng nhanh khi cần.﻿\nGiai đoạn này khai thác chức năng đăng ký tự động thời gian thực của AWS IoT Core, tự động cấp phát tài nguyên kết nối thiết bị. Tự động hóa này tối giảm gánh nặng vận hành khi di chuyển quy mô lớn.\nHình 7: Kiến trúc trực quan hóa quá trình di chuyển thiết bị\nSau khi hoàn tất di chuyển thiết bị, lớp chuyển tiếp vẫn hoạt động, tiếp tục chuyển tin nhắn về broker tự quản lý. Thiết kế này làm đường quay lại thiết yếu – nếu có sự cố, có thể ngay lập tức chuyển lưu lượng về broker cũ mà vẫn duy trì giao tiếp tin nhắn giữa thiết bị và backend.\nGiai đoạn 3: Dọn dẹp﻿ Giai đoạn dọn dẹp hoàn tất quá trình di chuyển. Lớp chuyển tiếp được loại bỏ trước, tách biệt broker tự quản lý. Sau khi hệ thống giám sát và các thành phần phụ xác nhận không còn lưu lượng đến broker cũ, và toàn bộ hệ thống vận hành ổn định qua AWS IoT Core, tiến hành kết thúc hoạt động broker — hoàn tất di chuyển.\nHình 8: Kiến trúc trực quan hóa quá trình di chuyển hoàn tất khớp với kiến ​​trúc mục tiêu\nTrình tự được kiểm soát này giúp quá trình chuyển đổi diễn ra mượt mà, đồng thời duy trì sự ổn định của hệ thống trong suốt giai đoạn chuyển đổi cuối cùng.\nKết luận﻿ Các tổ chức có thể di chuyển thành công đội thiết bị IoT lớn lên AWS IoT Core theo phương pháp từng giai đoạn và tuân thủ chiến lược năm trụ cột. Mô hình này giảm thiểu rủi ro, cung cấp các cơ chế failback ở mọi giai đoạn. Tiến trình chuẩn bị, di chuyển backend, di chuyển thiết bị và dọn dẹp đảm bảo chuyển đổi có quy trình và bảo mật, cho phép cả backend và thiết bị di chuyển với tốc độ riêng, duy trì tính ổn định vận hành.\nĐể có phân tích chi tiết, tương tác trực quan về hành trình di chuyển, mời theo dõi loạt video hướng dẫn trên kênh YouTube AWS IoT: Phần 1 và Phần 2. Các video này cung cấp thêm các góc nhìn và minh hoạ thực tế cho các khái niệm trong bài. Để biết thêm các case khách hàng và đối tác đã di chuyển lên AWS IoT, hãy xem bài blog này.\nHãy nhớ, chuyển đổi IoT thành công không chỉ đơn thuần là di chuyển hệ thống — mà là xây dựng nền tảng cho mở rộng trong tương lai, đồng thời đảm bảo liên tục kinh doanh suốt quá trình chuyển đổi.\nVề tác giả﻿ Andrea Sichel Andrea Sichel là Kiến trúc sư giải pháp IoT chuyên sâu tại Amazon Web Services, nơi ông hỗ trợ khách hàng trong hành trình ứng dụng đám mây lĩnh vực IoT. Bằng sự tò mò và triết lý đặt khách hàng lên hàng đầu, ông phát triển các giải pháp sáng tạo và luôn cập nhật công nghệ mới nhất. Andrea thích đối mặt các bài toán phức tạp và giúp tổ chức mở rộng tầm nhìn về chuyển đổi IoT. Ngoài công việc, Andrea huấn luyện đội bóng đá cho con trai và đam mê nhiếp ảnh. Khi không ở trên sân bóng hay sau máy ảnh, ông thường bơi lội để duy trì sự cân bằng giữa công việc và cuộc sống. Katja-Maja Kroedel Katja-Maja Kroedel là chuyên gia vận động về cơ sở dữ liệu và IoT tại AWS. Cô giúp khách hàng khai thác tối đa tiềm năng của công nghệ đám mây. Với nền tảng kỹ thuật máy tính và kinh nghiệm sâu rộng về IoT \u0026amp; databases, cô cộng tác chặt chẽ với khách hàng về định hướng áp dụng đám mây, chiến lược và di chuyển hệ thống trong những lĩnh vực này. Katja yêu thích công nghệ đổi mới, xây dựng và thử nghiệm với dịch vụ như AWS IoT Core, AWS RDS. "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/3-blogstranslated/3.4-blog4/",
	"title": "Blog 4",
	"tags": [],
	"description": "",
	"content": " "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/3-blogstranslated/3.5-blog5/",
	"title": "Blog 5",
	"tags": [],
	"description": "",
	"content": " "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/3-blogstranslated/3.6-blog6/",
	"title": "Blog 6",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch: DX Talk #7 — Reinventing DevSecOps with AWS Generative AI Mục đích sự kiện Chia sẻ tác động của AI trong vận hành hệ thống và các case study thực tế.\nDiễn giả Lê Thanh Đức — Cloud Delivery Manager, CMC Global Dư Quốc Thành — Technical Leader, CMC Global Văn Hoàng Kha — Cloud Engineer, AWS Community Builder Nội dung chính 1. Bối cảnh chung của DevSecOps và tác động của AI Vì sao DevSecOps: Nhiều doanh nghiệp đang chuyển sang mô hình Agile DevSecOps để rút ngắn thời gian release, tăng tự động hóa và đưa sản phẩm ra sớm hơn. Khi tốc độ phát hành tăng, rủi ro bảo mật cũng tăng theo. Ví dụ: một commit có thể chứa secret; dependency hoặc image có thể có lỗ hổng chưa được scan kỹ. Trước đây, bảo mật thường là nhiệm vụ của team Security (sau khi Dev và Ops hoàn thành), dẫn đến thay đổi khó khăn và chi phí khắc phục lớn (có thể gấp 10–20 lần). Vì vậy, security cần được tích hợp xuyên suốt từ đầu đến cuối. Ngoài việc thêm công cụ và framework vào pipeline, mọi thành viên trong team đều phải chịu trách nhiệm về security (Dev hiểu rủi ro khi code; Ops hiểu quy trình an toàn khi triển khai; Security hiểu cách DevOps vận hành). 2. Framework cho DevOps LifeCycle Framework được chia thành 3 lớp chính:\nLớp đầu: đưa bảo mật vào càng sớm càng tốt\nVí dụ: SAST để quét mã nguồn, Software Composition Analysis để kiểm tra dependency, scan script để phát hiện API key hoặc credential lộ trong code. Lớp giữa: áp dụng DevSecOps khi Build và Deploy, tập trung kiểm soát an toàn trong môi trường triển khai\nVí dụ: sử dụng các tool DAST để kiểm tra lỗ hổng trong image. Lớp cuối: Runtime Security và Continuous Feedback.\n3. 7 phase chính trong DevOps LifeCycle (Case studies thực tế) Phase 1: PLAN — Lập kế hoạch\nXác định yêu cầu bảo mật ngay từ khâu lập kế hoạch sản phẩm. Phân tích rủi ro, xây dựng model AThreast, đặt mục tiêu tuân thủ phù hợp với quy định/tiêu chuẩn dự án. Ba nhóm Dev — Sec — Ops cần thống nhất mục tiêu, quy trình và nguồn lực để đảm bảo Security gắn liền với Business từ đầu. Xác định rõ Security Roadmap. Phase 2: CODE — Viết mã\nBảo mật được đưa trực tiếp vào môi trường viết code. Developer cần tuân thủ secure coding standards và code review. Dùng SAST để phát hiện lỗi trong quá trình viết code. Hình thành tư duy \u0026ldquo;Security-First\u0026rdquo; cho developer. Phase 3: BUILD — Xây dựng\nTự động hóa hoàn toàn chuỗi CI/CD. Công cụ: dependency scan, config validation để đảm bảo build không chứa mã độc hay lỗ hổng. Đảm bảo bản build ổn định, có thể tái sử dụng và đảm bảo toàn vẹn phần mềm trước khi release. Phase 4: TEST — Kiểm thử\nThực hiện kiểm thử bảo mật toàn diện. Chạy vulnerability scan, DAST, penetration test, audit. Cập nhật test case theo các lỗ hổng được phát hiện. Phase 5: DEPLOY — Triển khai\nKiểm tra cấu hình \u0026amp; IaC, policy-as-code trước khi deploy. Đảm bảo runtime environment tuân thủ tiêu chuẩn bảo mật đã thống nhất. Giảm lỗi thủ công, đảm bảo deploy an toàn. Phase 6: OPERATE — Vận hành\nTự động vá lỗi và cập nhật bảo mật liên tục. Duy trì ổn định và an toàn sau release. Phase 7: MONITOR — Giám sát\nGiám sát liên tục. Dùng Realtime Analytics và các tool cảnh báo các mối đe dọa. DevSecOps giúp chủ động phòng ngừa thay vì phản ứng, giữ phần mềm ở trạng thái an toàn. 4. Công cụ hỗ trợ DevSecOps Pre-commit \u0026amp; Code Quality: SonarQube, Codacy, Semgrep (SAST), Gitleaks — scan code, kiểm tra code coverage, kiểm tra secret. Dependency \u0026amp; SBOM Scanning: Syft, Grype, Dependency-Track — quản lý package và lỗ hổng thư viện. IaC \u0026amp; Policy-as-Code: Checkov, Tfsec — quét Terraform/Kubernetes config; OPA Gatekeeper, Kyverno — enforce policy \u0026amp; compliance tự động. SAST/DAST \u0026amp; Security Tests: Trivy, Checkmarx, Semgrep, Codacy — phát hiện lỗ hổng ở code và runtime. CI/CD Integration: Jenkins, GitHub Actions, GitLab CI, ArgoCD — tự động hóa build, test, deploy an toàn. Monitoring \u0026amp; Logging: Prometheus, Grafana, Loki, Promtail — giám sát và quan sát hệ thống realtime. Alerting \u0026amp; Governance: Slack webhook, email alerts, anomaly detection — cảnh báo và phản ứng nhanh; centralized risk report — báo cáo và phân tích rủi ro tập trung. 5. Case studies thực tế về Gen-AI trong DevSecOps Demo pipeline anh Thành: CI/CD flowchart (mô tả tóm tắt) — (Dự án Blockchain Singapore — Anh Thành)\nDemo pipeline anh Đức:\nPull source code từ Bitbucket — Build bằng MSBuild — SonarQube analysis — Check SonarQube Quality Gate — Archive files — Push artifacts.\nDemo CI/CD pipeline (Dự án khách hàng Philippines — Anh Đức)\nTừ DevOps đến AIOps? =\u0026gt; Các toolchain DevOps hiện nay đều tích hợp Gen-AI bên trong.\nTác động của AI đối với DevOps:\nAI giúp phát hiện và phân tích lỗ hổng thông minh hơn. AI hỗ trợ tự động hóa phản ứng và khắc phục sự cố. AI giúp rút ngắn thời gian và giảm tải cho team bảo mật. AI giúp DevSecOps liên tục học và cải thiện theo thời gian. Lợi ích của Gen-AI trong DevOps:\nTự động hóa và tăng tốc quy trình DevSecOps. Tăng cường bảo mật chủ động. Tối ưu hóa quan sát và phản ứng sự cố. Demo: sử dụng Amazon-Q để scan lỗ hổng từ file code; sử dụng Amazon-Q để test Terraform MCP.\nQ/A — Các câu hỏi hay và trả lời Làm thế nào AI/ML có thể tối ưu hóa chi phí AWS (cost optimization)?\n=\u0026gt; Sử dụng các công cụ ước tính do AWS cung cấp để chọn đúng tài nguyên. Có thể tích hợp Auto Scaling policy dựa trên dự đoán, logs CloudWatch theo khung giờ hoặc ngưỡng để tắt khi không sử dụng. Một số dịch vụ hữu ích: AWS Compute Optimizer, Cost Explorer, \u0026hellip;\nAI có tự động khắc phục lỗi bảo mật không? Nếu có, con người nên tập trung vào phần nào của DevSecOps pipeline?\n=\u0026gt; Có. AI có thể tự động khắc phục một số lỗi bảo mật, nhưng chỉ nên coi AI là công cụ hỗ trợ. Mọi phần trong pipeline vẫn cần có sự giám sát chặt chẽ của con người, dù AI mạnh đến đâu.\n"
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/5-workshop/5.1-workshop-overview/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu về Workshop Workshop này hướng dẫn xây dựng một hệ thống Excel Import serverless trên AWS với các tính năng authentication và data processing.\nMục tiêu Sau bài workshop chúng ta sẽ:\nLàm quen với kiến trúc serverless: Cách thiết kế ứng dụng với Lambda, API Gateway, S3, và DynamoDB Làm quen event-driven architecture: Sử dụng S3 Event Notifications để trigger xử lý tự động Implement authentication: Tích hợp Amazon Cognito cho authentication và API security Parse Excel trong Lambda: Sử dụng Apache POI library để đọc và xử lý file .xlsx/.xls Deploy với AWS SAM: Làm quen với SAM CLI để build và deploy và áp dụng IaC cho toàn bộ hạ tầng. Các Thành Phần Chính 8 Lambda Functions: Register, Confirm, Login, Logout, GenerateUploadUrl, ListImportJobs, GetJobStatus, ImportS3Trigger 3 DynamoDB Tables: Students, Courses, ImportJobs 1 S3 Bucket: Lưu trữ file Excel với lifecycle policy (auto-delete sau 7 ngày) 1 Cognito User Pool: Quản lý users và authentication 1 API Gateway: REST API với Cognito authorizer Thời Gian \u0026amp; Chi Phí Thời gian hoàn thành: ~30 phút\nChi phí: Miễn phí (Tất cả đều nằm trong Free Tier)\nĐể tránh chi phí không mong muốn, hãy thực hiện cleanup ngay sau khi hoàn thành workshop.\nYêu Cầu Hiểu biết cơ bản về AWS (console, regions, basic services) Biết sử dụng terminal/command line Đọc hiểu ngôn ngữ Java "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/1-worklog/",
	"title": "Nhật ký công việc",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTrong trang này bạn sẽ cần giới thiệu worklog của bạn như thế nào? Bạn hoàn thành chương trình trong vòng bao nhiêu tuần? Bạn đã làm gì trong các tuần đó?\nThông thường và cũng là tiêu chuẩn, một worklog được thực hiện trong khoảng 3 tháng (trong suốt thời gian thực tập) với nội dung các tuần như sau:\nTuần 1: Làm quen với AWS và các dịch vụ cơ bản trong AWS\nTuần 2: Làm công việc A\u0026hellip;\nTuần 3: Làm công việc B\u0026hellip;\nTuần 4: Làm công việc C\u0026hellip;\nTuần 5: Làm công việc D\u0026hellip;\nTuần 6: Làm công việc E\u0026hellip;\nTuần 7: Làm công việc G\u0026hellip;\nTuần 8: Làm công việc H\u0026hellip;\nTuần 9: Làm công việc I\u0026hellip;\nTuần 10: Làm công việc L\u0026hellip;\nTuần 11: Làm công việc M\u0026hellip;\nTuần 12: Làm công việc N\u0026hellip;\n"
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/5-workshop/5.4-deploy-backend/5.4.1-sam-build/",
	"title": "SAM Build",
	"tags": [],
	"description": "",
	"content": "Build Project với Maven Maven sẽ compile Java code và download tất cả dependencies cần thiết.\nClean\ncd excel-import-workshop mvn clean Package application\nmvn package Quá trình này sẽ:\nDownload dependencies Compile Java source code Package thành JAR file Build với AWS SAM SAM CLI sẽ chuẩn bị Lambda deployment packages.\nsam build Quá trình này sẽ:\nĐọc template.yaml Tìm tất cả Lambda functions Copy compiled code từ target/ vào .aws-sam/build/ Tạo deployment packages cho từng function "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/1-worklog/1.1-week1/",
	"title": "Worklog Tuần 1",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 1: Kết kết nối, tìm kiếm thành viên cho nhóm. Tìm hiểu các dịch vụ AWS. Tạo tài khoản AWS đầu tiên, làm quen với console, quản lý chi phí. Tìm hiểu về các dịch vụ hổ trợ, cách gửi yêu cầu hổ trợ. Tìm hiểu về quản lý các truy cập, học cách thiết lập quản lý. Tìm hiểu về VPC, học cách thiết kế, triển khai và quản lý. Tìm hiểu về EC2, và triển khai ứng dụng Node.js trên EC2. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen các thành viên trong FCJ và tạo nhóm - Ghi nhớ các nội quy, quy định của văn phòng, và các hướng dẫn trong kỳ training đã được thông báo 08/08/2025 11/08/2025 3 - Tìm hiểu các dịch vụ AWS + Compute + Storage + Networking \u0026amp; Content Delivery + Database + Analysis + Management Tools + Developer Tools + Developer Tools + Machine Learning 09/08/2025 09/08/2025 https://cloudjourney.awsstudygroup.com/vi/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console\n- Tìm hiểu dịch vụ AWS support\n- Thực hành: + Tạo AWS account (Thiết lập MFA cho tài khoản) + Làm quen các thao tác trên console (Cài region mặc định, sử dụng thanh tìm kiếm dịch vụ, bookmark các dịch vụ thường dùng, cách sử dụng widgets) 09/08/2025 09/08/2025 https://000001.awsstudygroup.com/vi/ 5 - Tìm hiểu quản trị quyền truy cập với AWS IAM - Thực hành: + Tạo IAM Group, IAM Role, IAM User + Chuyển đổi IAM Role 10/08/2025 10/08/2025 https://000002.awsstudygroup.com/vi/ 6 - Tìm hiểu về VPC - Thực hành: + Học cách thiết kế, triển khai, quản lý môi trường trên AWS + Thiết lập kết nối Site-to-site VPN - Tìm hiểu về EC2 - Thực hành: + Khởi tạo các instance + Triển khai ứng dụng trên các instance vừa tạo 11/08/2025 12/08/2025 https://000003.awsstudygroup.com/vi/ 7 - Tìm hiểu về EC2 - Thực hành: + Khởi tạo các instance + Triển khai ứng dụng trên các instance vừa tạo 13/08/2025 14/08/2025 https://000004.awsstudygroup.com/vi/ Kết quả đạt được tuần 1: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking \u0026amp; Content Delivery Database Analysis Management Tools Developer Tools Developer Tools Machine Learning Đã tạo và cấu hình AWS Free Tier account thành công.\nBiết được 4 gói hổ trợ của AWS Support và những dịch vụ của từng gói.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nHiểu được IAM là gì: IAM dùng để định danh và phân quyền xem ai hoặc dịch vụ nào có thể truy cập như thế nào vào các tài nguyên trên AWS\nPhân biệt được các thành phần chính trong IAM:\nIAM User: Là 1 người dùng đăng nhập vào AWS Console để thực hiện các tác vụ quản trị hằng ngày IAM Group: Đại diện cho 1 nhóm user trên hệ thống thường Dùng để phân chia quyền theo vai trò của dự án hoặc phòng ban \u0026hellip; Group này không thể chứa group khác 1 user có thể thuộc nhiều group hoặc không thuộc group nào IAM Role: Dùng để gán quyền truy cập tạm thời cho 1 thực thể có thể tương tác với các tài nguyên khác (thường gắn vào EC2, Lambda, \u0026hellip;) ** Một số tài nguyên không thể tương tác được tới tài nguyên khác trên AWS nếu không được gán role (trong role có policies để xác định tài nguyên này được phép làm gì)\nIAM Policies: Quy định user, nhóm, vai trò có thể hoặc không thể làm gì (là văn bản viết bằng JSON) Inline Policy: Policy được tạo và gán trực tiếp trong thực thể Managed Policy: Policy tạo riêng, gán được nhiều thực thể IAM Switch Role: Thực thể sẽ tạm thời bỏ những quyền hiện tại của mình và sẽ sử dụng những quyền của thực thể mình đã switch tới Hiểu được VPC là gì, kiến trúc và các thành phần chính của VPC:\nSubnet: Mạng con trong VPC, chia thành Public - Private Subnet Route Table: Bảng định tuyến, điều hướng lưu lượng mạng (mỗi subnet phải được liên kết với 1 Route Table) (có thì EC2 mới ra internet được) Internet Gateway: Cho phép các Public Subnet truy cập internet NAT Gateway: Cho phép các Private Subnet kết nối ra internet nhưng không cho kết nối vào Biết cách tạo 1 VPC, tạo các Subnet, Internet Gateway, Route Table, tạo Security Group\nTriển khai EC2 instance trong Subnet vừa tạo trước đó và thực hiện kết nối\nTạo NAT Gateway để kết nối EC2 instance được tạo trong private Subnet ra internet\nBiết cách thiết lập CloudWatch và Alerting các chỉ số VPC\nTạo thành công môi trương VPN gồm VPC và EC2\nThiết lập kết nối Site to Site VPN giữa hai VPC thông qua Virtual Private Gateway và Customer Gateway\nKhởi tạo Windows instance, Linux instance và kết nối thành công\nCài đặt LAMP và XAMPP để triển khai ứng dụng AWS FCJ Management trên Window instance và Linux instance\n"
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/1-worklog/1.2-week2/",
	"title": "Worklog Tuần 2",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 2: Biết cách triển khai, quản lý cơ sở dữ liệu trên RDS Biết cách cấp quyền cho ứng dụng EC2 và hiểu được nên sử dụng cách nào Tìm hiểu về dịch vụ lưu trữ dạng đối tượng S3 Tìm hiểu về Lightsail và xây dựng ứng dụng trên đó Làm quen với giao diện Amazon CloudWatch và cách sử dụng để quản lý cung cấp dữ liệu Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Triển khai hệ thống backend sử dụng Amazon EC2, Amazon RDS và Node.js - Thực hành: + Tạo VPC, subnet, security group cho EC2 và RDS + Tạo EC2 instance, SSH bằng MobaXterm + Cài Git, Node.js, MySQL client trên EC2 + Clone source code từ GitHub + Cài đặt npm packages, cấu hình .env kết nối RDS + Thực hiện backup, restore, monitoring RDS 15/09/2025 15/09/2025 https://000005.awsstudygroup.com/vi/ 3 - Cấp quyền cho ứng dụng truy cập dịch vụ AWS bằng IAM Role - Thực hành: + Tạo EC2, S3 bucket, IAM User với Access Key + Upload file lên S3 bằng access key (không an toàn) + Tạo IAM Role gán vào EC2 để upload lên S3 (an toàn) - Sử dụng AWS Cloud9 cho lập trình - Thực hành: + Tạo Cloud9 instance + Dùng terminal, tạo file, chỉnh sửa văn bản, chạy AWS CLI 16/09/2025 16/09/2025 https://000048.awsstudygroup.com/vi/ https://000049.awsstudygroup.com/vi/ 4 - Triển khai website tĩnh trên Amazon S3 và tăng tốc bằng CloudFront - Thực hành: + Tạo S3 bucket và upload dữ liệu website + Bật Static Website Hosting và cấu hình index.html + Cấu hình Block Public Access và thiết lập truy cập công khai cho đối tượng cần thiết + Kiểm tra website qua S3 endpoint + Tích hợp CloudFront để tăng tốc và giữ bucket private + Bật S3 Versioning, thực hành thay đổi file index.html và khôi phục phiên bản cũ + Kiểm tra nội dung website qua CloudFront 17/09/2025 17/09/2025 https://000057.awsstudygroup.com/vi/ 5 - Triển khai hệ thống ứng dụng mã nguồn mở trên Amazon Lightsail - Thực hành: + Tạo Lightsail Database instance + Triển khai 3 ứng dụng: WordPress, PrestaShop và Akaunting + Cấu hình Networking (gán Static IP cho từng instance) + Kết nối database Lightsail + Cấu hình domain và Apache cho Akaunting + Tạo cơ sở dữ liệu MySQL riêng cho từng ứng dụng + Cấu hình tài khoản quản trị trong từng ứng dụng + Cấu hình bảo mật: · Tắt SSH (Port 22) · Thiết lập Firewall Rules - Triển khai container với Amazon Lightsail Containers - Thực hành: + Tạo Lightsail Container + Triển khai container từ public image Nginx + Tạo Lightsail Container + Tạo Lightsail Instance, cài Docker và AWS CLI + Build container image, push lên Lightsail, deploy container image 18/09/2025 18/09/2025 https://000045.awsstudygroup.com/vi/ https://000046.awsstudygroup.com/vi/ 6 - Làm quen sử dụng CloudWatch Dashboards Thực hành: + Dùng CloudFormation tạo EC2 instances với ứng dụng mẫu để sinh metrics và logs + Xem, lọc, tính toán và hiển thị metrics từ ứng dụng trên EC2 + Quan sát logs, tạo log groups/streams, metric filters + Tạo alarm dựa trên metrics và nhận thông báo qua SNS 19/09/2025 19/09/2025 https://000008.awsstudygroup.com/vi/ Kết quả đạt được tuần 2: Biết cách cài đặt môi trường EC2 và kết nối RDS bằng ứng dụng Node.js. Biết dùng Git để pull mã nguồn và cấu hình file .env Biết cách khôi phục database từ Snapshot Biết cách sử dụng IAM role để đảm bảo bảo mật cho ứng dụng chạy trên EC2 Triển khai thành công 3 ứng dụng trên Lightsail (WordPress, PrestaShop, Akaunting) Cấu hình DB, static IP, bảo mật SSH, và thao tác thành thạo giao diện Lightsail Hiểu và vận dụng Lightsail Container, Docker, AWS CLI Build, push và deploy container image thành công Truy cập public endpoint kiểm tra nội dung hiển thị đúng Tạo và cấu hình S3 bucket lưu trữ website tĩnh, bật versioning và quản lý quyền truy cập Tích hợp CloudFront để phân phối nhanh, bảo mật bucket, website hiển thị chính xác và load nhanh Làm quen với Amazon CloudWatch để giám sát hệ thống Thu thập và phân tích metrics Biết tạo alarms để nhận cảnh báo khi hệ thống gặp sự cố "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/1-worklog/1.3-week3/",
	"title": "Worklog Tuần 3",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 3: Làm các bài lab:\nThiết lập Hybrid DNS với Route 53 Resolver Thao tác dòng lệnh với AWS CLI Cơ sở dữ liệu NoSQL với Amazon DynamoDB Bộ nhớ đệm trong bộ nhớ với Amazon ElastiCache Workshop về mạng trên AWS Phân phối nội dung với Amazon CloudFront Điện toán biên với CloudFront và Lambda@Edge Ứng dụng Windows trên AWS Dịch vụ thư mục với AWS Managed Microsoft AD Xây dựng ứng dụng web có tính sẵn sàng cao Dịch chuyển máy chủ ảo với AWS VM Import/Export Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Triển khai kiến trúc DNS hybrid - Thực hành + Tạo một AWS Managed Microsoft Active Directory bằng dịch vụ AWS Directory Service để mô phỏng cho hệ thống DNS on-prem + Tạo Outbound Endpoint (forward truy vấn DNS đến DNS nội bộ) + Tạo Resolver Rules + Tạo Inbound Endpoint (cho phép DNS nội bộ gửi truy vấn DNS đến Route 53) - Làm quen với AWS CLI - Thực hành + Cài đặt, cấu hình AWS CLI + Thực hành sử dụng các lệnh cli với các dịch vụ AWS - Tìm hiểu và nắm vững khái niệm, cấu trúc, khả năng của DynamoDB cùng cách thao tác qua AWS CLI, Console, CloudShell và SDK Python - Thực hành + CRUD + Truy vấn + Quét dữ liệu + Sử dụng index 22/09/2025 22/09/2025 https://000010.awsstudygroup.com/vi/https://000011.awsstudygroup.com/vi/https://000060.awsstudygroup.com/vi/ 3 - Cơ sở dữ liệu NoSQL với Amazon DynamoDB - Bộ nhớ đệm trong bộ nhớ với Amazon ElastiCache\n- Workshop về mạng trên AWS 23/09/2025 23/09/2025 https://000060.awsstudygroup.com/vi/https://000061.awsstudygroup.com/vi/https://000092.awsstudygroup.com/vi/ 4 - Phân phối nội dung với Amazon CloudFront\n- Điện toán biên với CloudFront và Lambda@Edge\n- Ứng dụng Windows trên AWS 24/09/2025 24/09/2025 https://000094.awsstudygroup.com/vi/https://000130.awsstudygroup.com/vi/https://000093.awsstudygroup.com/ 5 - Dịch vụ thư mục với AWS Managed Microsoft AD\n- Xây dựng ứng dụng web có tính sẵn sàng cao 25/09/2025 25/09/2025 https://000095.awsstudygroup.com/https://000101.awsstudygroup.com/vi/ 6 - Dịch chuyển máy chủ ảo với AWS VM Import/Export\n26/09/2025 Kết quả đạt được tuần 3: Hiểu cách Route 53 hoạt động trong môi trường tích hợp Nắm được cách sử dụng các công cụ như Outbound/Inbound Endpoints và Resolver Rules để kiểm soát luồng truy vấn DNS Biết cách sử dụng aws configure để cấu hình cli Biết cách sử dụng script CLI để tổng hợp và quản lý tài nguyên sử dụng Hiểu các khái niệm và cấu trúc của DynamoDB Biết cách sử dụng CLI, console để thao tác với DynamoDB Nắm được khái niệm về cluster, node, shard và cách hoạt ododnjg của Redis Phân biệt được cluster-mode-enabled và cluster-mode-disabled Hiểu rõ mô hình AWS VPC, các thành phần chính và cách hoạt động của:\n- Subnet, Route Table, Internet Gateway, NAT Gateway\n- Security Group vs NACL\n- Elastic Network Interface (ENI) và Elastic IP (EIP) Phân biệt được các loại kết nối mạng:\n- VPC Peering: kết nối 1-1 giữa các VPC (không hỗ trợ transit routing)\n- Transit Gateway (TGW): kết nối nhiều VPC theo mô hình hub-and-spoke\n- VPN Site-to-Site: thiết lập mạng hybrid giữa AWS và on-prem\n- AWS Direct Connect: kết nối chuyên dụng, độ trễ thấp đến AWS Bảo vệ và tăng tốc S3 với CloudFront Có thể tự cấu hình CloudFront Distribution hoàn chỉnh Thực hành sử dụng dịch vụ VM Import/Export để import VM từ on-premises vào ec2 và ngược lại "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/1-worklog/1.4-week4/",
	"title": "Worklog Tuần 4",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 4: Tìm hiểu về tối ưu hóa: vận hành, bảo mật, độ tin cậy, hiệu suất, tối ưu chi phí Làm các bài lab liên quan Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Lab 22: Bật tắt máy chủ tự động và nhắn tin qua Slack với AWS\n- Thực hành:\n+ Tạo EC2 instance\n+ Tạo lambda function, add webhook vào slack, lấy url của webhook để nhận được thông báo từ lambda url\n- Lab 29: Tạo bảng theo dõi hệ thống với Amazon Cloudwatch và Grafana\n- Thực hành:\n+ Tạo ec2 instance\n+ Tạo IAM User để cấu hình Grafana, tạo IAM role gán cho EC2 instance\n+ Cài đặt, cấu hình Grafana để xem thống kê CPUUtilization của instance ec2\n- Lab 27: Quản lý tài nguyên theo nhóm bằng Tag và Resouce Groups\n- Thực hành:\n+ Thêm tags khi khởi tạo các tài nguyên\n+ Tạo resource group để gom các tài nguyên liên quan\n- Lab 28: Quản lý truy cập dịch vụ EC2 bằng Tag thông qua IAM\n- Thực hành:\n+ Tạo các policy với các quyền quyền: Liệt kê EC2, gắn tag khi tạo ec2, gắn tags lên ec2 đã tồn tại, tạo ec2, quản lý instance state\n\u0026amp;emspl; + Gán Tạo role chứa các policy đó\n+ Gán role đó lên user 29/09/2025 29/09/2025 https://000022.awsstudygroup.com/vi/\nhttps://000029.awsstudygroup.com/vi\nhttps://000027.awsstudygroup.com/vi/\nhttps://000028.awsstudygroup.com/vi/ 3 - Lab 30: Giới hạn Quyền của User với IAM Permission Boundary\n- Thực hành:\n+ Tạo policy giới hạn quyền tối đa\n+ Tạo user sau đó set policy boudary\n- Lab 44: Giới hạn chuyển Role theo Condition\n- Thực hành: Tạo các IAM user, group user, cấu hình IAM Role, giới hạn các quyền truy cập cho IAM User\n- Lab 18: Kiểm tra đánh giá tiêu chuẩn bảo mật với AWS Security Hub\n- Lab 33: Quản lý Khóa với dịch vụ Key Management Service (AWS KMS)\n- Thực hành:\n+ Tạo các Policy, IAM User, User Group để phân quyền truy cập\n+ Tạo khóa đối xứng để\n+ Tạo Bucket S3, tải dữ liệu lên S3 và cấu hình mã hóa bằng key vừa tạo cho file\n+ Cấu hình Cloud Trail để ghi lại log hoạt động của S3 và Athena để truy vấn log được ghi trực tiếp trong S3 30/09/2025 30/09/2025 https://000030.awsstudygroup.com/vi/ https://000044.awsstudygroup.com/vi/ https://000018.awsstudygroup.com/vi/ https://000033.awsstudygroup.com/vi/ 4 - Lab 13: Triển khai kế hoạch sao lưu hệ thống với AWS Backup\n- Thực hành:\n+ Tạo Backup Plan, cấu hình lịch và tài nguyên cần sao lưu\n+ Cài đặt SNS Notification nhận thông báo về việc sau lưu\n- Lab 19: Liên kết các Virtual Private Cloud (VPC) với VPC Peering - Thực hành:\n+ Tạo 2 VPC\n+ Tạo VPC Peering để tạo kết nối giữa 2 VPC\n+ Cấu hình Route Table, VPC này thêm route đến VPC kia bằng Peering connection\n+ Cấu hình Networks ACL, chặn tất cả chỉ allow mỗi CIDR\n- Lab 20: Quản lý tập trung các kết nối với AWS Transit Gateway\n- Thực hành:\n+ Chuẩn bị 4 instance ec2 bằng CloudFormation\n+ Tạo Transit Gateway, sử dụng TGW Attachment để gắn liên kết giữa các VPC, sử dụng TGW Route Table để xác định đường đi 01/10/2025 01/10/2025 https://000013.awsstudygroup.com/vi/\nhttps://000019.awsstudygroup.com/vi/\nhttps://000020.awsstudygroup.com/vi/ 5 - Lab 15: Triển khai Ứng dụng với Docker\n- Thực hành:\n+ Triển khai ứng dụng trên local\n+ Triển khai bằng Docker Image\n+ Đóng gói từng service thành image\n+ Tạo một container network làm trung gian để các container chứa image này có thể giao tiếp với nhau\n\u0026amp;emsp + Triển khai từng container chứa các image\n+ Triển khai bằng Docker Compose\n+ Đóng gói các service thành image\n+ Cấu hình file .yml, sử dụng docker compose để cùng lúc các container được cấu hình trong file .yml\n+ Push các image lên ECR hoặc Docker Hub để lưu trữ các image\n- Xem lại lí thuyết của các dịch vụ 02/10/2025 02/10/2025 https://000015.awsstudygroup.com/vi/\nhttps://www.youtube.com/playlist?list=PL4NoNM0L1m72HCTkOQUiIsHT8LRxdjeKJ 6 - Lab 31: Quản lý dịch vụ và tự động hóa tác vụ sử dụng AWS System Manager\n- Thực hành:\n+ Tạo 2 windows instance làm ví dụ\n+ Gán quyền AmazonSSMManagedInstanceCore cho 2 instance này\n+ Cập nhật bản vá, bảo mật cho 2 instance cùng lúc bằng Patch manager\n+ Sử dụng Run command để gửi lệnh command từ xa\n- Lab 58: Làm việc với AWS System Manager - Session Manager\n- Thực hành: + Gán role AmazonSSMManageInstanceCore cho instance\n+ Kết nối đến instance Ec2 ra được internet\n+ Kết nối với instance Ec2 không ra được internet (thông qua 3 endpoint ssm, ssmmessages, ec2messages)\nSử dụng S3 bucket để lưu lại session log để xem lịch sử command\n- Xem lại lí thuyết của các dịch vụ\n03/10/2025 03/10/2025 https://www.youtube.com/playlist?list=PL4NoNM0L1m72HCTkOQUiIsHT8LRxdjeKJ\nhttps://000031.awsstudygroup.com/vi/\nhttps://000058.awsstudygroup.com/vi/ Kết quả đạt được tuần 4: Biết cách sử dụng dịch vụ lambda để tự động hóa việc bật/tắt các instances ec2 và cách cấu hình để nhận được thông báo bên slack -\u0026gt; Mục tiêu là giảm chi phí cho các instances chỉ hoạt động trong 1 khoảng 1 gian ngắn.\nBiết cài đặt, cấu hình 1 dashboard bằng grafana để theo dõi các tài nguyên sử dụng trên aws.\nTạo tags khi khởi tạo các tài nguyên, lọc tài nguyên theo tags, thêm tag cho tài nguyên bằng CLI\nSử dụng resource group để gom nhóm các tài nguyên có các tags liên quan lại với nhau\nLuôn phải đặc quyền IAM ở mức tối thiểu, chỉ cấp quyền cần thiết khi sử dụng.\nSử dụng Patch manager để tự động cập nhật các bản vá hệ điều hành hoặc tự động cập nhật bảo mật\nSử dụng Run command để gửi lệnh command từ xa đến cùng lúc nhiều instance\nHiểu khái niệm, cách hoạt động, các ưu điểm của Session manager và tại sao nên sử dụng Session manager để quản lý máy chủ thay vì cách truyền thống.\nHiểu sự khác nhau giữa attach policy trực tiếp và sử dụng permissions boundary\nHiểu rõ hơn về các hoạt động của IAM, các request tới các service, authen các request đó và cách assumeRole hoạt động\nNắm được các tiêu chuẩn bảo mật và làm quen với giao diện console của AWS Security Hub\nHiểu được khái niệm về khóa đối xứng và bất đói xứng trong dịch vụ KMS, cách sử dụng để mã hóa dữ liệu được tải lên Bucket S3\nBiết cách sử dụng Cloud Trail để ghi lại log các hoạt động trong S3 và sử dụng Athena để truy vấn các log đó.\nBiết cách cấu hình AWS Backup để bảo vệ dữ liệu, tự động hóa quá trình sao lưu và phục hồi\nCấu hình được SNS Notification để nhận các thông báo liên quan đến việc sao lưu\nHiểu các khái niệm VPC Peering, Network ACL, Cross-Peering DNS\nBiết cách cấu hình ACl và tạo VPC Peering để kết nối 2 VPC\nBiết cách cấu hình Transit Gatewway để khi kết nối nhiều VPC thì đỡ phức tạp hơn VPC Peering\nLàm quen được các thao tác để triển khai một ứng dụng sử dụng AWS bằng Docker\n"
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/1-worklog/1.5-week5/",
	"title": "Worklog Tuần 5",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 5: Làm các bài LAB serverless trong Application Modernization on AWS Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Lab 78: Serverless - Lambda tương tác với S3 và DynamoDB\n- Lab 79: Serverless - Hướng dẫn viết Frontend gọi API Gateway 06/10/2025 06/10/2025 https://000078.awsstudygroup.com/vi\nhttps://000079.awsstudygroup.com/vi 3 - Lab 80: Serverless - Triển khai ứng dụng trên SAM\n- Lab 81: Serverless - Xác thực với Amazon Cognito 07/10/2025 07/10/2025 https://000080.awsstudygroup.com/vi\nhttps://000081.awsstudygroup.com/vi 4 - Lab 82: Serverless - Thiết lập trang website static có SSL trên S3\n- Lab 83: Serverless - Xử lý đơn hàng với SQS và SNS 08/10/2025 08/10/2025 https://000082.awsstudygroup.com/vi\nhttps://000083.awsstudygroup.com/vi 5 - Lab 84: Serverless - CI/CD với AWS CodePipeline\n- Lab 85: Serverless - Giám sát Lambda với CloudWatch và X-Ray 09/10/2025 09/10/2025 https://000084.awsstudygroup.com/vi\nhttps://000085.awsstudygroup.com/vi 6 - Lab 86: Serverless - Giới thiệu AWS AppSync 10/10/2025 10/10/2025 https://00006.awsstudygroup.com/vi Kết quả đạt được tuần 5: Hoàn thành các bài Lab serverless để biết các thực hiện cho project 1 "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/1-worklog/1.6-week6/",
	"title": "Worklog Tuần 6",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 5: Chuẩn bị proposal cho project 1 Tham gia các buổi workshop chia sẽ kiến thức Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu dịch vụ phù hợp cho project 1, ước tính các chi phí 11/08/2025 13/08/2025 https://tai-isme.github.io/workshop-template/vi/2-proposal/ 3 - Vẽ kiến trúc các dịch vụ sử dụng trong project 1 12/08/2025 13/08/2025 https://tai-isme.github.io/workshop-template/vi/2-proposal/ 4 - Vẽ kiến trúc các dịch vụ sử dụng trong project 1 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tham gia Workshop \u0026ldquo;DATA SCIENCE ON AWS\u0026quot;\n- Viết bài thu hoạch cho workshop DATA SCIENCE ON AWS\n- Tham gia workshop “Reinventing DevSecOps with AWS Generative AI”” - Viết bài thu hoạch cho workshop “Reinventing DevSecOps with AWS Generative AI 16/10/2025 16/10/2025 https://tai-isme.github.io/workshop-template/vi/4-eventparticipated/4.2-event2/ https://tai-isme.github.io/workshop-template/vi/4-eventparticipated/4.1-event1/ 6 - Chỉnh sửa lại kiến trúc sau khi nhận góp ý từ nhóm\n- Các điểm cẩm sửa:\n+ Đặt cloudfront + s3 ra ngoài region + Vẽ detail diagram cho từng flow + Đánh số cho từng bước\n+ Description từng bước + Xem lại hướng mũi của mũi tên (khi nào dùng 2 chiều - 1 chiều)\n+ Đặt Secret Manager chung 1 góc vs Guard Duty\n+ Đặt Cloudtrail gần với Cloud Watch cho monitoring nó đẹp hơn\n17/10/2025 17/10/2025 https://tai-isme.github.io/workshop-template/vi/2-proposal/ Kết quả đạt được tuần 5: Cân nhắc được các chi phí khi sử dụng các dịch vụ cho dự án. Các thành viên trong nhóm đều nắm được kiến trúc cho dự án sắp tới. Có một cái nhìn rõ ràng về các thành phần và cấu trúc hệ thống. Nắm được cách dữ liệu được lưu trữ và di chuyển trong hệ thống. Sau workshop \u0026ldquo;DATA SCIENCE ON AWS\u0026rdquo;:\nNắm được khái niệm cơ bản và phân biệt các lớp công nghệ AI/ML. Hiểu công dụng từng dịch vụ AWS phù hợp cho các tác vụ xử lý ngôn ngữ, nhận diện ảnh, chuyển giọng nói, trích xuất văn bản, recommendation. Nắm quy trình triển khai một pipeline ML điển hình (từ dữ liệu thô tới mô hình triển khai). Sau workshop \u0026ldquo;Reinventing DevSecOps with AWS Generative AI\u0026rdquo;:\nNắm được luồng tích hợp security từ giai đoạn planning đến monitoring. Cách sử dụng Amazon Q để tăng tốc phát hiện, phân tích và phản ứng với các lỗ hỏng. Biết bộ côn cụ phù hợp cho từng phase (SAST/DAST, dependency/IaC scanning, monitoring). Cách tối ưu chi phí và vận hành trên cloud bằng auto scale và các tool AWS hổ trợ. "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/1-worklog/1.7-week7/",
	"title": "Worklog Tuần 7",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 7: Học các 4 nhóm nội dung chính cho thi giữa kì Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Thiết kế kiến trúc bảo mật\n+ IAM, MFA, SCP, Encryption (KMS, TLS/ACM)\n+ Security Groups, NACLs, GuardDuty, Shield, WAF, Secret Manager 18/10/2025 22/10/2025 IAM, SCP:Viet-AWS, AWS IAM Basic, Docs, LAB 2\nMFA: LAB 1\nKMS:Viet-AWS, TLS: F5 DevCentral, ACM: AWS\nSG, NACL: Viet-AWS, AWSStudyGroup, GuarDuty: Lab 98\nShield, WAF: AWS\nSecrets Manager: AWS\nhttps://artempolynko.com/wp-content/uploads/2025/05/AWS-Solutions-Architect-Associate-Questions.pdf 3 - Thiết kế kiến trúc linh hoạt và bền vững (Resilient Architectures)\n+ Multi-AZ, Multi-Region, DR Strategies, Auto Scaling\n+ Route 53, Load Balancing, Backup \u0026amp; Restore\n- Chỉnh sửa lại 8 nội dung trong proposal, ước tính lại chi phí(tăng API GateWay, giảm DynamoDB) 18/10/2025 22/10/2025 https://www.youtube.com/watch?v=1_AR-Me9us4 https://artempolynko.com/wp-content/uploads/2025/05/AWS-Solutions-Architect-Associate-Questions.pdf 4 - Bảo mật (Secure Architectures)\n- Linh hoạt và bền vững (Resilient Architectures)\n- Hiệu năng cao (High-Performing Architectures)\n- Tối ưu chi phí (Cost-Optimized Architectures) 18/10/2025 22/10/2025 https://artempolynko.com/wp-content/uploads/2025/05/AWS-Solutions-Architect-Associate-Questions.pdf/\nhttps://d1.awsstatic.com/training-and-certification/docs/AWS_Certified_Solutions_Architect_Associate_Sample_Questions.pdf\nhttps://www.whizlabs.com/blog/aws-solutions-architect-associate-exam-questions/\nhttps://easy-prep.org/aws-solutions-architect-associate-exam-questions/full-length-practice-test 5 - Tìm hiểu SAM CLI\n- Tìm hiểu cấu trúc và cách viết file template.yaml 23/10/2025 24/10/2025 https://youtu.be/MipjLaTp5nA?si=cyGcu1VEBGHhkUi4\nhttps://youtu.be/W81ssQiBhcY?si=87QsQ6TicPSelkxo\nhttps://youtu.be/mhdX4znMd2Q?si=k6V_Hig8MDKdnqkq 6 - Tìm hiểu SAM CLI\n- Tìm hiểu cấu trúc và cách viết file template.yaml\n- Tham gia WORKSHOP “CLOUD INFRASTRUCTURE \u0026amp; OS ON AWS” 23/10/2025 24/10/2025 https://youtu.be/NDVJKz_MyFk?si=70pXCRDP7uadbYic\nhttps://youtu.be/gsE3bEPv0S0?si=AQbAz2_dK54doHhY Kết quả đạt được tuần 7: Học các kiến thức về Solution Architecture để chuẩn bị thi giữa kỳ. Biết thêm về các công nghệ Nitro System, các khái niệm, kiến thức về Container \u0026amp; Orchestration của AWS thông qua buổi workshop "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/1-worklog/1.8-week8/",
	"title": "Worklog Tuần 8",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 8: Học để thi middle Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Học qua app SAA-C03 27/10/2025 27/10/2025 https://docs.google.com/document/d/1BYGBu2KjeQgARkxTBP7dsnKu66KVhBxOv-GkmmjSOw8/edit?usp=sharing 3 - Học qua app SAA-C03 28/10/2025 28/10/2025 https://docs.google.com/document/d/1BYGBu2KjeQgARkxTBP7dsnKu66KVhBxOv-GkmmjSOw8/edit?usp=sharing 4 - Học qua app SAA-C03, giải đề(1-5) 29/10/2025 29/10/2025 https://docs.google.com/document/d/1BYGBu2KjeQgARkxTBP7dsnKu66KVhBxOv-GkmmjSOw8/edit?usp=sharing 5 - Học qua app SAA-C03, giải đề(6-10) 30/10/2025 30/10/2025 https://docs.google.com/document/d/1BYGBu2KjeQgARkxTBP7dsnKu66KVhBxOv-GkmmjSOw8/edit?usp=sharing 6 - Thi 31/10/2025 31/10/2025 Kết quả đạt được tuần 8: Kết quả thi được 27/65 "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/1-worklog/1.9-week9/",
	"title": "Worklog Tuần 9",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 9: Triển khai Identity Service với Amazon Cognito Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu cách để bắt đầu project serverless trên AWS - Nghiên cứu kiến trúc microservices với Lambda - Tìm hiểu AWS SAM CLI và cách sử dụng 03/11/2025 03/11/2025 https://youtu.be/gde38Yk5PQI?si=8uGMEhk23kzhN9GY\nhttps://youtu.be/J0aEfUUervE?si=xoF6gtLUIoBRwr3r\nhttps://youtu.be/KoY6fS77pDc?si=2vjMKXpGB6obHeKp\nhttps://youtu.be/0sgXYYJoVrA?si=sdrCQctWZAsN7jSH 3 - Học cách code Lambda functions với Java 17 - Tìm hiểu về AWS SDK for Java v2 - Nghiên cứu best practices cho serverless applications 04/11/2025 04/11/2025 https://youtu.be/9kJ83XIMa_8?si=XjWbHRWPagtKyw_D\nhttps://youtu.be/frnveY8CU3M?si=W4sQSflqgS30lb6k\nhttps://youtu.be/2m1yraouNyg?si=ntR5hsre_aozyuTT 4 - Khởi tạo project structure với SAM CLI - Thực hiện implement Identity Service: + Tạo các Lambda handlers cho authentication + Cấu hình Cognito User Pool + Thiết lập API Gateway endpoints - Tạo file template.yaml và samconfig.toml 05/11/2025 05/11/2025 5 - Implement đầy đủ các handlers cho authentication flow: + RegisterHandler, LoginHandler, LogoutHandler + VerifyEmailHandler, ResendVerificationCodeHandler + ForgotPasswordHandler, ResetPasswordHandler + ChangePasswordHandler - Tạo CognitoClient để tương tác với Cognito User Pool - Fix lỗi endpoint khi test với LocalStack 06/11/2025 06/11/2025 6 - Implement các handlers cho user profile và admin features: + GetUserProfileHandler, UpdateUserProfileHandler + AdminInviteHandler, RedeemInviteHandler + InviteEmailSenderHandler với SNS + RefreshTokenHandler - Tạo DynamoDB tables: UsersTable, InvitesTable - Implement Cognito triggers: PreSignUp, PostConfirmation, PreTokenGeneration - Debug và fix các lỗi endpoint 07/11/2025 07/11/2025 Kết quả đạt được tuần 9: Implement Identity Service với 17 Lambda handlers: luồng xác thực (đăng ký, đăng nhập, đăng xuất, xác minh email), quản lý mật khẩu (quên, đặt lại, thay đổi), hồ sơ người dùng, hệ thống mời quản trị, làm mới token, kích hoạt Cognito.\nTích hợp Amazon Cognito User Pool, trình ủy quyền API Gateway, bảng DynamoDB, SNS cho thông báo email.\nXây dựng cấu trúc dự án đa module.\n"
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/2-proposal/",
	"title": "Bản đề xuất",
	"tags": [],
	"description": "",
	"content": "Teaching Center Management System Giải pháp AWS Serverless cho dự án quản lý trung tâm dạy học Proposal Word template: proposal-template.docx\n1. Tóm tắt điều hành Dự án tập trung triển khai nền tảng LMS (Learning Management System) phục vụ nghiệp vụ đào tạo cốt lõi, tương đương phạm vi sử dụng của hệ thống tương tự như lms-hcmuni.fpt.edu.vn. Cụ thể, phạm vi bao gồm 2 phần: quản lý học vụ và xác thực/định danh và phân quyền.\nMục tiêu là cung cấp các khả năng LMS trọng yếu: quản lý môn học và lớp học; lịch học; tìm kiếm và ghi danh bằng mã enrollKey; dashboard theo vai trò (Admin, Teacher, Student); quản lý hồ sơ giảng viên/học viên; quản lý tài liệu môn học trên S3 (tạo thư mục, upload, tải xuống có kiểm tra ghi danh); và luồng import dữ liệu hàng loạt từ Excel để khởi tạo nhanh dữ liệu học thuật ban đầu. Phần xác thực/định danh và phân quyền bảo đảm đăng nhập/xác thực với Amazon Cognito (hỗ trợ OAuth/Google), lời mời tham gia (invite/redeem), cấp/đổi mật khẩu, làm mới token, hồ sơ người dùng, cùng cơ chế phân quyền theo vai trò để bảo vệ tài nguyên học vụ.\nTrong tương lai, hệ thống có thể mở rộng dần sang các module khác (CRM, thanh toán, HRM…) và cân nhắc tích hợp AI/IoT khi cần, nhưng không thuộc phạm vi triển khai hiện tại.\n2. Tuyên bố vấn đề Vấn đề hiện tại\nỞ bối cảnh LMS, nhiều đơn vị đào tạo đang vận hành rời rạc các bước: tạo môn học/lớp học, công bố lịch, ghi danh học viên, quản lý tài liệu, và truy cập hồ sơ — thường trải qua nhiều công cụ khác nhau. Điều này dẫn đến dữ liệu phân mảnh, khó kiểm soát quyền truy cập, quy trình ghi danh thủ công (dễ sai) và trải nghiệm người dùng không nhất quán giữa giảng viên và học viên.\nKhi số lượng môn/lớp tăng, thiếu một cơ chế phân quyền thống nhất theo vai trò, xác thực tin cậy (SSO/OAuth), và các API học vụ rõ ràng để phục vụ dashboard theo vai trò. Việc thiếu kênh import dữ liệu hàng loạt cũng gây chậm trễ khi khởi tạo học kỳ mới.\nGiải pháp\nNền tảng được triển khai trên kiến trúc AWS Serverless, tập trung giải quyết hai trụ cột:\nPhần xác thực/định danh và phân quyền: Amazon Cognito cho xác thực (email/password, Google OAuth), lời mời (invite/redeem), đặt lại/đổi mật khẩu, refresh token, hồ sơ người dùng; cấp quyền theo vai trò (ADMIN/TEACHER/STUDENT) để bảo vệ API và tài nguyên học vụ. Phần học vụ: API quản lý môn học/lớp học, tìm kiếm hợp nhất, ghi danh bằng enrollKey (kích hoạt PRE_ENROLLED → ACTIVE), dashboard theo vai trò, hồ sơ giảng viên/học viên, và quản lý tài liệu môn học trên S3 (tạo thư mục, presigned upload/download có kiểm tra ghi danh). Hỗ trợ import Excel để khởi tạo dữ liệu nhanh và rollback toàn phần khi lỗi. Luồng truy cập: CloudFront → S3 (nội dung tĩnh) và API Gateway → Lambda → DynamoDB (dữ liệu học vụ/định danh) với CloudWatch/SNS/Secrets Manager cho giám sát và bảo mật. CI/CD được thực hiện qua GitLab Runner kết hợp AWS SAM CLI.\nLợi ích và hoàn vốn đầu tư (ROI)\nTăng tốc độ phát triển và triển khai: CI/CD tự động với GitLab Runner và CloudFormation giúp giảm thời gian phát hành tính năng mới từ vài ngày xuống còn vài giờ. Tối ưu chi phí vận hành: Kiến trúc Serverless (Lambda, DynamoDB, API Gateway) chỉ tính phí khi có request, tiết kiệm 40–60% chi phí so với EC2 truyền thống. Bảo mật toàn diện: Secrets Manager và Cognito kết hợp IAM giúp bảo vệ dữ liệu nhạy cảm và kiểm soát truy cập chặt chẽ. Hiệu suất truy cập cao: CloudFront CDN giúp tăng tốc độ truy cập và giảm độ trễ 50–70%. Khả năng mở rộng linh hoạt: Hệ thống tự động mở rộng theo lưu lượng, không cần can thiệp thủ công. Giám sát chủ động: CloudWatch + SNS cung cấp cảnh báo real-time, giúp đội ngũ kỹ thuật xử lý sự cố kịp thời. 3. Kiến trúc giải pháp Mô tả chi tiết User Request Flow\nNgười dùng mở trình duyệt và truy cập ứng dụng thông qua tên miền. Amazon CloudFront nhận request: Kiểm tra cache để trả nội dung tĩnh (HTML/CSS/JS) từ S3 nếu có. Nếu nội dung chưa có trong cache, CloudFront fetch từ S3, trả lại cho user với độ trễ thấp. User nhận được frontend và tương tác với giao diện, phát sinh các request API. Authentication \u0026amp; API Handling\nKhi user đăng nhập: Amazon Cognito xác thực thông tin đăng nhập (username/password hoặc OAuth). Cognito tạo JWT token và trả về client. Frontend gửi request API kèm token JWT tới API Gateway. API Gateway thực hiện: Kiểm tra JWT token với Cognito. Nếu token hợp lệ, request được chuyển tới Lambda function tương ứng. Nếu token không hợp lệ, API Gateway trả về lỗi 401 Unauthorized. Lambda Processing \u0026amp; Data Access\nAWS Lambda thực thi logic nghiệp vụ: Quản lý học viên, điểm danh, đăng ký khóa học, cập nhật kết quả, lịch học… Khi cần truy cập thông tin nhạy cảm (API key, mật khẩu DB), Lambda gọi AWS Secrets Manager. Lambda đọc/ghi dữ liệu vào Amazon DynamoDB: DynamoDB lưu dữ liệu theo mô hình NoSQL, tối ưu read/write, tự động mở rộng khi lưu lượng tăng. Hỗ trợ truy vấn theo khóa chính (PK) hoặc secondary index (GSI). Lambda ghi log về CloudWatch Logs, bao gồm: request, error, execution metrics. Security \u0026amp; Access Control\nAmazon Cognito: xác thực người dùng và quản lý phiên làm việc, hỗ trợ OAuth/Google Sign-In. IAM Roles \u0026amp; Policies: kiểm soát quyền truy cập giữa các dịch vụ AWS (Lambda, DynamoDB, S3). API Gateway Authorization: xác thực JWT token từ Cognito trước khi cho phép truy cập Lambda. Secrets Manager: bảo vệ thông tin nhạy cảm (API keys, database credentials), cho phép Lambda truy cập an toàn. Monitoring \u0026amp; Alerts\nCloudWatch Logs thu thập logs từ Lambda và API Gateway. Metrics \u0026amp; Alarms: Tạo metrics từ logs (CPU, error rate, latency, request count). Cấu hình CloudWatch Alarms, khi vượt ngưỡng, kích hoạt alert. Amazon SNS gửi cảnh báo real-time đến team vận hành qua email hoặc endpoint HTTP/SMS. Kết hợp CloudTrail + CloudWatch để audit hành động API và bảo mật tổng thể. CI/CD \u0026amp; Deployment\nGitLab: lưu trữ source code và quản lý version control. GitLab Runner: Tự động trigger khi có code push hoặc merge request. Chạy CI/CD pipeline với các stage: test, build, deploy. Cài đặt dependencies và chạy unit test. Build artifact (ZIP package cho Lambda). AWS SAM CLI / CloudFormation: GitLab Runner sử dụng AWS SAM CLI để deploy. Triển khai hoặc cập nhật toàn bộ hạ tầng AWS (API Gateway, Lambda, DynamoDB, S3, IAM Role). Đảm bảo hạ tầng theo mô hình IaC, nhất quán giữa môi trường Dev/Prod. CI/CD tự động, giảm lỗi, rút ngắn thời gian triển khai. Summary\nRequest Path: User → CloudFront → API Gateway → Lambda (via Cognito Auth) → DynamoDB → Lambda → API Gateway → CloudFront → User. Security Path: Cognito Authentication → API Gateway Authorization → IAM Policies → Secrets Manager. Monitoring: CloudWatch Logs \u0026amp; Metrics → Alarms → SNS. CI/CD Path: GitLab → GitLab Runner → AWS SAM CLI → CloudFormation → AWS Resources. Dịch vụ AWS sử dụng Services Description Frontend \u0026amp; CDN CloudFront, S3 Phân phối nội dung, lưu trữ tĩnh Backend \u0026amp; Logic API Gateway, Lambda, DynamoDB, Secrets Manager, Cognito Serverless logic, dữ liệu, xác thực Monitoring CloudWatch Logs, CloudWatch Alarms, CloudWatch Metrics, SNS Giám sát, cảnh báo, thu thập metrics CI/CD \u0026amp; IaC CloudFormation, SAM Triển khai tự động và quản lý cơ sở hạ tầng (kết hợp GitLab Runner) 4. Triển khai kỹ thuật Các giai đoạn triển khai\nGiai đoạn phát triển (Development) Hoàn thiện các logic nghiệp vụ và main flow cho các hàm Lambda. Viết file template.yaml mô tả tài nguyên: API Gateway, Lambda Functions, DynamoDB, Cognito. Sử dụng AWS SAM CLI triển khai mã và template.yaml lên LocalStack để kiểm thử cục bộ. Giai đoạn deploy: Dùng AWS SAM CLI để triển khai mã và template.yaml lên môi trường AWS thật. Cấu hình GitLab CI/CD với GitLab Runner để tự động hóa quy trình build và deploy. Yêu cầu kỹ thuật\nCó tài khoản AWS sử dụng Free Tier triển khai và sử dụng các tài nguyên bình thường. File template.yaml phải được cấu hình chính xác để mô tả đầy đủ các dịch vụ. Hệ thống cần có cơ chế rollback tự động khi xảy ra lỗi triển khai. 5. Lộ trình \u0026amp; Mốc triển khai Trước thực tập (Tuần 0): Học các dịch vụ AWS để chuẩn bị cho project. Khảo sát, phân tích yêu cầu và các bộ phận liên quan của các trung tâm thật (Nhân sự, Đào tạo, Tuyển sinh). Thực tập (Tuần 1-12): Tuần 1–3: Thiết kế hệ thống, giao diện, kiến trúc tổng thể và chuẩn bị tài liệu (proposal, diagram, template SAM). Tuần 4–8: Phát triển các module cốt lõi (quản lý học viên, giảng viên, lớp học, xác thực người dùng). Kiểm thử cục bộ bằng LocalStack. Tuần 9–11: Tích hợp các module, hoàn thiện CI/CD pipeline, triển khai hệ thống lên môi trường AWS thật. Tuần 12: Kiểm thử tổng thể, đánh giá kết quả, hoàn thiện báo cáo và đề xuất hướng phát triển tiếp theo. Sau thực tập (Định hướng mở rộng – Tuần 12 về sau): Nâng cấp hệ thống, tối ưu hiệu năng, và tích hợp công nghệ AI (phân tích học tập cá nhân hóa) cùng IoT (quản lý lớp học thông minh). 6. Ước tính ngân sách Có thể xem chi phí trên AWS Pricing Calculator\nHoặc tải tệp ước tính ngân sách pdf | csv | json\nChi phí hạ tầng\nS3 Standard: 0.32 USD/tháng (10 GB, 5.000 PUT requests, 100.000 GET requests). CloudFront: 1.33 USD/tháng (10 GB, Data transfer out to origin 0.1 GB, Number of requests (HTTPS) 100.000). Amazon API Gateway: 0.38 USD/tháng (300.000 request). AWS Lambda Function - Include Free Tier: 0.00 USD/tháng (400.000 request, 512 MB lưu trữ). Amazon DynamoDB: 0.62 USD/tháng (Data storage 2 GB, 50.000 Write/, 200.000 Read) Amazon Cognito Lite Tier: 0.00 USD/tháng (500 MAUs) Amazon CloudWatch: 2.10 USD/tháng (3 custom metric, Log 1GB, 1 dashboard, 2 alarms) AWS Secrets Manager: 0.40 USD/tháng (1 secret) Amazon SNS: 0.00 USD/tháng (1M request, 1M lambda deliveries) AWS CloudFormation: 0.00 USD/tháng GitLab Runner: 0.00 USD/tháng (self-hosted hoặc GitLab Free Tier) Tổng: 5.15 USD/tháng, 61.80 USD/12 tháng\n7. Đánh giá rủi ro Ma trận rủi ro\nLỗi cấu hình AWS (IAM, Lambda, API Gateway, Cognito): Ảnh hưởng cao, xác suất trung bình Quá giới hạn Free Tier AWS: Ảnh hưởng trung bình, xác suất thấp. Mất dữ liệu trên S3/DynamoDB: Ảnh hưởng cao, xác suất thấp. Lỗi tích hợp giữa các dịch vụ AWS: Ảnh hưởng trung bình, xác suất thấp. Tấn công từ bên ngoài (SQL injection, XSS, unauthorized access): Ảnh hưởng cao, xác suất thấp đến trung bình Chiến lược giảm thiểu\nCấu hình AWS: Kiểm tra kỹ file template.yaml, thử triển khai trên LocalStack trước khi deploy thật. Vượt giới hạn Free Tier: Theo dõi chi phí thường xuyên, thiết lập cảnh báo chi tiêu (Billing Alert), tối ưu tài nguyên. Mất dữ liệu: Bật S3 Versioning, sao lưu định kỳ dữ liệu DynamoDB. Lỗi tích hợp dịch vụ: Đảm bảo các dịch vụ hoạt động cùng Region, kiểm tra IAM Role và quyền truy cập chéo giữa các service. Bảo mật ứng dụng: Validate input ở Lambda layer, sử dụng Cognito để xác thực chặt chẽ, cấu hình CORS đúng cách trên API Gateway, áp dụng principle of least privilege cho IAM roles, bật CloudWatch và API Gateway logging để audit Kế hoạch dự phòng\nKhi gặp lỗi deploy: rollback bằng AWS SAM CLI hoặc khôi phục version Lambda trước đó qua CloudFormation stack. Khi vượt ngân sách: tạm dừng các dịch vụ không thiết yếu, tối ưu lại kiến trúc và tài nguyên sử dụng. Khi có sự cố bảo mật: rà soát log CloudWatch, vô hiệu hóa user/token bị compromised qua Cognito, review IAM permissions, cách ly Lambda function bị ảnh hưởng 8. Kết quả kỳ vọng Hệ thống quản lý trung tâm dạy học được triển khai thành công trên nền tảng AWS Serverless, đảm bảo hoạt động ổn định, bảo mật, dễ mở rộng. Tối ưu chi phí vận hành nhờ tận dụng AWS Free Tier và kiến trúc serverless, giảm chi phí đầu tư hạ tầng ban đầu. Đảm bảo hiệu suất truy cập cao, thời gian phản hồi nhanh và khả năng mở rộng linh hoạt. Đảm bảo an toàn dữ liệu với các cơ chế backup, versioning, và kiểm soát truy cập chặt chẽ. Tích hợp CI/CD giúp tự động hóa triển khai, kiểm thử và rollback, đảm bảo quy trình phát triển hiệu quả và đáng tin cậy. "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/5-workshop/5.2-prerequisites/",
	"title": "Các bước chuẩn bị",
	"tags": [],
	"description": "",
	"content": "Yêu Cầu Môi Trường Để hoàn thành workshop này, chúng ta cần chuẩn bị.\nAWS Account:\nTài khoản AWS có thể sử dụng Free Tier IAM user có quyền với các services: AWS CloudFormation AWS Lambda Amazon API Gateway Amazon S3 Amazon DynamoDB Amazon Cognito CloudWatch Logs Tạo AWS Access Key (Giả sử bạn đã có IAM User)\nĐăng nhập vào AWS Tìm và chọn dịch vụ IAM Chọn mục Users ở menu bên trái để xem danh sách các IAM User Tìm và chọn người dùng mà bạn đã tạo trước đó Tìm đến mục Security Credentials Chọn Create Access Key để tạo một khóa truy cập mới Chọn CLI và tick Confirmation Giữ Access key và Secret key an toàn và không chia sẻ cho người khác. AWS CLI:\nHướng dẫn cài đặt\nKiểm tra phiên bản\naws --version AWS SAM CLI:\nHướng dẫn cài đặt\nKiểm tra phiên bản\nsam --version Cấu Hình AWS CLI Cấu hình credentials\naws configure Điền Access key và Secret key:\nLưu ý: Không để lộ Access Key/Secret Key\nClone Workshop Repo Clone từ Git\ngit clone https://github.com/Tai-isme/fcj-workshop-s3-notifications cd fcj-workshop-s3-notifications Download ZIP\nfcj-workshop-s3-notifications.zip Cấu trúc thư mục\n📦fcj-workshop-s3-notifications ┣ 📂excel-import-frontend ┃ ┣ 📂src ┃ ┣ 📜package.json ┃ ┗ 📜vite.config.js ┗ 📂excel-import-workshop ┃ ┣ 📂src ┃ ┣ 📜pom.xml ┃ ┗ 📜template.yaml "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch \u0026ldquo;DATA SCIENCE ON AWS\u0026rdquo; Mục Đích Của Sự Kiện Khám phá hành trình xây dựng một hệ thống Data Science hiện đại\nDanh Sách Diễn Giả Văn Hoàng Kha – Cloud Solutions Architect, AWS Community Builder\nBạch Doãn Vương – Cloud DevOps Engineer, AWS Community Builder\nNội Dung Nổi Bật Giới thiệu về AI và các khái niệm (Anh Kha) Trí tuệ nhân tạo (AI): Đóng vai trò như 1 trợ lý ảo, là một công nghệ/kỹ thuật có khả năng học hỏi giống con người. Học từ các dữ liệu có sẵn, học từ các dữ liệu mới chưa từng được học qua với tốc độ rất nhanh (nhưng không nhanh bằng tốc độ suy nghĩ của con người). Máy học (Machine Learning): Là một phương pháp để thực hiện AI, máy tính sẽ học hỏi dựa trên một lượng dữ liệu lớn dạng chữ, đơn giản để đưa ra dự đoán. Học sâu (Deep Learning): Học sâu là học chia thành nhiều lớp/tầng học các dữ liệu phức tạp, đa dạng từ nhiều mãng khác nhau và kết nối như 1 mạng nơ ron thần kinh trong não con người. AI tạo sinh (Generative AI): Học từ những mô hình ngôn ngữ/mô hình dữ liệu cực kì lớn chỉ có ở các hãng lớn (VD: Dữ liệu được Google thu tập từ hàng chục năm thông qua những kết quả tìm kiếm của người dùng trên Google -\u0026gt; ra đời một hình ngôn ngữ lớn (Gen-AI)). Generative AI hay hơn ML và DL là có thể tự sáng tạo như sáng tác thơ, tạo ảnh, video. (VD: Gemini từ Google, Bedrock từ AWS, \u0026hellip;) AI/ML trên nền tảng AWS (Anh Kha) AWS phát triển hơn 200 dịch vụ và hơn 10,000 tính năng. Về lịch sử: AWS sử dụng các dịch vụ mình phát triển cho chính hệ thống của mình sau đó mới bán ra thị thường Sau khi bán ra thị thường thì thu thập phản hồi, yêu cầu từ khách hàng và phát triển thêm các dịch vụ, tính năng theo phản hồi, yêu cầu của khách hàng Các dịch vụ của AWS được chia làm 3 tầng: Tầng trên (Dịch vụ AI): Các dạng phần mềm phục vụ được tất cả các bài toán ở hiện tại. Xử lý hình ảnh, âm thanh, chuyển chữ thành giọng nói (và ngược lại), trích xuất văn bản từ các file văn bản. Các dịch vụ cho phép người dùng sử dụng API để tự phát triển. Tầng giữa (Dịch vụ ML): Dành cho người dùng muốn tự quản lý, tự chuẩn bị dữ liệu, tự xử lý dữ liệu, tự training cho máy học, tự tinh chỉnh mô hình. Dịch vụ để training có thể sử dụng là Amazon SageMaker, dịch vụ tương tự như Google Colab. Tầng dưới (ML Frameworks và hạ tầng): AWS cung cấp các phần cứng, hạ tầng mạnh mẽ để training các mô hình lớn, hợp tác với các nhà cung cấp như NVIDIA. Các dịch vụ AI của AWS (Anh Kha) Amazon Comprehend: Xử lý ngôn ngữ tự nhiên sử dụng công nghệ máy học để tìm ý nghĩa và thông tin chi tiết trong văn bản. Amazon Translate: Là dịch vụ dịch, sử dụng Deep Learning để cung cấp bản dịch chính xác và tự nhiên hơn các thuật toán truyền thống. Amazon Transcribe: Nhận dạng giọng nói để chuyển giọng nói thành văn bản. Amazon Polly: Tạo ra giọng nói theo yêu cầu, chuyển văn bản thành giọng nói. Amazon Textract: Nhận dạng văn bản, sử dụng Machine Learning để trích xuất các văn bản, chữ viết tay và dữ liệu từ tài liệu được quét. Amazon Rekognition: Là dịch vụ nhận diện đối tượng, khuôn mặt, nhận diện qua video, kiểm duyệt nội dung phim, các tình huống thể thao (VD: Check var trong bóng đá). Amazon Personalize: Giúp xây dựng hệ thống gợi ý (recommendation) sản phẩm, phim ảnh dựa trên hành vi của người dùng, tương tự như cách Netflix hay YouTube đề xuất nội dung. Quy trình xây dựng mô hình Machine Learning (Anh Kha) Feature Engineering: Là quá trình chuẩn bị dữ liệu, làm sạch dữ liệu, chuyển dữ liệu về ngôn ngữ máy để cho máy có thể hiểu được.\nHuấn luyện mô hình: Dùng dữ liệu đã chuẩn bị để dạy cho máy học.\nTinh chỉnh và Đánh giá: Kiểm tra độ chính xác của model. Nếu chưa chính xác thì phải quay lại bước chuẩn bị, xử lý lại dữ liệu.\nTriển khai mô hình: Cho phép người dùng cuối có thể sử dụng thử.\nTheo dõi: Sau quá trình dùng thử, thu thập phản hồi của người dùng, từ đó re-change lại dữ liệu để tăng độ chính xác của mô hình.\nTraining model sử dụng Amazon SageMaker Canvas: Sau khi training xong thì có thể triển khai lên tự động, không cần viết code mà chỉ cần kéo thả.\nPhần demo (Anh Vương) Processing and cleaning data from the IMDb dataset with AWS Glue: Tải dữ liệu thô lên S3. Sử dụng AWS Glue để thực hiện các tác vụ làm sạch tự động. Dữ liệu sau khi đã được làm sạch sẽ được lưu lại vào S3, sẵn sàng cho việc huấn luyện mô hình trên Amazon SageMaker. So sánh chi phí và hiệu năng: Cloud vs On-Premise: Cloud giúp giảm chi phí đầu tư hạ tầng, tối ưu hóa chi phí vận hành nhờ mô hình trả phí theo dung lượng sử dụng. Cloud cho phép scale tài nguyên nhanh chóng. Linh hoạt và nhanh chóng thử nghiệm nhiều mô hình khác nhau và không bị giới hạn phần cứng. "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/5-workshop/5.4-deploy-backend/5.4.2-sam-deploy/",
	"title": "SAM Deploy",
	"tags": [],
	"description": "",
	"content": "Deploy với AWS SAM SAM CLI sẽ package code và deploy toàn bộ infrastructure lên AWS thông qua CloudFormation.\nDeploy Có 2 cách deploy ứng dụng bằng SAM:\nCách 1 — Tự tạo S3 Bucket aws s3 mb s3://demo-workshop-be-\u0026lt;YOUR-ID-ACCOUNT\u0026gt; --region ap-southeast-1 sam deploy --s3-bucket \u0026lt;tên-bucket-vừa-tạo\u0026gt; --stack-name \u0026lt;tên-stack\u0026gt; --region ap-southeast-1 Cách 2 — Sử dụng --guided (khuyến nghị cho lần đầu) sam deploy --guided Để đơn giản và tránh phải tạo bucket thủ công, chúng ta sẽ sử dụng Cách 2. --guided sẽ hỏi các tham số (stack name, region, permissions, v.v.) rồi lưu cấu hình vào samconfig.toml để lần sau chỉ cần chạy sam deploy.\nSAM sẽ hỏi một số câu hỏi hướng dẫn Khi chạy sam deploy --guided, SAM sẽ hỏi một số tham số để cấu hình (ví dụ):\nStack Name [excel-import-workshop]: Nhập tên stack (hoặc để trống để dùng tên project hiện tại). AWS Region [ap-southeast-1]: Nhập Region (hoặc để trống để dùng ap-southeast-1). Parameter Environment [dev]: Nhập environment (mặc định là dev nếu để trống). Confirm changes before deploy [y/N]: Nhập y để xem lại thay đổi trước khi deploy. Allow SAM CLI IAM role creation [y/N]: Nhập y để cho phép SAM tạo IAM roles cho Lambda. Disable rollback [y/N]: Nhập n để bật rollback nếu deploy thất bại (khuyến nghị n). Save arguments to configuration file [y/N]: Nhập y để lưu cấu hình vào samconfig.toml (để lần sau chỉ cần chạy sam deploy). Nếu chọn y, SAM sẽ tiếp tục hỏi tên file cấu hình (mặc định là samconfig.toml) và môi trường:\nSAM configuration file [samconfig.toml]: samconfig.toml SAM configuration environment [default]: default Trong ví dụ này mình chọn n để không lưu cấu hình.\nQuá Trình Deploy Preparing CloudFormation\nCloudFormation Change Set\nSAM sẽ hiển thị danh sách resources sẽ được tạo:\nConfirm deploy: Nhập: y để deploy\nCloudFormation Execution\nCloudFormation Execution Success\nNếu đã deploy một lần với --guided và chọn y ở save configuration file: Thì lần deploy tiếp theo chỉ cần:\nsam build sam deploy SAM sẽ đọc config từ samconfig.toml.\nKiểm Tra Resources đã tạo Kiểm Tra CloudFormation Stack Mở CloudFormation Console Tìm stack excel-import-workshop Status stack phải là: CREATE_COMPLETE Kiểm tra Lambda Mở Lambda Console Chọn Functions Kiểm tra API Gateway Mở API Gateway Console Chọn api Kiểm tra S3 Bucket Mở S3 Console Chọn Bucket workshop-excel-imports Kiểm tra User pool Mở Cognito Console Chọn ExcelWorkshopUsers Các resource đã được deploy thành công và đầy đủ.\n"
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/1-worklog/1.10-week10/",
	"title": "Worklog Tuần 10",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 10: Deploy Identity Service lên AWS *Triển khai Academic Service với Teacher và Student Management Setup hạ tầng monitoring với CloudWatch và SNS Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Sửa lỗi và deploy Identity Service lên AWS\n- Kiểm tra resources trên AWS Console: Lambda, API Gateway, DynamoDB, Cognito 10/11/2025 10/11/2025 3 - Test Identity Service\n- Setup CloudWatch Logs cho tất cả Lambda functions - Tạo monitoring-alarms.yaml cho Identity Service 11/11/2025 11/11/2025 4 - Triển khai Academic Service\n- Tạo template-academic.yaml với resources cơ bản - Setup shared module cho common utilities 12/11/2025 12/11/2025 5 - Implement CRUD Teacher Management\n- Tạo TeacherRepository và TeachersTable 13/11/2025 13/11/2025 6 - Implement Student Management 14/11/2025 14/11/2025 Kết quả đạt được tuần 10: Hoàn thiện và deploy thành công Identity Service với 17 Lambda handlers: Authentication: Register, Login, Logout, Verify Email, Resend Verification Password: Forgot, Reset, Change Password Profile: Get, Update User Profile Admin: Invite users, Send email via SNS, Redeem invites Token: Refresh token mechanism Triggers: PreSignUp, PostConfirmation, PreTokenGeneration JWT token generation và validation hoàn chỉnh "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/1-worklog/1.11-week11/",
	"title": "Worklog Tuần 11",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 11: Thêm tính năng Import Data từ Excel cho Academic Service Deploy Academic Service lên AWS Thiết lập CI/CD pipeline hoàn chỉnh với GitLab Runner Setup CloudWatch monitoring và SNS alerting cho toàn bộ hệ thống Hoàn thiện Infrastructure as Code với AWS SAM Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Thiết kế và implement Import Data feature: + Tạo S3 bucket để upload Excel files + Implement GenerateImportUploadUrlHandler (tạo presigned URL) + Implement ImportS3TriggerHandler (trigger khi có file mới) + Sử dụng Apache POI library để parse Excel - Tạo ImportJobsTable để track import status - Design import data schema cho Teachers và Students 17/11/2025 17/11/2025 3 - Hoàn thiện Import Data handlers: + Implement GetImportJobStatusHandler (check trạng thái) + Implement ListImportJobsHandler (xem lịch sử) + Parse Excel và validate data format 18/11/2025 18/11/2025 4 - Deploy Academic Service lên AWS\n- Test Teacher/Student CRUD functions\n- Test Import Data flow 19/11/2025 19/11/2025 5 - Thiết lập CI/CD pipeline với GitLab: + Tạo file .gitlab-ci.yml với stages: build, test, deploy + Cấu hình GitLab OIDC để authenticate với AWS + Setup GitLab Runner (sử dụng Docker image) + Jobs: build:be:identity, build:be:academic + Jobs: test:be:identity, test:be:academic + Jobs: deploy:be:identity:dev, deploy:be:academic:dev - Cấu hình artifacts và caching - Commit code để trigger CI/CD pipeline 20/11/2025 20/11/2025 6 - Setup CloudWatch monitoring : + Tạo monitoring-alarms.yaml cho Identity và Academic services + Cấu hình alarms cho Lambda + Cấu hình alarms cho API Gateway\n+ Cấu hình alarms cho DynamoDB\n- Setup SNS topic và subcribe để nhận email: tcm-pipeline-notifications 21/11/2025 21/11/2025 Kết quả đạt được tuần 11: Thiết lập thành công CI/CD pipeline với GitLab:\nFile .gitlab-ci.yml với workflow rules và stages rõ ràng Xác thực OIDC GitLab với AWS (không cần Access Keys) Các job song song cho Identity và Academic services Giai đoạn build: Maven clean install, SAM build, SAM package Giai đoạn test: JUnit tests với Mockito, coverage reports Giai đoạn deploy: SAM deploy với samconfig.toml Lưu trữ artifacts để tăng tốc build (Maven .m2 repository) Triển khai theo môi trường cụ thể: dev, staging, prod Cổng phê duyệt thủ công cho production deployments Thiết lập monitoring và alerting toàn diện với CloudWatch:\nTạo monitoring-alarms.yaml cho cả Identity và Academic services Cảnh báo Lambda: Lỗi \u0026gt; 5%, Thời gian thực thi \u0026gt; p99, Throttles, Số lượng thực thi đồng thời Cảnh báo API Gateway: Lỗi client 4XX, Lỗi server 5XX, Độ trễ Cảnh báo DynamoDB: Throttles đọc/ghi, Dung lượng tiêu thụ Chủ đề SNS: tcm-pipeline-notifications để gửi cảnh báo Đăng ký email để nhận thông báo real-time Bảng điều khiển CloudWatch để trực quan hóa metrics (có thể thêm sau) Chính sách lưu trữ 30 ngày để tối ưu chi phí "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/1-worklog/1.12-week12/",
	"title": "Worklog Tuần 12",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 12: Test và debug toàn bộ hệ thống (Identity + Academic Services) Viết Workshop documentation đầy đủ Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Test end-to-end toàn bộ Identity Service\n- Fix bugs phát hiện trong quá trình test 24/11/2025 24/11/2025 3 - Test end-to-end Academic Service\n- Fix bugs phát hiện trong quá trình test 25/11/2025 25/11/2025 4 - Test CI/CD pipeline end-to-end: + Push code changes và verify automatic build/test + Verify artifacts được cache đúng cách + Test parallel jobs cho Identity và Academic\n- Fix bugs phát hiện trong quá trình test 26/11/2025 26/11/2025 5 - Viết Workshop documentation 27/11/2025 27/11/2025 6 28/11/2025 28/11/2025 Kết quả đạt được tuần 12: "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": "Blog 1 - Tối ưu hóa quy trình làm việc HPC với các cụm tự động mở rộng trong Ansys Gateway vận hành bởi AWS Bài blog giới thiệu Ansys Gateway powered by AWS, giải pháp HPC trên nền tảng AWS, cho phép tự động mở rộng tài nguyên tính toán theo nhu cầu mô phỏng kỹ thuật. Bài viết trình bày kiến trúc, quy trình tạo và quản lý cụm HPC, tích hợp các dịch vụ lưu trữ như EFS, FSx for Lustre/OpenZFS, và sử dụng AWS ParallelCluster cùng Slurm để tự động cấp phát/nhả node. Người dùng có thể tối ưu chi phí, tăng hiệu quả mô phỏng với workflow linh hoạt, phù hợp cả cho các ứng dụng Ansys lớn cần hiệu năng cao.\nBlog 2 - Hiện đại hóa hạ tầng Kubernetes của Snowflake Corporate với Bottlerocket và Karpenter Bài blog này trình bày về quá trình hiện đại hóa hạ tầng Kubernetes của Snowflake Corporate bằng cách chuyển đổi từ Amazon Linux 2 sang Bottlerocket – hệ điều hành tối ưu cho container và sử dụng Karpenter để tự động hoá mở rộng node. Quá trình di chuyển được thực hiện theo từng giai đoạn để đảm bảo không gián đoạn dịch vụ, mang lại lợi ích về bảo mật, hiệu năng (tăng tốc khởi động node, giảm thời gian sẵn sàng của pod), giảm tải vận hành và tiết kiệm chi phí. Bài viết tổng kết các bài học thực tiễn và khuyến nghị cho doanh nghiệp khi vận hành EKS ở quy mô lớn.\nBlog 3 - Di chuyển liền mạch: Chuyển đổi bảo mật các đội thiết bị IoT lớn sang AWS Bài blog này mô tả chiến lược và các bước cụ thể để di chuyển quy mô lớn các hệ thống IoT lên AWS IoT Core. Blog tập trung vào các thách thức khi dùng broker tự quản, như chi phí cao, khó mở rộng, bảo mật và đổi mới chậm. AWS IoT Core cung cấp nhiều tính năng hỗ trợ việc chuyển đổi mượt mà mà không cần cập nhật thiết bị, tương thích đa giao thức, xác thực mạnh và khả năng mở rộng lớn. Quy trình di chuyển gồm các pha: chuẩn bị, chuyển backend, chuyển thiết bị và dọn dẹp, giúp giảm rủi ro và đảm bảo liên tục hệ thống khi chuyển sang nền tảng cloud hiện đại.\nBlog 4 - \u0026hellip; Blog 5 - \u0026hellip; Blog 6 - \u0026hellip; "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/4-eventparticipated/4.3-event3/",
	"title": "Event 3",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch \u0026ldquo;[GAPV] Introduction to AI/ML GenAI with AWS\u0026rdquo; Mục Đích Của Sự Kiện Chia sẻ các khái niệm cốt lõi trong AI, Machine Learning, Deep Learning và LLM Chia sẻ về vai trò của AWS trong việc hỗ trợ và tối ưu hóa các công nghệ này Danh Sách Diễn Giả Phạm Nguyễn Hải Anh - Cloud Engineer\nNội Dung Nổi Bật Các khái niệm ML, Deep Learning, LLM được chia sẻ theo hướng tiến hóa, migrate phiên bản sau so với phiên bản trước. AWS tự sản xuất ra Graviton Processor trải qua bốn thế hệ, các thế hệ sau hiệu suất cao hơn trước đồng nghĩa với việc chi phí sẽ cao hơn. Với Graviton này thì sẽ ưu tiên sử dụng cho các quá trình inference. Các trường hợp sử dụng Graviton Processor phù hợp: Có thể sinh ra text với các mô hình lên tới 70 tỷ tham số. Chuẩn bị và xử lý dữ liệu. Kỹ thuật Retrieval Augmented Generation (RAG). Deep Learning, GPU và các yếu tố ảnh hưởng tới chi phí và thời gian: Chi phí của instance trong 1 đơn vị thời gian, thời gian huấn luyện (phụ thuộc vào số lượng parameter của model). Số lượng mẫu trong dataset. Sức mạnh tính toán của tài nguyên sử dụng. Các thách thức trong inference: Độ trễ khi model sinh ra văn bản, tốc độ gửi văn bản. Chi phí để host instance. AWS kết hợp với NVIDIA tạo ra các CPU P5, P4 dành cho training và G6, G5 dành cho inference. AWS AI Chips do AWS tự sản xuất như Inferentia 2 và Trainium 2 phục vụ cho training và inference. Các dịch vụ AI của AWS Amazon Rekognition (Xử lý Ảnh/Video)\nPain point: quá trình đầu tư đắt đỏ, quá trình xử lý phức tạp, tốc độ phát triển nhanh chóng và kham hiếm nguồn lực về ML. Cách giải quyết của Amazon Rekognition là cung cấp khả năng quản lý đơn giản hơn theo hướng no-code/low-code, xây dựng nhanh chóng thông qua SDK/API, đưa ra kết quả chất lượng cao, không cần hỗ trợ của chuyên gia AI, cho phép custom dễ dàng. Các dịch vụ chính: Content moderation: Quản lý nội dung, phát hiện nội dung tiêu cực. Face Liveness: Chống giả mạo khuôn mặt. Face detection and analysis: Nhận biết giới tính, tuổi tác, cảm xúc trên khuôn mặt. Face search: Nhận diện khuôn mặt trong tập dữ liệu lớn (lên đến 20 tỷ khuôn mặt). Trích xuất ID: Trích xuất thông tin từ hồ sơ, tài liệu. Amazon SageMaker Canvas (No-Code/Low-Code)\nPain point: Các team quản lý ML thiếu hụt nguồn nhân lực ML, cần nhiều kỹ năng về code và kỹ thuật, khó cập nhật các công cụ hỗ trợ phát triển nhanh chóng. Cách giải quyết của SageMaker Canvas là cung cấp các mô hình có sẵn được train trước, cho phép custom với dữ liệu riêng mà không cần phải biết code. Generative AI (Amazon Bedrock)\nPain point: Thiếu Foundation Model được huấn luyện cụ thể cho một tác vụ, nhu cầu custom Foundation Model với dữ liệu nội bộ của doanh nghiệp (dữ liệu cần bảo vệ riêng tư) và khó khăn trong quản lý cơ sở hạ tầng và chi phí. Cách giải quyết của Bedrock là cung cấp các API để truy cập các Foundation Model nổi tiếng trên thế giới (Claude, Stable Diffusion, \u0026hellip;), cho phép custom các Foundation Model với dữ liệu riêng của doanh nghiệp. RAG technique giúp cải thiện độ chính xác và chất lượng nội dung của Foundation Model, tránh hiện tượng ảo tưởng khi mô hình đưa ra thông tin sai lệch. Thách thức khi xây dựng RAG: Quản lý nhiều nguồn dữ liệu, lựa chọn kiểu vector phù hợp để chuyển đổi tài liệu sang dữ liệu số, và nỗ lực xây dựng mô hình/hệ thống. Bedrock Knowledge Base: Cung cấp khả năng quản lý hoàn toàn bởi AWS, cho phép truy cập Foundation Model và Agent một cách bảo mật, dễ dàng truy cập dữ liệu liên quan. Bảo mật của Bedrock sử dụng Guardrails: Giúp sàng lọc, không tiết lộ dữ liệu nhạy cảm (PII). Định nghĩa các hành vi để block (VD: Không được gen ra các nội dung bạo lực, nhạy cảm). Giới hạn nội dung được cho phép sinh ra để tránh ảo tưởng. Các model mới trên Bedrock: Nova Canvas (sinh ảnh độ phân giải 2k x 2k). Nova Reel (sinh video từ text và ảnh). Bài học rút ra Có cái nhìn toàn diện về cách AWS hỗ trợ các doanh nghiệp tận dụng sức mạnh của AI/ML và GenAI. LLM là một dạng Deep Learning. Deep Learning là một nhánh của Machine Learning. Machine Learning là một phần của Trí tuệ nhân tạo (AI). "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/5-workshop/5.3-architecture/",
	"title": "Kiến trúc",
	"tags": [],
	"description": "",
	"content": "Kiến Trúc Tổng Quan Hệ thống Excel Import được thiết kế theo mô hình Serverless Event-Driven Architecture, tận dụng các managed services của AWS để giảm thiểu operational overhead và tối ưu chi phí.\nChi tiết Endpoints:\nPOST /register (RegisterFunction) POST /confirm (ConfirmFunction) POST /login (LoginFunction) POST /logout (LogoutFunction) POST /upload-url (GenerateUploadUrlFunction) GET /import/jobs (ListImportJobsFunction) GET /jobs/{jobId} (GetJobStatusFunction) Core Processing Function\nProcess Flow:\nGet file từ S3 (event.Records[0].s3) Parse Excel bằng Apache POI Validate từng row (email format, required fields) Batch write vào DynamoDB (25 items/batch) Update ImportJob status \u0026amp; statistics Output: Updated ImportJob record Tables: StudentsTable, CoursesTable, ImportJobsTable Amazon S3 (File Storage): Storage lưu trữ các file user import. "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/4-eventparticipated/",
	"title": "Các events đã tham gia",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/4-eventparticipated/4.4-event4/",
	"title": "Event 4",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “WORKSHOP “CLOUD INFRASTRUCTURE \u0026amp; OS ON AWS”” Mục Đích Của Sự Kiện Chia sẻ góc nhìn, quan điểm, và kiến thức về hạ tầng của AWS Chia sẻ, giới thiệu về Containers \u0026amp; Orchestration Danh Sách Diễn Giả Phạm Nguyễn Hải Anh - Cloud Engineer Danh Hoàng Hiếu Nghị - GenAI Engineer\nNội Dung Nổi Bật So sánh giữa hạ tầng On-Premise (tại chỗ) và AWS Cloud. On-Premise:\nCài đặt Hypervisor: Thường cần chuyên gia cài đặt thủ công, tốn công sức. Hạ tầng: Lớp ảo hóa gắn cứng với phần cứng vật lý, cần chuyên viên kỹ thuật can thiệp trực tiếp khi bảo trì. Scale: Có giới hạn khả năng xử lý nhất định, không thể tăng giảm tùy ý (ví dụ: lượng dùng CPU vẫn giữ nguyên dù ít người truy cập). Chi phí: Phải có vốn đầu tư trước Aws Cloud (EC2):\nCài đặt Hypervisor: AWS đã làm sẵn, được quản lý thông qua Console và giao diện AWS, cho phép tương tác trực tiếp. Hạ tầng: Bài toán ảo hóa được giải quyết thông qua Nitro System (sẽ trình bày chi tiết sau). Scale: Có khả năng scale theo lượng người dùng, là điểm mấu chốt khi chọn Cloud. Chi phí: Mô hình Pay-as-you-go, chỉ trả tiền cho phần đã sử dụng. Cách chọn lựa Instance phù hợp Chú ý các yếu tố: Series, thế hệ, option, kích thước (Tùy vào nhu cầu sử dụng) Ví dụ: chọn dòng máy chuyên về CPU nếu ứng dụng cần tính toán, hoặc chuyên về lưu trữ nếu là hệ thống database/cache. Có 3 cách thức để chi trả khi sử dụng EC2: On-Demand: Xài nhiêu tính nhiêu. Saving Plan: Cam kết sử dụng trong 1 hoặc 3 năm để nhận ưu đãi về giá (thích hợp khi có kế hoạch rõ ràng). Spot Instance: Rẻ nhất, sử dụng EC2 thừa ra, nhưng có thể bị AWS thu hồi máy khi cần (thích hợp cho testing). Mỗi accout Chia sẽ về công nghệ Nitro System – một công nghệ ảo hóa trên AWS Cloud giúp vận hành hạ tầng EC2. Lịch sử: Bắt đầu từ khoảng 2013, liên tục được phát triển và giới thiệu cải tiến tại các sự kiện như AWS re:Invent. Kiến trúc: Khác với ảo hóa truyền thống (Phần cứng -\u0026gt; Lớp Ảo hóa -\u0026gt; Instance), Nitro gắn một lớp Nitro trực tiếp lên hạ tầng phần cứng. Cấu trúc 3 phần: Nitro card: Các card (phần cứng) được gắn lên chip để cung cấp interface kết nối đến các dịch vụ (ví dụ: EBS, VPC). Nitro Security Chip: Một chip được thiết kế riêng, gắn vào bo mạch chủ (mainboard) để cung cấp tính năng bảo mật. Nitro Hypervisor: Lớp ảo hóa nhẹ, đơn giản nhưng tương thích tốt với hạ tầng. Security: Nhân viên vận hành (Operator) Data Center không có quyền truy cập trực tiếp vào phần cứng của Nitro. Mọi quyền truy cập phải được xác thực qua API và được log vào hệ thống của AWS. Không có API nào có quyền truy cập vào dữ liệu của người dùng. Nitro tạo ra một Cam kết bảo mật cho người dùng. AWS Graviton: Một con chip mới của AWS, giúp tăng hiệu suất, giảm chi phí và tiết kiệm năng lượng. Key take-note Không ai có quyền truy cập trực tiếp vào hạ tầng của người dùng. 100% truy cập đều phải thông qua API, có logging. Hệ thống Nitro được phát triển và quản lý theo quy trình DevSecOps. Có thể áp dụng kiến trúc Microservice cho hạ tầng. Containers \u0026amp; Orchestration Giới thiệu về containers "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/5-workshop/5.4-deploy-backend/",
	"title": "Triển khai Backend",
	"tags": [],
	"description": "",
	"content": "Deploy Backend với AWS SAM Trong phần này, chúng ta sẽ sử dụng SAM Template để deploy toàn bộ hạ tầng lên AWS.\nCác bước Build với Maven (compile Java)\nBuild với SAM (package Lambda)\nDeploy với SAM (tạo CloudFormation stack)\nVerify Resources (kiểm tra trên AWS Console)\n"
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/4-eventparticipated/4.5-event5/",
	"title": "Event 5",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “AWS Cloud Mastery Series #1” Mục Đích Của Sự Kiện Chia sẻ về ​AI/ML/GenAI on AWS Danh Sách Diễn Giả Đinh La Hoàng Anh\nDanh Hoàng Hiếu Nghị - GenAI Engineer\nNội Dung Nổi Bật 1. AWS AI/ML Services Overview Tập trung vào các dịch vụ AI được train sẵn (Pre-trained Services), chỉ cần gọi API là sử dụng được, không yêu cầu kiến thức sâu về ML.\nAmazon Rekognition (Computer Vision): Phân tích hình ảnh/video, nhận diện khuôn mặt, kiểm duyệt nội dung (ví dụ: làm mờ hình ảnh nhạy cảm). Hỗ trợ Custom Labels để train nhận diện các vật thể đặc thù. Amazon Translate: Dịch thuật thời gian thực, hỗ trợ văn phong tự nhiên và xử lý cả Emoji. Có thể tích hợp S3 để dịch hàng loạt văn bản. Amazon Textract (OCR): Trích xuất văn bản, chữ viết tay và dữ liệu từ các văn bản scan. Hiểu được layout, bảng biểu trong các giấy tờ hành chính. Amazon Transcribe: Chuyển đổi giọng nói thành văn bản (Speech-to-Text), nhận diện người nói và ngắt câu tự động. Amazon Polly: Chuyển đổi văn bản thành giọng nói (Text-to-Speech) với ngữ điệu tự nhiên. Amazon Comprehend (NLP): Xử lý ngôn ngữ tự nhiên: Phân tích cảm xúc (tích cực/tiêu cực), trích xuất từ khóa, nhận diện thông tin nhạy cảm (PII). Amazon Kendra: Công cụ tìm kiếm doanh nghiệp thông minh, hiểu ngữ nghĩa câu hỏi tự nhiên (không cần keyword chính xác 100%). Hỗ trợ RAG (Retrieval-Augmented Generation). Lưu ý: Chi phí khá cao. Amazon Lookout Family: Các dịch vụ phát hiện bất thường trong thiết bị công nghiệp (Equipment) hoặc sản phẩm lỗi (Vision). Amazon Personalize: Hệ thống gợi ý (Recommendation System) dựa trên hành vi người dùng để tăng tương tác và doanh số. Hỗ trợ sinh nội dung tự động cho sản phẩm. 2. Foundation Models \u0026amp; Bedrock Agents Chuyển dịch từ Chatbot truyền thống sang AI Agents có khả năng ra quyết định.\nSự tiến hóa của Chatbot: Từ các logic if-else đơn giản -\u0026gt; Chatbot trả lời câu hỏi -\u0026gt; AI Agents (có khả năng suy luận và thực thi tác vụ). Chiến lược phát triển: Không nên train model từ đầu nếu không cần thiết. Sử dụng các framework như LangChain, LangGraph để build nhanh và scale tốt. Thách thức khi đưa AI ra Production (Scale): Xử lý đồng thời nhiều người dùng. Memory: Khả năng ghi nhớ ngữ cảnh và xu hướng của người dùng qua các phiên làm việc. Identity: Quản lý xác thực và phân quyền truy cập Agent. Tools: Quản lý việc gọi API và thực thi công cụ chính xác. Giải pháp - Amazon Bedrock Agent Core: Runtime: Môi trường thực thi, wrapper ứng dụng. Memory: Tích hợp sẵn bộ nhớ ngữ cảnh dài hạn. Identity: Phân quyền người dùng cụ thể. Demo: Browser Use - Agent tự động thao tác trình duyệt để tìm kiếm top comment trên Youtube. Key Take-note (Bài học rút ra) Tận dụng tối đa các dịch vụ Pre-trained AI (Rekognition, Textract\u0026hellip;) cho các bài toán tiêu chuẩn để tiết kiệm thời gian development. Với các bài toán phức tạp cần suy luận và hành động, chuyển hướng sang xây dựng AI Agents trên nền tảng Amazon Bedrock. Chú trọng vấn đề Scaling và Security (Identity, Guardrails) ngay từ giai đoạn thiết kế Agent. "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/5-workshop/5.5-deploy-frontend/",
	"title": "Triển khai Frontend",
	"tags": [],
	"description": "",
	"content": "Cập Nhật File config.js Bước 1: Lấy API Gateway Endpoint\nMở CloudFormation Console Tìm stack excel-import-workshop Chọn tab Output Copy value của ApiUrl Bước 2: Thay đổi cấu hình\nVào thư mục /excel-import-frontend/ Vào thư mục /excel-import-frontend/src Mở file config.js Thay APP_API_URL bằng value của ApiUrl vừa copy Save lại Bước 3: Build Frontend và tạo S3 Bucket để host Frontend\nDi chuyển vào thư mục Frontend và chạy lần lượt các lệnh sau:\ncd ./excel-import-frontend/ npm install npm run build aws s3 mb s3://workshop-frontend-\u0026lt;ACCOUNT-ID\u0026gt; --region ap-southeast-1 Sau khi build hoàn tất, thư mục dist sẽ được tạo.\nBước 4: Host Frontend trên S3 Bucket\nVào S3 Bucket Console Chọn Bucket workshop-frontend-\u0026lt;ACCOUNT-ID\u0026gt; vừa tạo Mở folder dist (tạo từ lệnh npm run build ở Bước 3) nhấn CTRL + A để copy toàn bộ file và folder. Kéo toàn bộ file và folder đã copy vào phần Upload của Bucket Click Upload, after upload success click Close Vào tab Permissions Click Edit Block public access (bucket settings) Bỏ chọn Block public access Vào Object Ownership chuyển thành ACLs enabled sau đó Save Chọn tab Object select all file và folder click Action và chọn Make Public và Close. Click chọn Index.html copy Object URL ở tab mới để vào website. "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "Excel-to-DynamoDB on AWS using S3 Notifications Tổng quan Trong workshop này, chúng ta sẽ xây dựng một ứng dụng serverless hoàn chỉnh để import dữ liệu từ file Excel vào DynamoDB sử dụng các dịch vụ AWS:\nAWS Lambda để xử lý logic backend Amazon S3 để lưu trữ file Excel S3 Event Notifications để trigger Lambda tự động khi có file mới Amazon DynamoDB để lưu trữ dữ liệu từ excel Amazon Cognito để xác thực người dùng API Gateway để expose REST APIs Chúng ta sẽ thực hiện:\nDeploy serverless application bằng AWS SAM Cấu hình S3 Event để trigger Lambda Parse file Excel trong Lambda và lưu vào DynamoDB Tích hợp Cognito authentication Theo dõi tiến trình import job Kiến trúc hệ thống Workshop này triển khai một kiến trúc serverless event-driven với các thành phần:\nAPI Layer:\nAPI Gateway với Cognito Authorizer REST endpoints cho authentication và import operations Processing Layer:\nLambda functions xử lý business logic S3 Event Notifications trigger processing Apache POI library để parse Excel files Storage Layer:\nS3 bucket cho file uploads DynamoDB tables cho các dữ liệu từ file excel và import jobs Nội dung Tổng quan Workshop Chuẩn bị môi trường Kiến trúc hệ thống Deploy Backend (AWS SAM) Deploy Frontend (React) Test ứng dụng Dọn dẹp tài nguyên "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/5-workshop/5.6-test-application/",
	"title": "Test Ứng Dụng",
	"tags": [],
	"description": "",
	"content": "Test Application Trong phần này chúng ta kiểm tra toàn bộ luồng hoạt động: đăng ký người dùng, xác thực, upload file mẫu và theo dõi trạng thái import.\nĐăng ký và xác thực Tại màn hình đăng nhập, click Sign up. Điền thông tin và click Sign up để tạo tài khoản. Nhập Code được gửi qua email rồi click Verify Email. Sau khi verify, đăng nhập bằng Email và Password vừa tạo. Tải file mẫu Tải file import mẫu: import-template.xlsx Upload file và import Vào chức năng upload file, chọn file mẫu vừa tải về và upload. Sau khi upload, click Upload \u0026amp; Import để bắt đầu quá trình import. Theo dõi tiến trình File sẽ được đưa lên S3 Bucket và kích hoạt Lambda để import dữ liệu. Trạng thái import: Processing → nếu không lỗi sẽ chuyển Completed. Processing → nếu có lỗi sẽ chuyển Failed và hệ thống sẽ tự động rollback. Kiểm tra dữ liệu sau import Kiểm tra file trên S3\nChạy lệnh sau để kiểm tra file vừa upload:\naws s3 ls s3://workshop-excel-imports-\u0026lt;ACCOUNT-ID\u0026gt; --recursive Kiểm tra dữ liệu các tables\nVào DynamoDB Console → Explore items, chọn từng table để xem dữ liệu sau import. "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/4-eventparticipated/4.6-event6/",
	"title": "Event 6",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch \u0026ldquo;AWS Cloud Mastery Series #2\u0026rdquo; Mục Đích Của Sự Kiện Chia sẻ về ​DevOps on AWS Trang bị kiến thức về CI/CD, Infrastructure as Code và Container Services Hướng dẫn thực hành Monitoring \u0026amp; Observability trên AWS Danh Sách Diễn Giả Anh Tịnh\nAnh Kha - Cloud Security Engineer\nNội Dung Nổi Bật 1. DevOps Mindset \u0026amp; Culture Tại sao cần DevOps? Cầu nối giữa Development và Operations: DevOps là người hiểu cả hai mảng, giúp giải quyết vấn đề \u0026ldquo;code chạy trên máy tôi nhưng không chạy trên server\u0026rdquo;. Xu hướng phát triển: Từ DevOps Engineer → Platform Engineer, focus vào xây dựng Internal Developer Platform thay vì chỉ support từng team riêng lẻ. Các yếu tố cốt lõi của DevOps Build tất cả môi trường nhất quán: Đảm bảo môi trường development, staging và production giống nhau. Automation Everything: Giảm lỗi từ con người, tiết kiệm thời gian, và đảm bảo quy trình lặp lại được nhất quán. Continuous Learning: Chia sẻ kiến thức và học hỏi liên tục trong team. Giảm Mean Time To Recover (MTTR): Phát hiện và xử lý lỗi nhanh hơn bằng cách deploy liên tục và có monitoring system. 2. Learning Path cho DevOps Engineer T-shaped Skills Sâu một mảng trước: Nên chọn từ System/Linux hoặc Development, học sâu về một mảng trước khi mở rộng. Từ System: Linux fundamentals → Docker → Kubernetes → Cloud Services Từ Development: Hiểu application lifecycle → CI/CD → Container → Infrastructure Lời khuyên quan trọng Master one thing at a time: Đừng học tất cả cùng lúc. Học sâu một thứ cho thật hiểu trước. Document everything: Ghi chép mọi thứ, viết sao cho người khác đọc hiểu được. Soft skills: Khả năng diễn đạt và giao tiếp rất quan trọng vì DevOps là cầu nối giữa các team. Don\u0026rsquo;t compare với người khác: So sánh bản thân hôm nay với hôm qua, mỗi người có tốc độ học khác nhau. Thực hành quan trọng hơn lý thuyết Đừng chỉ xem video tutorial: Phải thực hành ngay, không thể học mà không làm. Hạn chế dùng AI để copy code: ChatGPT có thể giúp nhưng phải hiểu code, không nên copy mù quáng. Học từ lỗi: Khi gặp lỗi, phải tự debug và hiểu nguyên nhân, không chỉ copy error message vào ChatGPT. 3. DevOps Metrics \u0026amp; Monitoring DORA Metrics Deployment Frequency: Tần suất deploy lên production Lead Time for Changes: Thời gian từ commit code đến chạy production Mean Time to Recovery (MTTR): Thời gian trung bình để khôi phục khi có lỗi Change Failure Rate: Tỷ lệ deploy gây ra lỗi Monitoring \u0026amp; Observability Không thể quản lý những gì không đo được: Phải có hệ thống giám sát để biết application chạy như thế nào. CloudWatch, X-Ray, Dashboards: Theo dõi metrics, logs, và performance. Alerting: Thiết lập cảnh báo khi có vấn đề để xử lý nhanh. 4. CI/CD Pipeline Continuous Integration (CI) Source Control: Git strategies (GitFlow, Trunk-based), quản lý code như thế nào Code Quality: Scan code trước khi commit Review code (không dùng AI để auto-approve) Test automation Build \u0026amp; Test: CodeBuild, testing pipelines Security: Scan dependencies, check for vulnerabilities (injection attacks ngay cả khi dùng AI code) Continuous Delivery/Deployment (CD) Continuous Delivery: Cần approval trước khi deploy lên production Continuous Deployment: Tự động deploy hoàn toàn, không cần intervention Deployment Strategies: Blue/Green Deployment Canary Deployment (70/30 split để test) Rolling Updates CI/CD Best Practices Version Control cho tất cả: Có branch strategy rõ ràng Viết commit message rõ ràng Tạo Pull Request và có người review Không push thẳng lên main branch Testing ở mọi stage: Unit test trước khi commit Integration test sau khi merge Không bao giờ commit code không test Automation workflow: Scan security Build Test Review Deploy 5. Infrastructure as Code Terraforms Declarative approach: Định nghĩa infrastructure bằng code Important commands: terraform init - Khởi tạo terraform plan - Xem trước thay đổi (QUAN TRỌNG - phải check trước khi apply) terraform apply - Triển khai infrastructure AWS CloudFormation \u0026amp; CDK CloudFormation: Templates, stacks, drift detection CDK (Cloud Development Kit): Infrastructure as Code bằng programming languages (TypeScript, Python, etc.) CDK generate ra CloudFormation template 6. Container Services Docker Fundamentals Không chỉ build image: Phải hiểu container interface, networking, storage Docker Compose: Quản lý multi-container applications Best practices: Không commit node_modules hay dependencies Sử dụng .dockerignore Multi-stage builds để giảm image size Amazon ECS \u0026amp; EKS ECS: Managed container service, dễ sử dụng EKS: Kubernetes trên AWS, phức tạp hơn nhưng flexible hơn ECR: Container registry của AWS Key Takeaways DevOps không chỉ là tool: Là văn hóa, quy trình làm việc, và mindset. Automation là key: Nhưng phải hiểu trước khi automate. Learning never stops: Công nghệ thay đổi nhanh, phải học liên tục. Học sâu từ fundamentals: Linux/Networking trước, rồi mới lên container/orchestration. CI/CD là core: Phải thực hành được từ source control đến deployment. Monitoring \u0026amp; Security: Quan trọng như code, không thể bỏ qua. "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": "Trong suốt thời gian thực tập tại AWS từ 08/09/2025 đến 12/12/2025, tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế. Tôi đã tham gia xây dựng và triển khai dự án Teaching Center Management System trên nền tảng AWS Serverless, tập trung vào hai thành phần chính: quản lý học vụ — quản lý môn học, lớp học, ghi danh bằng enrollKey, quản lý tài liệu trên S3, import Excel và phần xác thực/định danh và phân quyền — Amazon Cognito, invite/redeem, SSO Google, quản lý hồ sơ. Công việc chính bao gồm: thiết kế kiến trúc tổng thể, kiến trúc các dịch vụ hạ tầng được sử dụng; viết mẫu IaC bằng AWS SAM/CloudFormation; phát triển các hàm AWS Lambda cho các module học vụ và xác thực; tích hợp API Gateway, DynamoDB, S3, Cognito; cấu hình CloudFront, Route 53, WAF cho frontend; thiết lập pipeline CI/CD với Gitlab Runner; giám sát và cảnh báo bằng CloudWatch Logs/Alarms và SNS. Qua đó, tôi cải thiện rõ rệt kỹ năng thiết kế kiến trúc cloud, phát triển serverless, IaC, CI/CD, bảo mật và giám sát trên AWS, viết tài liệu kỹ thuật, làm việc nhóm và giao tiếp.\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy và gắng trao đổi, giao tiếp với các thành viên.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ☐ ✅ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ☐ ✅ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ☐ ✅ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ✅ ☐ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ☐ ☐ ✅ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ✅ ☐ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ☐ ✅ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ☐ ✅ ☐ Cần cải thiện Cần cải thiện trong cách kết nối thành viên trong làm việc, để đảm bảo được chất lượng đầu ra của dự án tốt hiện tại Cần cải thiện trong việc tư duy tìm kiếm ý tưởng, trình bày ý tưởng và lên kế hoạch Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/5-workshop/5.7-cleanup/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "1) Xoá nội dung của S3 Buckets\n# Xóa tất cả object trong bucket (empty) aws s3 rm s3://workshop-excel-imports-\u0026lt;YOUR-ACCOUNT-ID\u0026gt; --recursive aws s3 rm s3://workshop-frontend-\u0026lt;YOUR-ACCOUNT-ID\u0026gt; --recursive 2) Xoá S3 Buckets\nSau khi bucket đã rỗng, xoá bucket bằng lệnh:\naws s3 rb s3://workshop-excel-imports-\u0026lt;YOUR-ACCOUNT-ID\u0026gt; aws s3 rb s3://workshop-frontend-\u0026lt;YOUR-ACCOUNT-ID\u0026gt; 3) Xử lý SamCliSourceBucket do SAM CLI tạo\nSamCliSourceBucket là bucket tạm do AWS SAM CLI tạo để upload mã nguồn khi sam deploy. Nếu bucket này có Bucket Versioning bật (Enabled), bạn phải xóa thủ công các phiên bản (versioned objects) trước khi xoá bucket. Mở AWS Console -\u0026gt; S3 -\u0026gt; chọn SamCliSourceBucket (tên ví dụ: aws-sam-cli-managed-default-...). Chuyển sang tab Properties -\u0026gt; Bucket Versioning. Nếu Versioning = Enabled, xóa các phiên bản object (hoặc tạm thời tắt versioning và xóa từng phiên bản) rồi empty bucket. Sau khi bucket không còn object (cả version), chọn Delete bucket và xác nhận. 4) Xóa CloudFormation stack (SAM delete)\ncd ./excel-import-workshop/ sam delete --stack-name excel-import-workshop --region us-east-1 --no-prompts "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": "Đánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Môi trường làm việc hiện tại rất tốt, tạo một môi trường giúp mọi người kết nối và phát triển.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp và tác phong chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ, luôn luôn hổ trợ trả lời, gợi ý cho những thắc mắc hay những câu hỏi của nhau.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty cho phép thời gian lên công ty linh hoạt khi cần thiết, chỉ cần đảm bảo vẫn đầy đủ. Các buổi workshop được tổ chức khá nhiều giúp hổ trợ trong quá trình học tập và tìm hiểu kiến thức mới.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Điều hài lòng nhất trong thời gian thực tập là môi trường và các mentor. Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Hiện tai chưa thấy điểm cần cải thiện Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Có! Nếu bạn quan tâm đến Cloud đặc biệt là AWS thì đây là nơi rất phù hợp vì nơi đây cung cấp cho bạn môi trường, mentor nhiệt tình, các tài liệu học tập và các buổi workshop nhiều kiến thức. Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập? Hiện tại không có Bạn có muốn tiếp tục chương trình này trong tương lai? Rất muốn tiếp tục Góp ý khác (tự do chia sẻ): Không có "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/4-eventparticipated/4.7-event7/",
	"title": "Event 7",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch \u0026ldquo;AWS Cloud Mastery Series #3 - Security Pillar\u0026rdquo; Mục Đích Của Sự Kiện Chia sẻ về AWS Well-Architected Security Pillar Trang bị kiến thức về 5 trụ cột bảo mật: IAM, Detection, Infrastructure Protection, Data Protection, Incident Response Thông Tin Sự Kiện Thời gian: Thứ Sáu, 29 tháng 11, 2025 (8:30 AM – 12:00 PM - Morning Only) Địa điểm: AWS Vietnam Office Danh Sách Diễn Giả Anh Hoàng Anh Anh Thịnh, Anh Đạt, Anh Đức Anh Anh (Long) - Security Specialist from the USA\nNội Dung Nổi Bật Vai trò Security Pillar trong Well-Architected Security Pillar: Một trong 6 trụ cột của AWS Well-Architected Framework Mục tiêu: Bảo vệ dữ liệu, hệ thống và tài sản trên AWS Top threats tại Việt Nam: Exposed S3 Buckets với dữ liệu nhạy cảm Hardcode credentials trong code (push lên GitHub) Long-term credentials không rotate Public-facing databases Lack of monitoring và detection Nguyên tắc cốt lõi Least Privilege: Chỉ cấp quyền tối thiểu cần thiết, không hơn không kém Zero Trust: Không tin tưởng bất kỳ ai/gì theo mặc định, luôn verify Defense in Depth: Nhiều lớp bảo mật, không chỉ dựa vào một tầng Shared Responsibility Model AWS chịu trách nhiệm: Security OF the Cloud (infrastructure, hardware, network) Customer chịu trách nhiệm: Security IN the Cloud (data, IAM, applications, OS, network config) Phải hiểu rõ: Không phải AWS tự động bảo vệ tất cả, bạn phải config đúng Pillar 1 — Identity \u0026amp; Access Management (8:50 – 9:30 AM) IAM Fundamentals IAM = Identity and Access Management: Dịch vụ xác thực và quản lý quyền truy cập Components: Users: Người dùng cá nhân Roles: Vai trò được assume bởi services/users Policies: JSON documents định nghĩa permissions Groups: Nhóm users để quản lý dễ hơn Best Practices Xóa Root Access Keys: Root account có toàn quyền, rất nguy hiểm nếu bị lộ Least Privilege: Chỉ cấp quyền cần thiết, không dùng wildcard (*) nếu không cần Tránh dùng long-term credentials: Sử dụng temporary credentials thay thế Không hardcode credentials: Dùng IAM Roles, STS tokens, không để username/password trong code IAM Identity Center (SSO) Single Sign-On: Đăng nhập một lần, dùng cho nhiều accounts/applications Benefits: Dễ quản lý users trong môi trường multi-account Tự động rotate credentials (15 phút - 36 giờ) Tích hợp với external identity providers ⚠️ Lưu ý quan trọng: Khi enable Identity Center = enable AWS Organizations → sẽ chấm dứt toàn bộ credits của accounts mới (không thể hoàn lại) Nhưng: Free credits $200 vẫn mất, nhưng promotional credits (found credit, activate credit) thì không bị ảnh hưởng Service Control Policies (SCP) SCP vs IAM: IAM: Cho phép (Allow) user/role làm gì SCP: Giới hạn (Boundary) quyền tối đa trong organization Ví dụ: Bằng lái A1 cho phép chạy 60km/h (IAM) Biển báo đoạn đường chỉ cho phép 40km/h (SCP) Kết quả: Chỉ được chạy 40km/h Use case: Giới hạn regions (chỉ ap-southeast-1, ap-southeast-2), ngăn tạo expensive resources Permission Boundaries Giới hạn quyền tối đa mà user có thể trao cho người khác Scenario: Senior dev có thể tạo IAM cho intern, nhưng quyền tối đa chỉ bằng quyền của senior Ngăn chặn: Intern không thể tắt monitoring, xóa logs để che giấu lỗi MFA (Multi-Factor Authentication) TOTP (Time-based OTP): Google Authenticator, Microsoft Authenticator Ưu điểm: Miễn phí, dễ setup, sync được giữa nhiều devices Nhược điểm: Dễ bị phishing nếu nhập vào fake website FIDO2 (Fast Identity Online 2): YubiKey, physical security keys Ưu điểm: Chống phishing tốt hơn (chỉ work với registered domain) Nhược điểm: Tốn tiền ($25-$90), nếu mất key = mất account (trừ khi có backup) Credential Rotation Vấn đề: Hardcode password trong code → push lên GitHub → bot scan trong vài giây → account bị hack AWS Secrets Manager: Tự động rotate secrets theo schedule 4 bước rotation: Tạo secret mới Set secret vào database/service Test xem secret mới có work không Mark secret mới là \u0026ldquo;current\u0026rdquo;, secret cũ là \u0026ldquo;previous\u0026rdquo; Trong thời gian rotation, nếu hacker có secret cũ, họ vẫn bị kick ra khi rotation xong Pillar 2 — Detection CloudTrail Organization Level Organization Trail: Enable CloudTrail cho toàn bộ organization, không phải setup từng account Benefits: Single pane of glass để monitor tất cả activities Automatic deployment cho new accounts Centralized logging Event Types Management Events: API calls, Console actions (CreateBucket, DeleteInstance) Data Events: Object-level operations (GetObject, PutObject trong S3) Network Activity: VPC Flow Logs integration Insights Events: Detect unusual activity patterns Infrastructure as Code CloudFormation/Terraform: Deploy CloudTrail và detection rules tự động Version Control: Manage detection logic qua Git Automatic Deployment: Deploy trên toàn organization GuardDuty - Intelligent Threat Detection Thách thức hiện tại Không biết đang bị tấn công: Lack of visibility Không có context: Không biết severity, không biết cách xử lý Delay Response: Trung bình mất 206 ngày để phát hiện breach (theo industry stats) GuardDuty Solutions Machine Learning-based: Tự động detect threats không cần manual rules Data Sources: CloudTrail logs (API activities) VPC Flow Logs (network traffic) DNS logs Kubernetes audit logs (nếu dùng EKS) Threat Intelligence: AWS threat intelligence + 3rd party feeds Finding Types: Compromised credentials Unusual API calls Cryptocurrency mining Malware detection Unauthorized access attempts Real-time Automation EventBridge Integration: GuardDuty → EventBridge → Lambda → Actions Automatic Response: Block IP addresses Revoke IAM credentials Isolate EC2 instances Send SNS notifications Create tickets Timing Consideration GuardDuty findings: Có thể mất 5-10 phút để generate finding EventBridge: Trigger ngay lập tức (real-time) khi có finding Trade-off: Không thể faster hơn 5-10 phút với GuardDuty, đây là limitation của service Alternative cho real-time: CloudWatch Metrics + Anomaly Detection cho network anomalies (không cần đợi GuardDuty) Security Hub - Centralized Security Management Tổng hợp findings từ nhiều sources Aggregates from: GuardDuty Inspector Macie IAM Access Analyzer Systems Manager Firewall Manager Single dashboard: Xem tất cả security findings ở một chỗ Pillar 3 — Infrastructure Protection VPC Segmentation Private vs Public Subnets: Database/backend phải ở private, chỉ expose cần thiết Network isolation: Separate VPCs cho different environments (dev/staging/prod) Security Groups vs NACLs Security Groups: Stateful (return traffic tự động allow) Instance level Allow rules only NACLs: Stateless (phải define cả inbound và outbound) Subnet level Allow và Deny rules WAF + Shield + Network Firewall WAF (Web Application Firewall): Bảo vệ layer 7 (HTTP/HTTPS) Shield: DDoS protection (Standard free, Advanced có cost) Network Firewall: Stateful inspection, IPS/IDS capabilities Workload Protection EC2: Security groups, IMDSv2, SSM Session Manager (không cần SSH keys) ECS/EKS: Pod security policies, network policies, secrets management Pillar 4 — Data Protection KMS (Key Management Service) AWS Managed Keys (AMK): AWS tự động manage, bạn không control Customer Managed Keys (CMK): Bạn tự tạo, tự control Quan trọng: Nếu mất key = mất data, không recover được Support key rotation (automatic hoặc manual) Key Rotation Automatic Rotation: Mặc định 365 ngày (1 năm) AWS tự động tạo key mới, re-encrypt data Transparent cho applications Manual Rotation: Phức tạp hơn: phải decrypt → delete old key → create new key → encrypt lại Dùng khi cần control chi tiết hơn Encryption at Rest S3: Default encryption, bucket policies có thể enforce EBS: Encryption khi tạo volume RDS/DynamoDB: Encryption option khi tạo database Nitro System: Hardware-based encryption cho EC2 Certificate Management (ACM) AWS Certificate Manager: Free SSL/TLS certificates cho ELB, CloudFront, API Gateway Automatic renewal (60 ngày trước khi expire) với DNS validation Lưu ý: Phải có domain riêng, không work với domain mặc định của AWS Macie - Sensitive Data Discovery Machine Learning-based: Tự động detect sensitive data (credit cards, SSN, PII) S3 scanning: Scan buckets, generate findings về data exposure Timing: Mất 15-20 phút cho lần scan đầu tiên Integration: Findings send to Security Hub Data Classification \u0026amp; Guardrails Guardrails: Policy enforcement - không tin tưởng developers sẽ nhớ encrypt Example: Bucket policy deny PutObject nếu không có encryption header Zero Trust principle: Enforce thay vì recommend Demo: HTTP vs HTTPS với Wireshark HTTP: Traffic bị plaintext Wireshark capture: Username và password visible rõ ràng Hacker có thể \u0026ldquo;nghe lén\u0026rdquo; và lấy credentials HTTPS: Traffic encrypted với TLS Wireshark capture: Chỉ thấy encrypted gibberish Cần private key mới decrypt được (mà attacker không có) Pillar 5 — Incident Response Tư duy bảo mật hiện đại Bối cảnh: Các cuộc tấn công phức tạp, tự động hóa cao → Bắt buộc phải dùng Automation Định nghĩa Incident: Không chỉ hack/lộ dữ liệu, mà cả Downtime, High Traffic bất thường Shared Responsibility: AWS bảo mật \u0026ldquo;OF\u0026rdquo; the Cloud, bạn bảo mật \u0026ldquo;IN\u0026rdquo; the Cloud Biện pháp phòng vệ cốt lõi Công cụ AWS bắt buộc: Organizations, SCPs, CloudTrail, Config, GuardDuty, Security Hub Identity Management: Loại bỏ long-lived credentials → Dùng SSO, IAM Roles, STS tokens Bảo vệ Data \u0026amp; Network: S3 không public, Database/RDP/SSH không có Public IP Infrastructure as Code: Không click Console → Dùng Terraform/CloudFormation Double Gate: Thay đổi rủi ro cao cần ≥2 bước phê duyệt (SCP + Policy + Manual approval) Incident Response Lifecycle Preparation:\nCó playbooks, runbooks sẵn sàng Train team Setup automation trước Tools ready (CloudTrail, GuardDuty, Security Hub) Detection \u0026amp; Analysis:\nMonitor alerts từ GuardDuty, Security Hub Analyze logs, identify scope Determine severity Containment:\nIsolate affected resources Revoke credentials Preserve evidence (snapshots, logs) Không xóa gì cả - cần để forensics Eradication:\nRemove threat/vulnerability Patch systems Restore to clean state Recovery \u0026amp; Lessons Learned:\nRestore normal operations Post-mortem analysis Update playbooks Improve detection Modern Threats \u0026amp; Reality Check Shareid Responsibility: AWS bảo vệ cloud infrastructure, bạn phải bảo vệ data và confg Modern threats today: AI-powered attacks (faster, smarter) Supply chain attacks Zero-day exploits Insider threats Q\u0026amp;A Q: Có cách nào tối ưu thời gian GuardDuty finding? A: 5-10 phút là limitation của service. Nếu cần real-time hơn, dùng CloudWatch Metrics + Anomaly Detection cho network anomalies. Q: Different approaches for real-time detection? A: Three approaches: Anomalies: CloudWatch Metrics (instant) Security Issues: GuardDuty (5-10 min) Compliance: AWS Config (minutes to hours depending on rule) Key Takeaways (Bài học rút ra) Security is a shared responsibility: AWS + You, không phải AWS tự động làm tất cả Defense in Depth: Nhiều layers, không chỉ dựa một tầng Zero Trust: Không trust theo mặc định, luôn verify Automate everything: Manual không scale, automation giúp response nhanh "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]