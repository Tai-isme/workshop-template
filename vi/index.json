[
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch \u0026ldquo;DATA SCIENCE ON AWS\u0026rdquo; Mục Đích Của Sự Kiện Khám phá hành trình xây dựng một hệ thống Data Science hiện đại\nDanh Sách Diễn Giả Văn Hoàng Kha – Cloud Solutions Architect, AWS Community Builder\nBạch Doãn Vương – Cloud Develops Engineer, AWS Community Builder\nNội Dung Nổi Bật Giới thiệu về AI và các khái niệm (Anh Kha) Trí tuệ nhân tạo (AI): Đóng vai trò như 1 trợ lý ảo, là một công nghệ/kỹ thuật có khả năng học hỏi giống con người. Học từ các dữ liệu có sẵn, học từ các dữ liệu mới chưa từng được học qua với tốc độ rất nhanh (nhưng không nhanh bằng tốc độ suy nghĩ của con người). Máy học (Machine Learning): Là một phương pháp để thực hiện AI, máy tính sẽ học hỏi dựa trên một lượng dữ liệu lớn dạng chữ, đơn giản để đưa ra dự đoán. Học sâu (Deep Learning): Học sâu là học chia thành nhiều lớp/tầng học các dữ liệu phức tạp, đa dạng từ nhiều mãng khác nhau và kết nối như 1 mạng nơ ron thần kinh trong não con người. AI tạo sinh (Genertive AI): Học từ những mô hình ngôn ngữ/mô hình dữ liệu cực kì lớn chỉ có ở các hãng lớn (VD: Dữ liệu được Google thu tập từ hàng chục năm thông qua những kết quả tìm kiếm của người dùng trên Google -\u0026gt; ra đời một một hình ngôn ngữ lớn (Gen-AI)). Genertive AI hay hơn ML và DL là có thể tự sáng tạo như sáng tác thơ, tạo ảnh, video. (VD: Gemini từ Google, Bedrock từ AWS, \u0026hellip;) AI/ML trên nền tảng AWS (Anh Kha) AWS phát triển hơn 200 dịch vụ và hơn 10,000 tính năng. Về lịch sử: AWS sử dụng các dịch vụ mình phát triển cho chính hệ thống của mình sau đó mới bán ra thị thường Sau khi bán ra thị thường thì thu thập phản hồi, yêu cầu từ khách hàng và phát triển thêm các dịch vụ, tính năng theo phản hồi, yêu cầu của khách hàng Các dịch vụ của AWS được chia làm 3 tầng: Tầng trên (Dịch vụ AI): Các dạng phần mềm phục vụ được tất cả các bài toán ở hiện tại. Xử lý hình ảnh, âm thanh, chuyển chữ thành giọng nói (và ngược lại), trích xuất văn bản từ các file văn bản. Các dịch vụ cho phép người dùng sử dụng API để tự phát triển. Tầng giữa (Dịch vụ ML): Dành cho người dùng muốn tự quản lý, tự chuẩn bị dữ liệu, tự xử lý dữ liệu, tự trainning cho máy học, tự tinh chỉnh mô hình. Dịch vụ để trainning có thể sử dụng là Amazon SageMaker, dịch vụ tương tự như Google Colab. Tầng dưới (ML Frameworks và hạ tầng): AWS cung cấp các phần cứng, hạ tầng mạnh mẽ để trainning các mô hình lớn, hợp tác với các nhà cung cấp như NVIDIA. Các dịch vụ AI của AWS (Anh Kha) Amazon Comprehen: Xử lý ngôn ngữ tự nhiên sử dụng công nghệ máy học để tìm ý nghĩa và thông tin chi tiết trong văn bản. Amazon Translate: Là dịch vụ dịch, sử dụng Deep Learning để cung cấp bản dịch chính xác và tự nhiên hơn các thuật toán truyền thống. Amazon Transcribe: Nhận dạng giọng nói để chuyển giọng nói thành văn bản. Amazon Polly: Tạo ra giọng nói theo yêu cầu, chuyển văn bản thành giọng nói. Amazon Textract: Nhận dạng văn bản, sử dụng Machine Learning để trích xuất các văn bản, chữ viết tay và dữ liệu từ tài liệu được quét. Amazon Rekognition: Là dịch vụ nhận diện đối tượng, khuôn mặt, nhận diện qua video, kiểm duyệt nội dung phim, các tình huống thể thao (VD: Check var trong bóng đá). Amazon Personalize: Giúp xây dựng hệ thống gợi ý (recommendation) sản phẩm, phim ảnh dựa trên hành vi của người dùng, tương tự như cách Netflix hay YouTube đề xuất nội dung. Quy trình xây dựng mô hình Machine Learning (Anh Kha) Feature Engineering: Là quá trình chuẩn bị dữ liệu, làm sạch dữ liệu, chuyển dữ liệu về ngôn ngữ máy để cho máy có thể hiểu được.\nHuấn luyện mô hình: Dùng dữ liệu đã chuẩn bị để dạy cho máy học.\nTinh chỉnh và Đánh giá: Kiểm tra độ chính xác của model. Nếu chưa chính xác thì phải quay lại bước chuẩn bị, xử lý lại dữ liệu.\nTriển khai mô hình: Cho phép người dùng cuối có thể sử dụng thử.\nTheo dõi: Sau quá trình dùng thử, thu thập phản hồi của người dùng, từ đó re-change lại dữ liệu để tăng độ chính xác của mô hình.\nTrainning model sử dụng Amazon SageMaker Canvas, sau khi traninning xong thì có thể triển khai lên tự động, không cần viết code mà chỉ cần kéo thả.\nPhần demo (Anh Vương) Xử lý và làm sạch dữ liệu từ dataset IMDb với AWS Glue Tải dữ liệu thô lên S3 Sử dụng AWS Glue để thực hiện các tác vụ làm sạch tự động. Dữ liệu sau khi đã được làm sạch sẽ được lưu lại vào S3, sẵn sàng cho việc huấn luyện mô hình trên Amazon SageMaker. So sánh chi phí và hiêu năng: Cloud vs On-Premise Cloud giúp giảm chi phí đầu tư hạ tầng, tối ưu hóa chi phí vận hành nhờ mô hình trả phí theo dung lượng sử dụng. Cloud cho phép scale tài nguyên nhanh chóng. Linh hoạt và nhanh chóng thử nghiệm nhiều mô hình khác nhau và không bị giới hạn phần cứng. "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Nguyễn Văn A\nSố điện thoại: 0989888999\nEmail: Anguyenvan@gmail.com\nTrường: Đại học Sư phạm Kỹ thuật TP.HCM\nNgành: Công nghệ thông tin\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/08/2025 đến ngày 12/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": " Tối ưu hóa quy trình làm việc HPC với các cụm tự động mở rộng trong Ansys Gateway vận hành bởi AWS Bởi Dnyanesh Digraskar và Trent Andrus | Vào 22 tháng 4 năm 2025 | trong AWS ParallelCluster, High Performance Computing, Partner solutions.\nĐược đóng góp bởi Dnyanesh Digraskar, Kiến trúc sư Giải pháp Đối tác HPC tại AWS, và Trent Andrus, Chuyên gia Sản phẩm tại Ansys.\nAnsys Gateway vận hành bởi AWS là một giải pháp kỹ thuật đám mây (gọi tắt là “Ansys Gateway” trong phần còn lại của bài viết) được lưu trữ trên AWS Marketplace. Sản phẩm này cung cấp cho khách hàng giao diện liền mạch để chạy mô phỏng Ansys trong tài khoản Amazon Web Services (AWS) của mình. Khách hàng có thể triển khai nhanh các ứng dụng Ansys đã được xác thực, tinh chỉnh trên hạ tầng HPC mà AWS khuyến nghị. Groupama FDJ và Turntide Technologies sử dụng Ansys Gateway để tăng tốc các công việc thiết kế kỹ thuật và mô phỏng. So với hạ tầng on-premise, Groupama FDJ đạt tốc độ mô phỏng nhanh hơn 17 lần khi thiết kế xe đạp đua, còn Turntide Technologies tăng tốc mô phỏng thiết kế động cơ điện lên 7 lần.\nSau phiên bản phát hành đầu tiên của Ansys Gateway, một số phản hồi từ người dùng liên quan đến việc cần kiểm soát nhiều hơn trong quy trình tạo cụm HPC. Để giải quyết vấn đề này, Ansys Gateway nay đã tích hợp tính năng cụm tự động mở rộng từ phiên bản 2024 R2 trở đi. Điều này cho phép cấp phát tài nguyên tính toán động dựa trên hàng đợi công việc Slurm. Bên cạnh quy trình tạo cụm được nâng cấp, Ansys Gateway nay hỗ trợ các dịch vụ AWS như Amazon FSx for Lustre, Amazon FSx for OpenZFS và Amazon Elastic File System (EFS). Các dịch vụ này thường được sử dụng để hỗ trợ nhiều loại quy trình làm việc HPC khác nhau. Với khả năng tự mở rộng, EFS là lựa chọn khởi đầu tuyệt vời cho đa số khách hàng. Đối với các mô phỏng lớn có nhiều thao tác I/O, các hệ thống tệp chia sẻ hiệu năng cao như FSx for Lustre và OpenZFS giúp tránh nghẽn cổ chai I/O. Trong môi trường tính toán hỗn hợp Windows và Linux, OpenZFS có thể truy cập được từ cả hai nền tảng.\nMở rộng tài nguyên HPC cho các mô phỏng kỹ thuật là một thách thức phức tạp. Tính mở rộng phản ánh khả năng hạ tầng HPC cung cấp tài nguyên tính toán tỷ lệ thuận với nhu cầu khối lượng công việc. Thông thường, các mô phỏng gắn kết chặt chẽ như phần mềm mô phỏng chất lỏng Ansys Fluent, phần mềm mô phỏng động lực học phi tuyến Ansys LS-DYNA, hay phần mềm phân tích phần tử hữu hạn cấu trúc Ansys Mechanical đều có thể mở rộng trên nhiều lõi và đạt hiệu năng tuyến tính gần như tuyệt đối (tùy thuộc vào benchmark). Với các cụm tự động mở rộng, người dùng có thể quản lý tài nguyên hiệu quả dựa trên nhu cầu khối lượng công việc và loại bỏ các “nút thắt cổ chai” phần cứng trong lúc cao điểm.\nBài blog này mô tả kiến trúc, quy trình làm việc và các khuyến nghị về Amazon EC2 khi chạy các ứng dụng Ansys trong Ansys Gateway.\nCác thành phần kiến trúc Các thành phần kiến trúc của Ansys Gateway, bao gồm Mặt kiểm soát (Control Plane) và Mặt ứng dụng (Application Plane), đã được mô tả chi tiết trong bài blog năm 2023.\nTừ phiên bản này trở đi, Ansys Gateway tích hợp với AWS ParallelCluster, một công cụ quản lý cụm mã nguồn mở. Slurm được sử dụng như bộ điều phối công việc để tự động cấp phát các nút tính toán khi các công việc được xếp hàng đợi và giải phóng khi không còn cần thiết nữa. Hình 1 dưới đây minh họa sơ đồ kiến trúc triển khai AWS ParallelCluster trong VPC của khách hàng Ansys Gateway. Sơ đồ kiến trúc triển khai AWS ParallelCluster trong Amazon Virtual Private Cloud (VPC) của khách hàng Ansys Gateway được minh họa ở Hình 1.\nHình 1: Kiến trúc triển khai HPC của Ansys Gateway dựa trên AWS ParallelCluster. Đây là lớp ứng dụng được triển khai trong tài khoản AWS của khách hàng.\nThành phần chính của cụm HPC bao gồm: Nút quản lý (Head Node) – Quản lý quy trình công việc và trạng thái cụm. Bộ điều khiển Slurm – Bộ điều phối sử dụng Slurm workload manager. Các nút tính toán động – Được cung cấp và chấm dứt dựa trên nhu cầu khối lượng công việc. Ví dụ: khởi chạy các loại phiên bản Amazon EC2 như C6i, Hpc6a, Hpc7a cho khối lượng công việc dựa trên CPU và P5, G6e để tăng tốc GPU. Lưu trữ – Amazon EFS hoặc Amazon Elastic Block Store (EBS) để cài đặt ứng dụng và dữ liệu công việc liên tục có thể hoạt động như bộ gắn Hệ thống tệp mạng (NFS) hoặc Amazon FSx cho Lustre và Amazon FSx cho OpenZFS cho khối lượng công việc hiệu suất cao. Hàng đợi cụm – Hàng đợi công việc hỗ trợ nhiều loại phiên bản cho nhiều loại khối lượng công việc khác nhau, chẳng hạn như: hàng đợi phiên bản được tối ưu hóa điện toán để chạy mô phỏng CFD và sự cố; hàng đợi phiên bản được tối ưu hóa bộ nhớ để chạy mô phỏng FEA hoặc NVH; Hàng đợi phiên bản được tối ưu hóa GPU để chạy mô phỏng hướng đồ họa. Bạn nên chạy ứng dụng trên các loại phiên bản đồng nhất với tất cả các nút điện toán có thiết kế giống nhau để đạt được hiệu suất tối ưu. Mạng nâng cao – Amazon Elastic Fabric Adapter (EFA) là giao diện mạng nâng cao dành cho các phiên bản Amazon EC2 để chạy các ứng dụng yêu cầu liên lạc giữa các nút ở mức độ cao trên quy mô lớn. AWS ParallelCluster mang lại sự linh hoạt lớn cho Ansys Gateway trong định nghĩa tài nguyên tính toán và hàng đợi. Một hàng đợi có thể chứa nhiều tài nguyên tính toán, và mỗi tài nguyên lại có thể có nhiều loại instance EC2. Ví dụ: một hàng đợi có tài nguyên tính toán với các loại instance như r6i.32xlarge, r6in.32xlarge, r6id.32xlarge. Thông thường, cụm sẽ cố gắng cấp phát loại instance rẻ nhất trước, nếu không đủ thì chuyển sang loại kế tiếp. Đây là cách giúp giải quyết tạm thời vấn đề thiếu hụt tài nguyên.\nNhờ các cụm mở rộng động, người dùng Ansys Gateway giờ đây có thể có quy trình mô phỏng dựa trên job (theo hàng đợi) thay vì mỗi cluster cho một mô phỏng như truyền thống. Với cluster tĩnh, tài nguyên có thể lãng phí vào thời gian thấp điểm, dẫn đến chi phí không cần thiết. Cluster tĩnh cũng có thể không phù hợp với mọi loại công việc, khiến bạn phải resize hoặc tạo cluster mới với các loại instance khác nhau, gây downtime và chi phí ngoài dự kiến.\nQuy trình gửi công việc mô phỏng Phần này sẽ mô tả quy trình từng bước thực hiện trên giao diện Ansys Gateway để tạo các cụm HPC mở rộng động nhằm chạy các mô phỏng Ansys. Giả định rằng bạn đã đăng nhập vào Ansys Gateway và có quyền truy cập vào không gian làm việc để gửi các công việc mô phỏng.\nBước 1: Tạo cụm HPC Việc tạo cụm mở rộng động thực hiện theo các bước sau:\nChọn loại lưu trữ (giữa Amazon EFS, Amazon FSx for OpenZFS và Amazon FSx for Lustre) Chọn các gói ứng dụng Ansys cần cài đặt Định nghĩa các hàng đợi tính toán của cụm và chọn tài nguyên Cũng như khi tạo bất kỳ tài nguyên nào, bạn bắt đầu bằng cách chọn một tenant (tức là workspace đã đăng ký) trong Ansys Gateway như minh họa ở Hình 2a. Sau đó, hãy tạo mới hoặc chọn một project space chưa có cụm mở rộng động. Project space này phải có chỉ báo ở cột Releases là “24R2+” như minh họa ở Hình 2b.\nHình 2a: Trang chủ của Ansys Gateway. Người dùng có thể chọn một tenant để truy cập vào các project space của họ. Có hai tùy chọn tenant được hiển thị, mỗi tenant đều có tên và ID riêng.\nHình 2b: Trang chủ các project space của Ansys Gateway. Một project space có tiêu đề “Gateway Autoscaling Cluster Demonstration” được hiển thị.\nTrong project space này, hãy tạo một tài nguyên mới và chọn “Autoscaling Cluster” từ danh sách thả xuống như minh họa ở Hình 3.\nHình 3: Một project space trống với danh sách thả xuống đang mở, gợi ý người dùng tạo một máy tính để bàn ảo mới hoặc các cụm (clusters).\nSau khi chọn “Autoscaling Cluster” từ danh sách thả xuống, trình hướng dẫn tạo mới sẽ cho phép bạn thiết lập một số tính năng chính của cụm. Đầu tiên là loại lưu trữ, tiếp theo là các ứng dụng cần cài đặt, và cuối cùng là các hàng đợi tài nguyên tính toán. Theo mặc định, một ổ đĩa Amazon Elastic File System (EFS) sẽ được gắn vào cụm HPC và sẵn sàng cho các tài nguyên trong project space. Trong Hình 4, một vị trí lưu trữ thứ hai tùy chọn được định nghĩa cho đường dẫn cài đặt sản phẩm.\nHình 4: Các tùy chọn lưu trữ của trình hướng dẫn tạo cụm. Theo mặc định, một hệ thống tệp EFS sẽ được tạo và gắn vào cụm. Ngoài ra, một vùng lưu trữ thứ hai là Amazon FSx for OpenZFS cũng được thiết lập, với dung lượng 256 GiB và băng thông 2048 MiB/s/TiB. Tên lưu trữ và đường dẫn mount cũng được người dùng cung cấp.\nKhi đã xác định xong các tùy chọn lưu trữ, bạn có thể chọn các gói ứng dụng muốn cài đặt. Trong Hình 5, Ansys Structures được chọn.\nHình 5: Bước chọn các ứng dụng mô phỏng để cài đặt trong trình hướng dẫn tạo cụm.\nTrong quá trình tạo cụm, trình hướng dẫn có thể tự động triển khai một máy chủ chạy Ansys HPC Platform Services (HPS), như minh họa ở Hình 6. Khi sử dụng HPS, người dùng có thể đơn giản hóa đáng kể việc gửi công việc mô phỏng nhờ khả năng upload, submit, theo dõi và tải kết quả trực tiếp từ máy trạm mà không cần tự chuyển file lên đám mây hoặc viết script gửi công việc. Lưu ý rằng HPS được cung cấp dưới dạng container và sử dụng Docker để triển khai. Để biết thêm thông tin về thiết lập và sử dụng HPS, tham khảo tài liệu Ansys HPC Platform Services.\nVị trí cài đặt HPS cần trùng với nơi cài sản phẩm Ansys (ví dụ: đều cài trên ổ FSx for OpenZFS).\nHình 6: Bước thiết lập Ansys HPC Platform Services (HPS) trong trình hướng dẫn tạo cụm. Theo mặc định, một máy ảo nền tảng Linux sẽ được tạo cho người dùng và các dịch vụ HPS sẽ tự động được triển khai.\nTiếp theo, trình hướng dẫn giúp người dùng tạo hàng đợi gửi công việc. Người dùng có thể chỉ định cả số lượng nút tĩnh và động theo giới hạn hạn ngạch dịch vụ AWS của họ. Có thể xác định tối đa mười hàng đợi cho một cụm.\nHình 7: Sau khi nhấn nút “Add queue”, người dùng sẽ chọn ứng dụng cho hàng đợi này, đặt tên hàng đợi, chọn số lượng nút tĩnh (luôn sẵn sàng), số lượng nút động tối đa, các tùy chọn nâng cao (như EFA, placement group, v.v.), và cuối cùng là loại hoặc các loại instance muốn dùng. Quy trình này được lặp lại cho từng hàng đợi.\nỨng dụng liên kết với một hàng đợi được chọn từ danh sách thả xuống. Thông thường, nên đặt tên hàng đợi sao cho thể hiện rõ ứng dụng và phiên bản mà hàng đợi đó dùng, ví dụ như “mech242”.\nSau khi đã định nghĩa các hàng đợi mong muốn, bạn có thể đặt tên và tạo cụm. Khi quá trình tạo cụm hoàn tất, bạn sẽ thấy một huy hiệu “Running” báo hiệu rằng mọi tài nguyên và dịch vụ đã được triển khai. Các tài nguyên tính toán sẽ vẫn ở trạng thái offline cho đến khi có công việc được gửi. Từ project space, nhấp vào cụm sẽ hiển thị trang tổng quan với thông tin về head node, HPS node, các hàng đợi và các nút tính toán đã cấp phát. Xem Hình 8a và 8b để biết chi tiết về thông tin sau khi cụm được tạo.\nHình 8a: Trang tổng quan sau khi tạo cụm, hiển thị thông tin chi tiết về head node và HPS node.\nHình 8b: Trang tổng quan cụm hiển thị: các hàng đợi đang có theo tên (một hàng đợi có tên mech242), số lượng nút đã cấp phát (0/10), ứng dụng liên kết (Ansys Structure 2024 R2); danh sách các ứng dụng cùng vị trí cài đặt (Ansys Structures trên Amazon FSx for Open ZFS); danh sách các vị trí lưu trữ được gắn (EFS mặc định, OpenZFS) kèm tên, loại và đường dẫn mount.\nBước 2: Gửi công việc đến cụm Khi cụm đã được tạo, bạn có thể tận dụng quy trình gửi công việc đơn giản hóa mà HPS cung cấp. Ví dụ với Ansys Mechanical ở Hình 9, việc kết nối tới máy chủ HPS chỉ đơn giản là nhập địa chỉ IP của server HPS theo định dạng https://example.com:port/hps. Tham khảo Hình 9 để biết địa chỉ của máy chủ HPS.\nHình 9: Cửa sổ thiết lập quy trình giải bài toán (Solve Process Settings) của Ansys Mechanical.\nĐối với những người dùng quen thuộc với dòng lệnh Linux, bạn vẫn có thể gửi công việc bằng các lệnh Slurm tiêu chuẩn như srun, sbatch và salloc. Tham khảo tài liệu Ansys Help để biết thêm thông tin về cách gửi công việc bằng Slurm.\nBước 3: Theo dõi việc tự động mở rộng nút Sau khi submit job, người dùng truy cập giao diện giám sát công việc HPS trên trang cluster của Ansys Gateway để theo dõi trạng thái job (Pending, Running, Evaluated), xem file log và tải về file kết quả.\nHình 10: Giao diện giám sát công việc của HPS. Người dùng có thể truy cập giao diện này từ trình duyệt web để xem trạng thái công việc (Pending, Running, Evaluated), theo dõi các file log và tải về từng file riêng lẻ.\nSử dụng các lệnh Slurm để vận hành cụm (cluster operations)\nNhững người dùng quen thuộc với việc giám sát thông qua các lệnh Slurm vẫn có thể làm như vậy. Công việc được gửi qua HPS có thể nhìn thấy thông qua lệnh \u0026ldquo;squeue\u0026rdquo; trong Hình 11 (sau khi kết nối tới Linux VDI trong workspace). Nút được yêu cầu đang ở trạng thái configuring (CF), có nghĩa là nó đang được mở rộng quy mô.\nHình 11: Truy vấn Slurm bằng lệnh “squeue” trên dòng lệnh Linux. Lệnh này trả về danh sách các công việc kèm các thông tin như trạng thái công việc và tài nguyên được cấp phát.\nTương tự, có thể xem số lượng nút đã cấp phát bằng lệnh “sinfo -s” như trong Hình 12. A/I/O/T thể hiện số lượng nút Đang sẵn sàng/Đang chờ rỗi/Đang offline/Tổng số nút.\nHình 12: Truy vấn Slurm bằng lệnh “sinfo” để xem danh sách các hàng đợi đang có. Kết quả trả về gồm một hàng đợi kèm thông tin về tên và số lượng nút đang sử dụng.\nNgười dùng cũng có thể gửi công việc bằng các lệnh Slurm như “srun,” “sbatch,” và “salloc” như minh họa ở Hình 13. Script gửi công việc đã được tích hợp sẵn trong gói cài đặt ứng dụng trên Ansys Gateway.\nHình 13: Gửi công việc trực tiếp tới Slurm bằng lệnh “salloc” và theo dõi trạng thái bằng lệnh “squeue”.\nBước 4: Lấy kết quả và shutdown cụm Nếu gửi job bằng HPS, có thể tải file kết quả trực tiếp về máy cá nhân từ ổ lưu trữ chung của cụm. Nếu gửi bằng lệnh Slurm sử dụng ổ tạm trên instance, cần copy file kết quả về ổ lưu trữ khi job hoàn thành. Mặc định, các nút động sẽ online thêm 10 phút sau khi chạy xong, sau đó tự động dừng nếu không có việc mới.\nKhuyến nghị loại Amazon EC2 cho các ứng dụng Ansys Ansys Gateway hỗ trợ quy trình tạo cluster nâng cao cho các ứng dụng:\nAnsys Electronics Desktop Ansys Fluids Ansys LS-DYNA Ansys Lumerical Ansys Pathfinder-SC Ansys Speos Ansys Structures Ansys Totem-SC Các quy trình thiết lập chi tiết cho từng ứng dụng đều có trong tài liệu Ansys help Recommended Configurations by Application, thuộc phần Recommended Usage Guide. Sau khi đã tìm hiểu quy trình nâng cao để tạo cụm HPC trên Ansys Gateway, bạn hãy tham khảo Bảng 1 để biết các khuyến nghị chung về các loại instance Amazon EC2 thường dùng khi chạy các ứng dụng Ansys trên Ansys Gateway. Xem thêm danh sách chi tiết các loại instance được đề xuất tại Ansys Help page. Amazon EC2 Instances Specifications HPC6id HPC7a / HPC6a C6i* P5+ P4d+ G6e G5 Processor Intel Ice Lake AMD EPYC Intel Ice Lake NVIDIA H100 NVIDIA A100 L40S NVIDIA A10G Instance Size^ 32xlarge 96xlarge / 48xlarge 32xlarge 48xlarge 24xlarge 48xlarge 48xlarge Physical Cores 64 192 / 96 64 96 48 96 96 RAM per node (GiB) 1024 768 / 384 256 2048 1152 1536 768 Memory per core (GiB) 16 4 – 32 (HPC7a) / 4 (HPC6a) 4 24 24 16 8 EFA Bandwidth (GB/s) 200 300 / 100 50 3200 400 400 100 Number of GPUs 8 8 8 8 RAM per GPU (GB) 640 HBM3 40 HBM2 48 24 Target Ansys Apps^ Electronics Desktop, Fluids, LS-DYNA, Lumerical, Structures Fluids, LS-DYNA, Structures Electronics Desktop, Fluids, LS-DYNA, Lumerical, Pathfinder, Speos, Structures, Totem-SC Fluids Fluids Fluids, Structures, HFSS Fluids, Discovery Physics Description Implicit, Explicit, CFD codes Explicit, CFD codes Implicit, Explicit, CFD, Optics codes CFD codes Implicit, Explicit, CFD codes Implicit, Explicit, CFD codes Interactive modeling and simulations *Bật Elastic Fabric Adapter (EFA) để tăng tốc độ giao tiếp giữa các nút. Tắt Simultaneous Multithreading (SMT) nhằm đảm bảo hiệu suất CPU ổn định. ^ Các ứng dụng HPC thường sẽ hoạt động hiệu quả hơn khi sử dụng toàn bộ instance ở kích thước tối đa, nhờ có các tính năng như EFA. Không thể chạy ngay trên Ansys Gateway mà đòi hỏi người dùng phải cấu hình thêm các gói NVIDIA bổ sung. Bảng 1: Khuyến nghị loại instance Amazon EC2 cho các ứng dụng Ansys khác nhau.\nKết luận Ansys Gateway vận hành trên AWS hiện nay đã tích hợp với AWS ParallelCluster, giúp người dùng triển khai các cụm HPC theo nhu cầu để chạy mô phỏng Ansys trên AWS. Điều này cho phép các kỹ sư thực hiện các mô phỏng quy mô lớn một cách hiệu quả, đồng thời tối ưu hóa chi phí điện toán đám mây. Nhờ tự động điều chỉnh tài nguyên theo khối lượng công việc mô phỏng, Ansys Gateway giúp giảm thiểu thời gian máy tính nhàn rỗi và đảm bảo khả năng mở rộng tối ưu cho các tác vụ HPC.\nĐể bắt đầu với Ansys Gateway, hãy truy cập Ansys Gateway trên AWS Marketplace để triển khai môi trường HPC trên đám mây chỉ với vài cú nhấp chuột. Trải nghiệm ngay hôm nay để cảm nhận lợi ích của mô phỏng kỹ thuật hiệu năng cao, linh hoạt trên AWS.\nVề tác giả﻿ Dnyanesh Digraskar Dnyanesh Digraskar là Kiến trúc sư Giải pháp Đối tác HPC Cấp cao tại AWS. Anh phụ trách chiến lược triển khai HPC với các đối tác phần mềm độc lập (ISV) của AWS, nhằm hỗ trợ họ xây dựng các giải pháp có khả năng mở rộng và tuân theo kiến trúc tốt. Anh có hơn mười lăm năm kinh nghiệm trong các lĩnh vực CFD, CAE, mô phỏng số và HPC. Dnyanesh có bằng Thạc sĩ Kỹ thuật Cơ khí từ Đại học Massachusetts, Amherst. Trent Andrus Trent là Chuyên gia Sản phẩm tại Ansys, tập trung vào các chủ đề liên quan đến HPC và điện toán đám mây. Với niềm đam mê cập nhật các tiến bộ về hiệu năng phần cứng và phần mềm, anh hướng đến việc chuyển hóa kiến thức của mình thành những giải pháp giúp HPC trở nên dễ tiếp cận hơn cho mọi người dùng. Ngoài công việc, Trent là một người đam mê đạp xe và thường xuyên tập luyện để cải thiện hiệu suất của chính mình. "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": "Hiện đại hóa hạ tầng Kubernetes của Snowflake Corporate với Bottlerocket và Karpenter Bởi Sameeksha Garg, Gaurav Singodia, Jagdish Pawar, RK Sai (Ravikiran Koduri), và Sayan Moitra | ngày 18 tháng 4 năm 2025 | Trong Amazon Elastic Kubernetes Service, Customer Solutions, Open Source\nSnowflake Corporate IT Cloud Operations đã đạt đến một bước ngoặt quan trọng trong tiến trình phát triển hạ tầng điện toán đám mây. Việc quản lý các tải công việc dạng container trên Amazon Elastic Kubernetes Service (Amazon EKS) đòi hỏi một hệ điều hành hiện đại, an toàn và hiệu quả. Hệ thống hiện tại, sử dụng trên Amazon Linux 2 (AL2), vẫn hoạt động tốt nhưng lại xuất hiện một số thách thức. Việc tăng cường bảo mật đòi hỏi phải cập nhật thường xuyên, gây áp lực vận hành. Đảm bảo có những bản cập nhật an toàn và nhất quán trên quy mô lớn các node là điều khó khăn. Thêm vào đó, thời gian khởi động cho các node AL2 khá lâu, dẫn đến hiệu quả mở rộng thấp. Sau khi đánh giá toàn diện, Bottlerocket, hệ điều hành tối ưu cho container của AWS, đã được lựa chọn là giải pháp lý tưởng để giải quyết các khó khăn này.\nChiến lược di chuyển Việc chuyển từ AL2 sang Bottlerocket không đơn thuần là một thay đổi kỹ thuật mà còn là một quyết định chiến lược để đảm bảo hệ thống Kubernetes của Snowflake Corporate trong tương lai. Xét đến quy mô và độ phức tạp của các tải công việc, chiến lược di chuyển được thiết kế đảm bảo không có thời gian chết (zero downtime), ít gián đoạn, và mở rộng tự động liền mạch. Để đạt được, Snowflake Corporate đã lựa chọn Karpenter – bộ tự động mở rộng cluster Kubernetes mã nguồn mở, cùng với NodePool và NodeClass để hỗ trợ việc cấp phát node động. Quá trình di chuyển được thực hiện theo từng giai đoạn nhằm giảm thiểu các rủi ro và đảm bảo tính ổn định.\nCác bước di chuyển Quá trình di chuyển bắt đầu bằng việc chuẩn bị cụm (cluster). Các AMI Bottlerocket đã được tích hợp vào môi trường EKS bằng cách sửa đổi cấu hình NodePool và NodeClass để sử dụng Bottlerocket làm họ AMI mặc định. Các chính sách AWS Identity and Access Management (IAM) được tối ưu hóa để phù hợp với mô hình bảo mật của Bottlerocket, tuân thủ nguyên tắc phân quyền tối thiểu.\nSơ đồ kiến trúc này minh họa chiến lược di chuyển:\nTriển khai Karpenter đã thay thế phương pháp cấp phát tài nguyên tĩnh truyền thống, cho phép khởi tạo node đúng thời điểm cần thiết. Việc xác thực các tải công việc được thực hiện bằng cách sử dụng môi trường staging để kiểm thử trên các node Bottlerocket trước khi đưa vào production. Việc giám sát hiệu năng được triển khai thông qua Fluentd và Datadog nhằm theo dõi các chỉ số thời gian thực, đồng thời các kiểm tra tuân thủ bảo mật giúp đảm bảo hạ tầng bất biến của Bottlerocket phù hợp với các chính sách bảo mật của Snowflake Corporate.\nViệc triển khai được thực hiện theo từng giai đoạn, bắt đầu với các ứng dụng không trạng thái. Node affinity, pod anti-affinity và category được sử dụng để đảm bảo phân phối tải công việc tối ưu. Việc giới thiệu từ từ các node Bottlerocket giúp workload chuyển dịch suôn sẻ cùng với các instance AL2 hiện hữu. Quá trình cordon và drain các node hỗ trợ loại bỏ dần các instance AL2 mà không gây gián đoạn dịch vụ.\nCuối cùng, các giải pháp giám sát và tối ưu hóa nâng cao đã được triển khai. Việc tự động mở rộng với Karpenter giúp điều chỉnh động nhóm node của cluster. Điều chỉnh hiệu suất được thực hiện dựa trên các tải công việc thực tế, đồng thời cải tiến khả năng quan sát cung cấp các thông tin chi tiết về sức khỏe của hệ thống, cho phép phát hiện và xử lý chủ động các sự cố.\nVí dụ định nghĩa NodeClass và liên kết với NodePool:\napiVersion: karpenter.k8s.aws/v1alpha5 kind: NodeClass metadata: name: bottlerocket-nodeclass spec: amiFamily: Bottlerocket instanceProfile: \u0026#34;KarpenterNodeInstanceProfile\u0026#34; securityGroupSelector: aws-ids: [\u0026#34;sg-0123456789\u0026#34;] Example of defining a NodePool: apiVersion: karpenter.k8s.aws/v1alpha5 kind: NodePool metadata: name: bottlerocket-nodepool spec: template: spec: nodeClassRef: name: bottlerocket-nodeclass limits: resources: cpu: 1000 ttlSecondsAfterEmpty: 30  Example of applying node affinity to schedule workloads on Bottlerocket nodes: apiVersion: apps/v1 kind: Deployment metadata: name: bottlerocket-app spec: replicas: 3 selector: matchLabels: app: bottlerocket-app template: metadata: labels: app: bottlerocket-app spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: karpenter.k8s.aws/node-pool operator: In values: - bottlerocket-nodepool containers: - name: app image: my-app-image:latest Example of using pod anti-affinity to spread workloads across different nodes: apiVersion: apps/v1 kind: Deployment metadata: name: workload-deployment spec: replicas: 3 selector: matchLabels: app: critical-app template: metadata: labels: app: critical-app spec: affinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: app operator: In values: - critical-app topologyKey: \u0026#34;kubernetes.io/hostname\u0026#34; containers: - name: workload image: workload-image:latest Ví dụ định nghĩa NodePool:\napiVersion: karpenter.k8s.aws/v1alpha5 kind: NodePool metadata: name: bottlerocket-nodepool spec: template: spec: nodeClassRef: name: bottlerocket-nodeclass limits: resources: cpu: 1000 ttlSecondsAfterEmpty: 30 Ví dụ áp dụng node affinity để schedule workload lên node Bottlerocket:\napiVersion: apps/v1 kind: Deployment metadata: name: bottlerocket-app spec: replicas: 3 selector: matchLabels: app: bottlerocket-app template: metadata: labels: app: bottlerocket-app spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: karpenter.k8s.aws/node-pool operator: In values: - bottlerocket-nodepool containers: - name: app image: my-app-image:latest Ví dụ sử dụng pod anti-affinity để phân tán workload:\napiVersion: apps/v1 kind: Deployment metadata: name: workload-deployment spec: replicas: 3 selector: matchLabels: app: critical-app template: metadata: labels: app: critical-app spec: affinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: app operator: In values: - critical-app topologyKey: \u0026#34;kubernetes.io/hostname\u0026#34; containers: - name: workload image: workload-image:latest Những thách thức \u0026amp; cách khắc phục Mặc dù Bottlerocket mang lại nhiều lợi ích, quá trình di chuyển vẫn xuất hiện những thách thức nhất định. Một số workload ban đầu gặp vấn đề tương thích do hệ thống file bất biến của Bottlerocket. Để khắc phục, các image ứng dụng đã được chỉnh sửa để tuân thủ hoàn toàn tiêu chuẩn container và áp dụng cấu hình read-only khi phù hợp. Bottlerocket cũng yêu cầu cấu hình lại vai trò IAM để phù hợp với mô hình bảo mật mới; điều này được giải quyết bằng việc triển khai kiểm soát quyền truy cập chi tiết và tích hợp IAM với Karpenter. Để giảm thiểu rủi ro, workloads được di chuyển theo từng phần, đảm bảo hiệu năng ứng dụng duy trì ổn định trước khi loại bỏ hoàn toàn các node AL2.\nLợi ích chính Quá trình di chuyển đã mang lại sự cải thiện vượt trội về bảo mật, hiệu năng và hiệu quả vận hành. Bảo mật được nâng cao nhờ các node bất biến, ngăn chặn thay đổi trái phép và loại bỏ hiện tượng trôi cấu hình. Mức độ lỗ hổng được giảm mạnh nhờ loại bỏ các trình quản lý gói, truy cập shell và SSH, hạn chế nguy cơ tấn công. Cập nhật tự động và nguyên tử đảm bảo các node luôn được vá bảo mật mà không phải dừng hệ thống.\nThời gian khởi động node nhanh hơn nhờ tối ưu hóa quá trình khởi tạo, giúp các node mới gia nhập cluster nhanh chóng và tăng hiệu quả tự động mở rộng, bảo đảm workload được sắp lại nhanh hơn. Hiệu quả vận hành nâng cao thông qua việc scaling động với Karpenter, cấp phát tài nguyên đúng khi cần, tránh cấp phát dư thừa. Về chi phí, Bottlerocket với hệ điều hành nhẹ cùng khả năng cấp phát thông minh của Karpenter đã giúp tiết kiệm đáng kể nguồn lực.\nHiệu suất: Bottlerocket so với AL2 Bottlerocket nhất quán mang lại tốc độ node readiness nhanh hơn. Các benchmark sơ bộ cho thấy Bottlerocket rút ngắn thời gian node readiness khoảng 5 giây so với AL2. Ngoài ra, cơ chế native container image caching của Bottlerocket giúp giảm khoảng 36 giây cho mỗi pod trên một node mới, đồng thời các pod chưa thể lên lịch sẽ khởi chạy nhanh hơn so với AL2 khoảng 40 giây.\nTăng cường bảo mật: AL2 vs Bottlerocket So sánh trực tiếp về các cải tiến bảo mật cho thấy lý do vì sao Bottlerocket là lựa chọn vượt trội:\nBài học rút ra\nQuá trình di chuyển đã mang lại nhiều bài học giá trị. Bảo mật và hiệu quả vận hành luôn song hành; thiết kế bất biến của Bottlerocket giúp tăng cường bảo mật cho Snowflake Corporate. Việc tự động hóa đơn giản hóa quy trình, khi Karpenter hỗ trợ mở rộng thời gian thực đã loại bỏ nhu cầu can thiệp thủ công. Việc di chuyển theo từng bước giúp giảm rủi ro, đồng thời triển khai qua từng giai đoạn cho phép tinh chỉnh cấu hình mà không ảnh hưởng đến môi trường production.\nKết luận: Ý nghĩa rộng hơn cho doanh nghiệp vận hành EKS quy mô lớn Việc di chuyển thành công hạ tầng Kubernetes của Snowflake Corporate sang Bottlerocket và Karpenter đã tạo ra một mô hình tiêu chuẩn mới mà toàn ngành có thể tham khảo. Những lợi ích nổi bật như tăng cường bảo mật, rút ngắn thời gian khởi tạo node và tối ưu vận hành có thể được áp dụng rộng rãi tại các doanh nghiệp quản trị Kubernetes quy mô lớn. Trong tương lai, có thể tiếp tục nâng cấp với điều phối workload dựa trên AI, tích hợp sâu hơn với các công cụ quan sát hệ thống và khám phá Kubernetes serverless sử dụng Bottlerocket. Việc áp dụng Bottlerocket và Karpenter giúp Snowflake Corporate không chỉ nâng cao bảo mật mà còn tăng hiệu năng nhờ khả năng mở rộng động, nhấn mạnh sức mạnh của các giải pháp cloud-native hiện đại trong việc xây dựng môi trường Kubernetes hiệu suất cao, ổn định và bền vững.\nVề tác giả Sameeksha Garg Sameeksha Garg là Quản lý Tài khoản Kỹ thuật (Technical Account Manager) tại AWS, cam kết hỗ trợ và thúc đẩy hành trình lên đám mây cho các khách hàng doanh nghiệp toàn cầu của AWS. Cô có hơn 7 năm kinh nghiệm trong ngành, bao gồm các lĩnh vực như bảo mật đám mây, vận hành đám mây, quản lý cơ sở hạ tầng đám mây và chăm sóc khách hàng doanh nghiệp. Sameeksha đặc biệt đam mê các công nghệ bảo mật đám mây và luôn nỗ lực giúp khách hàng đảm bảo an toàn cho khối lượng công việc của họ trên nền tảng đám mây. Gaurav Singodia Gaurav Singodia là một lãnh đạo kỹ thuật cao cấp tại Snowflake với thành tích nổi bật trong việc thúc đẩy đổi mới sáng tạo và tăng trưởng nhờ tư duy khởi nghiệp. Hiện tại, ông dẫn dắt một tổ chức toàn cầu đa dạng bao gồm các nhóm SRE (Đảm bảo độ tin cậy của hệ thống), Kỹ sư hệ thống, Kỹ sư phần mềm, Hạ tầng dữ liệu, Nền tảng nhận diện, AI/ML và Phân tích, với trọng tâm lớn vào việc duy trì chất lượng cao và đạt được khả năng mở rộng trên tất cả các lĩnh vực. Jagdish Pawar Jagdish Pawar có hơn 18 năm kinh nghiệm lãnh đạo trong các công ty khởi nghiệp công nghệ, doanh nghiệp đang phát triển và các tập đoàn lớn. Ông có chuyên môn về xây dựng và dẫn dắt các nhóm liên chức năng, quản lý sản phẩm, kỹ thuật và quản lý vận hành điện toán đám mây với độ tin cậy cao, an toàn và khả năng mở rộng lớn. RK Sai (Ravikiran Koduri) RK Sai (Ravikiran Koduri) là Trưởng nhóm Hỗ trợ Doanh nghiệp tại AWS. Trong vai trò cố vấn kỹ thuật, ông giúp các Nhà cung cấp phần mềm độc lập (ISV) triển khai vận hành các khối lượng công việc với quy mô lớn. RK Sai là người truyền cảm hứng về AWS Deep Racer, các dịch vụ AI và Quản lý tài chính đám mây. Trong thời gian rảnh, ông luôn cố gắng biến ý nghĩa trừu tượng về sự viên mãn thành điều cụ thể trong cuộc sống. Sayan Moitra Sayan Moitra là kỹ sư DevOps cấp cao chuyên về kỹ thuật đám mây, DevOps và đảm bảo độ tin cậy hệ thống (SRE), với thế mạnh trong việc triển khai hạ tầng và ứng dụng. Anh sở hữu nhiều chứng chỉ AWS và CKAD, đồng thời được công nhận về chuyên môn trong lĩnh vực điện toán không máy chủ (serverless computing). Sayan có niềm đam mê học hỏi liên tục và giải quyết các vấn đề phức tạp. "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": "Di chuyển liền mạch: Chuyển đổi bảo mật các đội thiết bị IoT lớn sang AWS﻿ Bởi Andrea Sichel and Katja-Maja Kroedel | Ngày 15 tháng 4 năm 2025 | Trong các chủ đề: Advanced (300), AWS IoT Core, AWS IoT Device Management, Best Practices, Intermediate (200), Internet of Things, Migration, Technical How-to\nDi chuyển các đội thiết bị IoT quy mô lớn lên đám mây là một trong những chuyển đổi kỹ thuật phức tạp nhất mà các tổ chức ngày nay phải đối mặt. Mặc dù các lợi ích của việc di chuyển lên đám mây là rõ ràng, con đường dẫn đến triển khai thành công đòi hỏi phải lên kế hoạch và thực hiện cẩn thận. Trong một bài viết trước, chúng tôi đã phân tích các lý do chính để di chuyển sang AWS IoT Core. Bài viết này sẽ chia sẻ một chiến lược đã được kiểm nghiệm cho việc chuyển đổi các đội thiết bị IoT với hàng trăm triệu thiết bị sang AWS IoT Core, giải quyết các thách thức phổ biến, phác họa một kịch bản di chuyển cụ thể và đi sâu vào các tính năng của AWS IoT Core hỗ trợ các ca di chuyển phức tạp.\nCác thách thức với broker nhắn tin IoT tự quản lý﻿ Nhiều tổ chức bắt đầu hành trình IoT của mình với các broker nhắn tin tự quản lý. Dù phương pháp này mang lại sự kiểm soát và linh hoạt ban đầu, nó thường trở nên ngày càng thách thức hơn khi số lượng thiết bị tăng lên. Hiểu rõ các thách thức này là điều quan trọng trước khi bắt đầu quá trình di chuyển lên đám mây.\nChi phí cao﻿ Tác động tài chính của việc duy trì và vận hành hạ tầng IoT tự quản lý vượt xa chi phí lưu trữ cơ bản. Các tổ chức thường gặp khó khăn với việc lên kế hoạch năng lực không hiệu quả, cần đội ngũ kỹ sư riêng để quản lý hạ tầng. Những đội ngũ này phải luôn cân đối các ưu tiên giữa các phòng ban khác nhau và duy trì độ tin cậy của hệ thống. Chi phí cho việc giám sát, bảo mật và tuân thủ càng làm tình hình tài chính thêm phức tạp.\nPhù hợp năng lực tính toán﻿ Một trong những khía cạnh khó khăn nhất của việc quản lý hạ tầng IoT là đáp ứng tài nguyên tính toán với nhu cầu tải công việc. Các thời kỳ sử dụng cao điểm đòi hỏi phải có năng lực dư thừa để duy trì hiệu suất, trong khi các thời điểm sử dụng thấp dẫn đến phân bổ tài nguyên lãng phí. Thách thức này càng nghiêm trọng hơn với các triển khai toàn cầu, nơi các mô hình sử dụng khác nhau theo khu vực và múi giờ. Các tổ chức thường phải chọn giữa việc cấp phát dư thừa để đảm bảo độ tin cậy, hoặc mạo hiểm với các vấn đề hiệu suất khi xảy ra đột biến bất ngờ.\nCác thách thức bảo mật chưa được giải quyết﻿ Bảo mật có lẽ là thách thức quan trọng nhất trong việc triển khai IoT quy mô lớn. Quản lý hàng triệu thiết bị kết nối cần các giao thức bảo mật tinh vi, gồm quản lý chứng chỉ, phát hiện mối đe dọa theo thời gian thực, cơ chế cập nhật và truyền dữ liệu an toàn. Khi các yêu cầu quy định phát triển, các tổ chức buộc phải liên tục cập nhật thực tiễn bảo mật mà vẫn phải duy trì dịch vụ không gián đoạn. Yêu cầu này ngày càng phức tạp hơn khi đội thiết bị mở rộng và phân bố địa lý.\nSự đổi mới chậm lại﻿ Có lẽ chi phí tiềm ẩn lớn nhất từ broker tự quản là ảnh hưởng tới đổi mới. Các đội kỹ thuật dành quá nhiều thời gian để duy trì hạ tầng hiện có thay vì phát triển tính năng mới hoặc cải thiện trải nghiệm khách hàng. Gánh nặng duy trì này dẫn tới chậm ra mắt sản phẩm và bỏ lỡ cơ hội thị trường, ảnh hưởng đến vị thế cạnh tranh của tổ chức.\nKịch bản khách hàng và yêu cầu﻿ Hãy cùng xét một kịch bản di chuyển minh họa việc các môi trường IoT phức tạp cũng có thể chuyển đổi thành công sang AWS IoT Core.﻿\nHình 1: Kịch bản khách hàng trước khi di chuyển\nKiến trúc﻿ Hình dung một khách hàng với thiết lập sau, minh họa trong hình 1:﻿\n10 triệu thiết bị: Kết nối hàng ngày từ nhiều vị trí trên toàn thế giới.﻿\nGiải pháp triển khai tại chỗ: Thiết bị ban đầu kết nối broker và dịch vụ backend tại chỗ, thực hiện logic cho ứng dụng người dùng nội bộ hoặc hỗ trợ.﻿\nMáy chủ DNS: Được sử dụng để kết nối đến broker MQTT tự quản lý.﻿\nHơn 80 dịch vụ backend: Kiến trúc vi dịch vụ phân tán với 20–100 instance mỗi dịch vụ.﻿\nAPI Gateway: Các ứng dụng tiêu thụ dữ liệu tương tác với backend qua API gateway.﻿\nYêu cầu kỹ thuật cho giải pháp mới﻿ Giải pháp mới phải đáp ứng yêu cầu kỹ thuật nghiêm ngặt để đảm bảo chuyển đổi liền mạch:﻿\nCập nhật thiết bị không cần tương tác: Đội thiết bị phải chuyển đổi mà không cần thay đổi firmware hoặc tác động thủ công, vì không thể cập nhật trên hiện trường trong thời gian di chuyển mong đợi.\nKhả năng tương thích giao thức: Hỗ trợ liền mạch cả giao thức MQTT3 và MQTT5, do đội thiết bị gồm nhiều thế hệ phần cứng dùng các phiên bản giao thức khác nhau.\nPhân phối tin nhắn nâng cao: Dịch vụ backend cần chức năng subscription chia sẻ để cân bằng tải hiệu quả và đảm bảo xử lý tin nhắn nhất quán giữa các instance dịch vụ.\nTính năng của AWS IoT Core cho di chuyển phức tạp﻿ AWS IoT Core cung cấp bộ tính năng được thiết kế riêng để hỗ trợ các ca di chuyển phức tạp như đã minh họa ở trên.﻿\nAWS IoT Core vận hành dựa trên mô hình trách nhiệm chia sẻ, xác định ranh giới bảo mật và vận hành. AWS quản lý và bảo mật hạ tầng gốc, gồm trung tâm dữ liệu vật lý, bảo trì dịch vụ và độ sẵn sàng dịch vụ. Khách hàng chịu trách nhiệm bảo mật ứng dụng, triển khai bảo mật ở mức thiết bị, quản lý chứng chỉ và phát triển logic kinh doanh trên AWS IoT Core.\nHình 2: Các tính năng cốt lõi của AWS IoT\nDưới đây là một số khả năng chính (các dịch vụ được tô đậm là đặc biệt phù hợp với kiến trúc của khách hàng):\nDịch vụ nhận diện: Xác thực thiết bị nâng cao bằng chứng chỉ X.509, hỗ trợ các Tổ chức cấp chứng chỉ (CA) tùy chỉnh, và kiểm soát truy cập chi tiết thông qua các AWS IoT policies.\nGateway thiết bị: Khả năng kết nối mở rộng linh hoạt, hỗ trợ hàng triệu kết nối đồng thời, đa giao thức (HTTPS, MQTT, MQTT qua WebSockets, và LoRaWAN), cùng khả năng cân bằng tải tự động.\nBroker tin nhắn: Phân phối tin nhắn độ trễ thấp với hỗ trợ MQTT 3.1.1, MQTT 5, subscription chia sẻ, chức năng lưu trữ tin nhắn.﻿\nRegistry: Danh mục thiết bị toàn diện với quản lý metadata linh hoạt, nhóm thiết bị động, tích hợp với AWS IoT Device Management.﻿\nCác tính năng then chốt cho di chuyển phức tạp﻿ AWS IoT Core cung cấp một bộ tính năng mạnh mẽ giúp đơn giản hóa các quá trình di chuyển đội thiết bị IoT phức tạp, đồng thời giải quyết những thách thức thường gặp khi nâng cấp lên giải pháp AWS IoT Core do AWS quản lý. Một khía cạnh quan trọng của phương án di chuyển theo từng giai đoạn là các kỹ thuật này cho phép các dịch vụ backend và thiết bị thực hiện di chuyển theo tốc độ riêng của mình, từ đó giảm thiểu tối đa thời gian gián đoạn và ngừng hoạt động. Hãy cùng tìm hiểu chi tiết một số khả năng quan trọng, liên quan trực tiếp đến kịch bản di chuyển của khách hàng được nêu ở phần trước:\nCustom domain: Tính năng này nổi bật như một yếu tố then chốt cho việc migration quy mô lớn. Nó loại bỏ một trong những rào cản lớn nhất khi migration bằng cách cho phép tổ chức sử dụng domain hiện tại với endpoint AWS IoT Core. Điều này đồng nghĩa thiết bị có thể tiếp tục hoạt động với cấu hình sẵn có, từ đó giảm đáng kể rủi ro và độ phức tạp của quá trình migration. Ngoài ra, người dùng còn có thể cấu hình các policy và phiên bản TLS cũng như các giao thức, cổng kết nối cho endpoint sử dụng.\nHỗ trợ MQTT (MQTT 3 và MQTT 5): Trong các hệ thống IoT đa dạng, thiết bị thường sử dụng nhiều phiên bản MQTT khác nhau. AWS IoT Core hỗ trợ cả MQTT 3.1.1 và MQTT 5, cho phép các thiết bị sử dụng các phiên bản MQTT khác nhau vẫn có thể kết nối, đảm bảo quá trình migration diễn ra suôn sẻ mà không cần nâng cấp đồng loạt toàn bộ thiết bị lên chuẩn MQTT mới nhất ngay lập tức.\nBring your own certificate authority (CA): Việc giữ nguyên hạ tầng bảo mật hiện tại rất quan trọng trong quá trình migration. AWS IoT Core cho phép bạn đăng ký CA đang dùng lên AWS, tạo lập chuỗi tin cậy giữa thiết bị và AWS IoT Core mà không cần phải cấp lại certificate mới cho thiết bị. Điều này loại bỏ nhu cầu quay vòng certificate trong suốt quá trình migration.\nGần đây, AWS IoT Core cập nhật thêm các tính năng tăng cường quá trình di chuyển và nâng cao hiệu năng:﻿\nMessage enrichment with registry metadata: Lan truyền các thuộc tính thiết bị lưu trong registry cùng mỗi thông điệp gửi đi, giúp loại bỏ nhu cầu dùng AWS Lambda hoặc các instance xử lý để truy xuất thông tin này từ nguồn khác.\nThing-to-connection association: \u0026ldquo;thing\u0026rdquo; là một entry trong registry chứa các thuộc tính mô tả thiết bị. Chính sách xác định các thao tác mà thiết bị có thể thực hiện trên AWS IoT. Tính năng mới cho phép sử dụng biến trong chính sách với bất kỳ định dạng client ID, giải quyết được vấn đề migration khi client ID không tuân thủ quy tắc về tên \u0026ldquo;thing\u0026rdquo; của AWS IoT Core. Khi cấu hình xong, có thể sử dụng nhiều client ID cho mỗi certificate và \u0026ldquo;thing\u0026rdquo;, linh hoạt mà không cần thay đổi định danh hay cấu hình thiết bị đang có.\nClient ID in just-in-time registration (JITR): Thực hiện xác thực bảo mật bổ sung trong quá trình JITR nhờ nhận được thông tin client ID.\nCustom client certificate validation: Cho phép xác thực chứng chỉ khách hàng (client certificate) một cách tùy chỉnh thông qua hàm AWS Lambda khi thiết bị kết nối. Điều này hỗ trợ tích hợp với các dịch vụ kiểm tra chứng thực bên ngoài như OCSP (Online Certificate Status Protocol), giúp tăng cường kiểm soát bảo mật cho toàn bộ quá trình xác thực thiết bị.\nCustom authentication with X.509 client certificates: Mở rộng xác thực certificate bằng Lambda, cho phép chỉ định chính sách động cho thiết bị khi kết nối. Tính năng này bổ sung cho chức năng Custom Authorizer vốn đã hỗ trợ JWT token và username/password.\nALPN TLS extension removal: Extension ALPN của TLS không còn bắt buộc phải có trong quá trình bắt tay bảo mật (Transport Layer Security handshake) , giúp loại bỏ rào cản đối với những thiết bị không hỗ trợ ALPN.\nCác tính năng trên mang lại sự linh hoạt, bảo mật và hiệu quả cao hơn khi quản lý đội thiết bị IoT trên AWS IoT Core. Bằng cách tận dụng chúng, tổ chức có thể giảm tối đa độ phức tạp và rủi ro khi di chuyển đội thiết bị lớn, đảm bảo chuyển đổi liền mạch sang nền tảng IoT trên đám mây hiện đại, an toàn, mở rộng được.\nKiến trúc mục tiêu﻿ Kiến trúc mục tiêu gồm di chuyển 10 triệu thiết bị kết nối AWS IoT Core qua Amazon Route 53 (hoặc bất kỳ máy chủ DNS nào). Các dịch vụ backend, API gateway và ứng dụng tiêu thụ vẫn giữ nguyên.\nHình 3: Kiến trúc mục tiêu\nChiến lược di chuyển﻿ Ý tưởng là xây dựng chiến lược di chuyển dựa trên năm trụ cột chính nhằm đảm bảo quá trình chuyển đổi diễn ra suôn sẻ. Quá trình này bắt đầu bằng cách duy trì phương pháp tiếp cận không rủi ro thông qua việc lập kế hoạch và kiểm thử cẩn thận, đồng thời kiểm soát hoạt động với tài liệu và giám sát đầy đủ. Chiến lược nhấn mạnh việc giữ cho mức độ sai sót ở mức tối thiểu thông qua các bước thực hiện và xác nhận chính xác.\nPhù hợp với các nguyên tắc chiến lược đã nêu, nên áp dụng phương pháp tiếp cận theo từng giai đoạn.Mỗi giai đoạn có mục tiêu và các phụ thuộc cụ thể, cho phép theo dõi tiến độ một cách chặt chẽ và linh hoạt điều chỉnh khi cần thiết.\nHãy cùng đi sâu vào từng giai đoạn, làm rõ động lực các quyết định và minh hoạ thực tế.﻿\nGiai đoạn 0: Chuẩn bị﻿ Giai đoạn chuẩn bị đặt nền móng cho di chuyển thành công. Trọng tâm là thiết lập cầu nối giữa hạ tầng hiện tại và AWS IoT Core, đảm bảo vận hành liên tục trong suốt quá trình.\nTrung tâm của giai đoạn này là triển khai lớp chuyển tiếp (republish). Thành phần này đóng vai trò trung gian, hỗ trợ giao tiếp hai chiều giữa broker tự quản lý và AWS IoT Core — như một đường hầm bảo mật cho phép tin nhắn chuyển động liền mạch giữa hai hệ.\nHình 4: Kiến trúc của Giai đoạn Chuẩn bị\nLớp chuyển tiếp gồm hai thành phần chủ yếu:﻿ Thiết bị đến backend (Device to backend): Thành phần này thu nhận các thông điệp từ thiết bị đang kết nối với broker do bạn tự quản lý và chuyển tiếp chúng đến AWS IoT Core. Việc triển khai luồng này trước cho phép bắt đầu quá trình chuyển dịch các dịch vụ backend, trong khi thiết bị vẫn tiếp tục kết nối với broker hiện tại.\nBackend đến thiết bị (Backend to device): Được triển khai song song, thành phần này đảm bảo các thông điệp từ các dịch vụ backend mới đã được chuyển dịch vẫn đến được các thiết bị còn kết nối với broker tự quản lý. Khả năng truyền thông hai chiều này giúp duy trì tính toàn vẹn của hệ thống trong suốt quá trình chuyển đổi.\nKhuyên dùng triển khai lớp chuyển tiếp bằng dịch vụ container như Amazon Elastic Container Service (ECS) hoặc các phương án tính toán khác phù hợp. Mã nguồn thành phần này đơn giản: đăng ký một chủ đề trên broker rồi publish sang broker kia. Deployment bằng container giúp linh hoạt scale up/down tùy nhu cầu di chuyển.\nGiai đoạn 1: Di chuyển backend﻿ Giai đoạn này tập trung di chuyển dịch vụ backend từ broker tự quản lý sang AWS IoT Core. Hãy cùng xem cách tận dụng lớp chuyển tiếp để di chuyển backend từng bước mà không mất thông tin.\nLớp chuyển tiếp thiết bị đến backend﻿ Trong quá trình di chuyển backend, duy trì phân phối tin nhắn đều qua các subscription chia sẻ là tối quan trọng để tránh quá tải subscriber. Lớp chuyển tiếp tích hợp mượt mà với instance có sẵn, dùng mô hình subscription chia sẻ, đảm bảo phân phối tin nhắn cân bằng. Khi tin nhắn đi qua lớp này sang instances đã di chuyển, kiểm soát kỹ từng thành phần để ngăn quá tải. Tiến trình cẩn trọng giúp di chuyển từ từ, giữ nguyên mô hình phân phối tin nhắn và ổn định hệ thống.\nLớp chuyển tiếp backend đến thiết bị﻿ BTD triển khai cấp cluster ECS của Amazon, kết nối tới AWS IoT Core để tiêu thụ tin nhắn. Khác lớp DTB, tất cả instances BTD có thể triển khai đồng thời vì mỗi instance xử lý chủ đề thiết bị riêng biệt, không lo quá tải. Điều này giúp đẩy nhanh di chuyển backend mà vẫn đảm bảo tin nhắn tới thiết bị.\nHình 5: Kiến trúc trực quan hóa Lớp xuất bản lại thiết bị từ phía sau cho quá trình di chuyển dịch vụ A\nTrong quá trình di chuyển backend, khuyến nghị thiết lập AWS IoT Core rule để lưu tin nhắn vào Amazon S3 như lớp backup quan trọng. Việc lưu backup cho phép phục hồi và xử lý lại nếu có sự cố ngoài dự kiến, đảm bảo không mất dữ liệu từ thiết bị.\nVới lớp chuyển tiếp hoạt động ổn định, tiến trình di chuyển theo từng bước hệ thống như sau:﻿\nGiới thiệu instance DTB đầu tiên﻿\nKiểm tra luồng tin nhắn qua instance này đến AWS IoT Core và về thiết bị﻿\nLoại bỏ instance backend chưa di chuyển tương ứng﻿\nTiếp tục lần lượt với tất cả instance backend﻿\nPhương pháp này giúp chuyển đổi mượt mà toàn bộ dịch vụ backend sang AWS IoT Core. Chiến lược tương tự áp dụng cho các dịch vụ nền tảng khác, đảm bảo liên tục vận hành qua toàn bộ quá trình.\nHình 6: Kiến trúc trực quan hóa quá trình hoàn tất di chuyển phần phụ trợ sang AWS IoT\nGiai đoạn 2: Di chuyển thiết bị﻿ Giai đoạn này đặc biệt cần chú ý chi tiết vì ảnh hưởng trực tiếp đến trải nghiệm người dùng và kết nối thiết bị.﻿\nChìa khóa để di chuyển thiết bị thành công là chiến lược định tuyến DNS có trọng số (hay chiến lược tùy chọn), ví dụ dịch vụ Amazon Route 53 (hoặc bất kỳ DNS nào). Phương án này cho phép điều tiết chi tiết quá trình chuyển đổi:\nBắt đầu với tỷ lệ nhỏ (thường 1–2%) lưu lượng chuyển sang AWS IoT Core.﻿\nGiám sát kết nối thiết bị, chuyển giao tin nhắn, khả năng vượt ngưỡng throttling và tỷ lệ lỗi dựa vào metric AWS IoT và dimension trong Amazon CloudWatch.﻿\nTăng dần tỷ lệ dựa trên chỉ số hiệu năng.﻿\nDuy trì khả năng đảo ngược lưu lượng nhanh khi cần.﻿\nGiai đoạn này khai thác chức năng đăng ký tự động thời gian thực của AWS IoT Core, tự động cấp phát tài nguyên kết nối thiết bị. Tự động hóa này tối giảm gánh nặng vận hành khi di chuyển quy mô lớn.\nHình 7: Kiến trúc trực quan hóa quá trình di chuyển thiết bị\nSau khi hoàn tất di chuyển thiết bị, lớp chuyển tiếp vẫn hoạt động, tiếp tục chuyển tin nhắn về broker tự quản lý. Thiết kế này làm đường quay lại thiết yếu – nếu có sự cố, có thể ngay lập tức chuyển lưu lượng về broker cũ mà vẫn duy trì giao tiếp tin nhắn giữa thiết bị và backend.\nGiai đoạn 3: Dọn dẹp﻿ Giai đoạn dọn dẹp hoàn tất quá trình di chuyển. Lớp chuyển tiếp được loại bỏ trước, tách biệt broker tự quản lý. Sau khi hệ thống giám sát và các thành phần phụ xác nhận không còn lưu lượng đến broker cũ, và toàn bộ hệ thống vận hành ổn định qua AWS IoT Core, tiến hành kết thúc hoạt động broker — hoàn tất di chuyển.\nHình 8: Kiến trúc trực quan hóa quá trình di chuyển hoàn tất khớp với kiến ​​trúc mục tiêu\nTrình tự được kiểm soát này giúp quá trình chuyển đổi diễn ra mượt mà, đồng thời duy trì sự ổn định của hệ thống trong suốt giai đoạn chuyển đổi cuối cùng.\nKết luận﻿ Các tổ chức có thể di chuyển thành công đội thiết bị IoT lớn lên AWS IoT Core theo phương pháp từng giai đoạn và tuân thủ chiến lược năm trụ cột. Mô hình này giảm thiểu rủi ro, cung cấp các cơ chế failback ở mọi giai đoạn. Tiến trình chuẩn bị, di chuyển backend, di chuyển thiết bị và dọn dẹp đảm bảo chuyển đổi có quy trình và bảo mật, cho phép cả backend và thiết bị di chuyển với tốc độ riêng, duy trì tính ổn định vận hành.\nĐể có phân tích chi tiết, tương tác trực quan về hành trình di chuyển, mời theo dõi loạt video hướng dẫn trên kênh YouTube AWS IoT: Phần 1 và Phần 2. Các video này cung cấp thêm các góc nhìn và minh hoạ thực tế cho các khái niệm trong bài. Để biết thêm các case khách hàng và đối tác đã di chuyển lên AWS IoT, hãy xem bài blog này.\nHãy nhớ, chuyển đổi IoT thành công không chỉ đơn thuần là di chuyển hệ thống — mà là xây dựng nền tảng cho mở rộng trong tương lai, đồng thời đảm bảo liên tục kinh doanh suốt quá trình chuyển đổi.\nVề tác giả﻿ Andrea Sichel Andrea Sichel là Kiến trúc sư giải pháp IoT chuyên sâu tại Amazon Web Services, nơi ông hỗ trợ khách hàng trong hành trình ứng dụng đám mây lĩnh vực IoT. Bằng sự tò mò và triết lý đặt khách hàng lên hàng đầu, ông phát triển các giải pháp sáng tạo và luôn cập nhật công nghệ mới nhất. Andrea thích đối mặt các bài toán phức tạp và giúp tổ chức mở rộng tầm nhìn về chuyển đổi IoT. Ngoài công việc, Andrea huấn luyện đội bóng đá cho con trai và đam mê nhiếp ảnh. Khi không ở trên sân bóng hay sau máy ảnh, ông thường bơi lội để duy trì sự cân bằng giữa công việc và cuộc sống. Katja-Maja Kroedel Katja-Maja Kroedel là chuyên gia vận động về cơ sở dữ liệu và IoT tại AWS. Cô giúp khách hàng khai thác tối đa tiềm năng của công nghệ đám mây. Với nền tảng kỹ thuật máy tính và kinh nghiệm sâu rộng về IoT \u0026amp; databases, cô cộng tác chặt chẽ với khách hàng về định hướng áp dụng đám mây, chiến lược và di chuyển hệ thống trong những lĩnh vực này. Katja yêu thích công nghệ đổi mới, xây dựng và thử nghiệm với dịch vụ như AWS IoT Core, AWS RDS. "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/3-blogstranslated/3.4-blog4/",
	"title": "Blog 4",
	"tags": [],
	"description": "",
	"content": " "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/3-blogstranslated/3.5-blog5/",
	"title": "Blog 5",
	"tags": [],
	"description": "",
	"content": " "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/3-blogstranslated/3.6-blog6/",
	"title": "Blog 6",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/5-workshop/5.4-s3-onprem/5.4.1-prepare/",
	"title": "Chuẩn bị tài nguyên",
	"tags": [],
	"description": "",
	"content": "Để chuẩn bị cho phần này của workshop, bạn sẽ cần phải:\nTriển khai CloudFormation stack Sửa đổi bảng định tuyến VPC. Các thành phần này hoạt động cùng nhau để mô phỏng DNS forwarding và name resolution.\nTriển khai CloudFormation stack Mẫu CloudFormation sẽ tạo các dịch vụ bổ sung để hỗ trợ mô phỏng môi trường truyền thống:\nMột Route 53 Private Hosted Zone lưu trữ các bản ghi Bí danh (Alias records) cho điểm cuối PrivateLink S3 Một Route 53 Inbound Resolver endpoint cho phép \u0026ldquo;VPC Cloud\u0026rdquo; giải quyết các yêu cầu resolve DNS gửi đến Private Hosted Zone Một Route 53 Outbound Resolver endpoint cho phép \u0026ldquo;VPC On-prem\u0026rdquo; chuyển tiếp các yêu cầu DNS cho S3 sang \u0026ldquo;VPC Cloud\u0026rdquo; Click link sau để mở AWS CloudFormation console. Mẫu yêu cầu sẽ được tải sẵn vào menu. Chấp nhận tất cả mặc định và nhấp vào Tạo stack. Có thể mất vài phút để triển khai stack hoàn tất. Bạn có thể tiếp tục với bước tiếp theo mà không cần đợi quá trình triển khai kết thúc.\nCập nhật bảng định tuyến private on-premise Workshop này sử dụng StrongSwan VPN chạy trên EC2 instance để mô phỏng khả năng kết nối giữa trung tâm dữ liệu truyền thống và môi trường cloud AWS. Hầu hết các thành phần bắt buộc đều được cung cấp trước khi bạn bắt đầu. Để hoàn tất cấu hình VPN, bạn sẽ sửa đổi bảng định tuyến \u0026ldquo;VPC on-prem\u0026rdquo; để hướng lưu lượng đến cloud đi qua StrongSwan VPN instance.\nMở Amazon EC2 console\nChọn instance tên infra-vpngw-test. Từ Details tab, copy Instance ID và paste vào text editor của bạn để sử dụng ở những bước tiếp theo\nĐi đến VPC menu bằng cách gõ \u0026ldquo;VPC\u0026rdquo; vào Search box\nClick vào Route Tables, chọn RT Private On-prem route table, chọn Routes tab, và click Edit Routes.\nClick Add route. Destination: CIDR block của Cloud VPC Target: ID của infra-vpngw-test instance (bạn đã lưu lại ở bước trên) Click Save changes "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch: DX Talk #7 — Reinventing DevSecOps with AWS Generative AI Mục đích sự kiện Chia sẻ tác động của AI trong vận hành hệ thống và các case study thực tế.\nDiễn giả Lê Thanh Đức — Cloud Delivery Manager, CMC Global Dư Quốc Thành — Technical Leader, CMC Global Văn Hoàng Kha — Cloud Engineer, AWS Community Builder Nội dung chính 1. Bối cảnh chung của DevSecOps và tác động của AI Vì sao DevSecOps: Nhiều doanh nghiệp đang chuyển sang mô hình Agile DevSecOps để rút ngắn thời gian release, tăng tự động hóa và đưa sản phẩm ra sớm hơn. Khi tốc độ phát hành tăng, rủi ro bảo mật cũng tăng theo. Ví dụ: một commit có thể chứa secret; dependency hoặc image có thể có lỗ hổng chưa được scan kỹ. Trước đây, bảo mật thường là nhiệm vụ của team Security (sau khi Dev và Ops hoàn thành), dẫn đến thay đổi khó khăn và chi phí khắc phục lớn (có thể gấp 10–20 lần). Vì vậy, security cần được tích hợp xuyên suốt từ đầu đến cuối. Ngoài việc thêm công cụ và framework vào pipeline, mọi thành viên trong team đều phải chịu trách nhiệm về security (Dev hiểu rủi ro khi code; Ops hiểu quy trình an toàn khi triển khai; Security hiểu cách DevOps vận hành). 2. Framework cho DevOps LifeCycle Framework được chia thành 3 lớp chính:\nLớp đầu: đưa bảo mật vào càng sớm càng tốt\nVí dụ: SAST để quét mã nguồn, Software Composition Analysis để kiểm tra dependency, scan script để phát hiện API key hoặc credential lộ trong code. Lớp giữa: áp dụng DevSecOps khi Build và Deploy, tập trung kiểm soát an toàn trong môi trường triển khai\nVí dụ: sử dụng các tool DAST để kiểm tra lỗ hổng trong image. Lớp cuối: Runtime Security và Continuous Feedback.\n3. 7 phase chính trong DevOps LifeCycle (Case studies thực tế) Phase 1: PLAN — Lập kế hoạch\nXác định yêu cầu bảo mật ngay từ khâu lập kế hoạch sản phẩm. Phân tích rủi ro, xây dựng model AThreast, đặt mục tiêu tuân thủ phù hợp với quy định/tiêu chuẩn dự án. Ba nhóm Dev — Sec — Ops cần thống nhất mục tiêu, quy trình và nguồn lực để đảm bảo Security gắn liền với Business từ đầu. Xác định rõ Security Roadmap. Phase 2: CODE — Viết mã\nBảo mật được đưa trực tiếp vào môi trường viết code. Developer cần tuân thủ secure coding standards và code review. Dùng SAST để phát hiện lỗi trong quá trình viết code. Hình thành tư duy \u0026ldquo;Security-First\u0026rdquo; cho developer. Phase 3: BUILD — Xây dựng\nTự động hóa hoàn toàn chuỗi CI/CD. Công cụ: dependency scan, config validation để đảm bảo build không chứa mã độc hay lỗ hổng. Đảm bảo bản build ổn định, có thể tái sử dụng và đảm bảo toàn vẹn phần mềm trước khi release. Phase 4: TEST — Kiểm thử\nThực hiện kiểm thử bảo mật toàn diện. Chạy vulnerability scan, DAST, penetration test, audit. Cập nhật test case theo các lỗ hổng được phát hiện. Phase 5: DEPLOY — Triển khai\nKiểm tra cấu hình \u0026amp; IaC, policy-as-code trước khi deploy. Đảm bảo runtime environment tuân thủ tiêu chuẩn bảo mật đã thống nhất. Giảm lỗi thủ công, đảm bảo deploy an toàn. Phase 6: OPERATE — Vận hành\nTự động vá lỗi và cập nhật bảo mật liên tục. Duy trì ổn định và an toàn sau release. Phase 7: MONITOR — Giám sát\nGiám sát liên tục. Dùng Realtime Analytics và các tool cảnh báo các mối đe dọa. DevSecOps giúp chủ động phòng ngừa thay vì phản ứng, giữ phần mềm ở trạng thái an toàn. 4. Công cụ hỗ trợ DevSecOps Pre-commit \u0026amp; Code Quality: SonarQube, Codacy, Semgrep (SAST), Gitleaks — scan code, kiểm tra code coverage, kiểm tra secret. Dependency \u0026amp; SBOM Scanning: Syft, Grype, Dependency-Track — quản lý package và lỗ hổng thư viện. IaC \u0026amp; Policy-as-Code: Checkov, Tfsec — quét Terraform/Kubernetes config; OPA Gatekeeper, Kyverno — enforce policy \u0026amp; compliance tự động. SAST/DAST \u0026amp; Security Tests: Trivy, Checkmarx, Semgrep, Codacy — phát hiện lỗ hổng ở code và runtime. CI/CD Integration: Jenkins, GitHub Actions, GitLab CI, ArgoCD — tự động hóa build, test, deploy an toàn. Monitoring \u0026amp; Logging: Prometheus, Grafana, Loki, Promtail — giám sát và quan sát hệ thống realtime. Alerting \u0026amp; Governance: Slack webhook, email alerts, anomaly detection — cảnh báo và phản ứng nhanh; centralized risk report — báo cáo và phân tích rủi ro tập trung. 5. Case studies thực tế về Gen-AI trong DevSecOps Demo pipeline anh Thành: CI/CD flowchart (mô tả tóm tắt) — (Dự án Blockchain Singapore — Anh Thành)\nDemo pipeline anh Đức:\nPull source code từ Bitbucket — Build bằng MSBuild — SonarQube analysis — Check SonarQube Quality Gate — Archive files — Push artifacts.\nDemo CI/CD pipeline (Dự án khách hàng Philippines — Anh Đức)\nTừ DevOps đến AIOps? =\u0026gt; Các toolchain DevOps hiện nay đều tích hợp Gen-AI bên trong.\nTác động của AI đối với DevOps:\nAI giúp phát hiện và phân tích lỗ hổng thông minh hơn. AI hỗ trợ tự động hóa phản ứng và khắc phục sự cố. AI giúp rút ngắn thời gian và giảm tải cho team bảo mật. AI giúp DevSecOps liên tục học và cải thiện theo thời gian. Lợi ích của Gen-AI trong DevOps:\nTự động hóa và tăng tốc quy trình DevSecOps. Tăng cường bảo mật chủ động. Tối ưu hóa quan sát và phản ứng sự cố. Demo: sử dụng Amazon-Q để scan lỗ hổng từ file code; sử dụng Amazon-Q để test Terraform MCP.\nQ/A — Các câu hỏi hay và trả lời Làm thế nào AI/ML có thể tối ưu hóa chi phí AWS (cost optimization)?\n=\u0026gt; Sử dụng các công cụ ước tính do AWS cung cấp để chọn đúng tài nguyên. Có thể tích hợp Auto Scaling policy dựa trên dự đoán, logs CloudWatch theo khung giờ hoặc ngưỡng để tắt khi không sử dụng. Một số dịch vụ hữu ích: AWS Compute Optimizer, Cost Explorer, \u0026hellip;\nAI có tự động khắc phục lỗi bảo mật không? Nếu có, con người nên tập trung vào phần nào của DevSecOps pipeline?\n=\u0026gt; Có. AI có thể tự động khắc phục một số lỗi bảo mật, nhưng chỉ nên coi AI là công cụ hỗ trợ. Mọi phần trong pipeline vẫn cần có sự giám sát chặt chẽ của con người, dù AI mạnh đến đâu.\n"
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/4-eventparticipated/4.3-event3/",
	"title": "Event 3",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “[GAPV] Introduction to AI/ML GenAI with AWS” Mục Đích Của Sự Kiện Chia sẻ các khái niệm cốt lõi trong AI, Machine Learning, Deep Learning và LLM Chia sẽ về vai trò của AWS trong việc hỗ trợ và tối ưu hóa các công nghệ này Danh Sách Diễn Giả Phạm Nguyễn Hải Anh - Cloud Engineer\nNội Dung Nổi Bật Các khái niệm ML, Deep Learning, LLM được chia sẽ theo hướng tiến hóa, migrate phiên bản sau so với phiên bản trước. AWS tự sản xuất ra Graviton Processor trải qua bốn thế hệ, các thế hệ sau hiệu suất cao hơn trước đồng nghĩa với việc chi phí sẽ cao hơn Với Gravition này thì sẽ ưu tiên sử dụng cho các quá trình inference Các trường hợp sử dụng Gravition Processor phù hợp: Có thể sinh ra text với các mô hình lên tới 70 tỷ tham số Chuẩn bị và xử lý dữ liệu Kỹ thuật Retrieval Augmented Generation (RAG) Deep Learning, GPU và các yếu tố ảnh hường tới chi phí và thời gian: Chi phí của instance trong 1 đơn vị thời gian, thời gian huấn luyện (phụ thuộc vào số lượng paramater của model) Số lượng mẫu trong dataset Sức mạnh tính toán của tài nguyên sử dụng Các thách thức trong inference: Độ trễ khi model sinh ra văn bản, tốc độ gửi văn bản Chi phí để host instance AWS kết hợp với NVIDIA tạo ra các CPU P5, P4 dành cho training và G6, G5 dành cho inference AWS AI Chips do AWS tự sản xuất như Inferentia 2 và Trainium 2 phụ vụ cho training và inference Các dịch vụ AI của AWS Amazon Rekognition (Xử lý Ảnh/Video)\nPain point: quá trình đầu tư đắt đỏ, quá trình xử lý phức tạp, tốc độ phát triển nhanh chóng và kham hiếm nguồn lực về ML Cách giải quyết của Amazon Rekognition là cung cấp khả năng quản lý đơn giản hơn theo hướng no-code/low-code, xây dựng nhanh chóng thông qua SDK/API, đưa qua kết quả chất lương cao, không cần hỗ trợ của chuyên gia AI, cho phép custom dễ dàng. Các dịch vụ chính: Content moderation: Quản lý nội dung, phát hiện nội dung tiêu cực Face Livness: Chống giả mạo khuôn mặt Face detection and analysis: Nhận biết giới tính, tuổi tác, cảm xúc trên khuôn mặt Face search: Nhận diện khuôn mặt trong tập dữ liệu lớn (lên đến 20 tỷ khuôn mặt) Trích xuất ID: Trích xuất thông tin từ hồ sơ, tài liệu Amazon SageMaker Canvas (No-Code/Low-Code)\nPaint point: Các team quản lý ML thiếu hụt nguồn nhân lực ML, cần nhiều kỹ năng về code và kỹ thuật, khó cập nhật các công cụ hỗ trợ phát triển nhanh chóng. Cách giải quyết của SageMaker Canvas là cung cấp các mô hình có sẵn được train trước, cho phép custom với dữ liệu riêng mà không cần phải biết code. Generative AI (Amazon Bedrock)\nPaint point: Thiếu Foundation Model được huấn luyện cụ thể cho một tác vụ, nhu cầu custom Foundation Model với dữ liệu nội bộ của doanh nghiệp(dữ liệu cần bảo vệ riêng tư) và khó khăn trong quản lý cơ sở hạ tầng và chi phí. Cách giải quyết của Bedrock là cung cấp các API để truy cập các Foundation Model nổi tiếng trên thế giới(Cloud, Stable Diffusion,\u0026hellip;), cho phép custom các Foundation Model với dữ liệu riêng của doanh nghiệp. Kỹ thuật RAG giúp cải thiện độ chính xác và chất lượng nội dung của Foundation Model, tránh hiện tượng ảo tưởng khi mô hình đưa ra thông tin sai lệch. Thách thức khi xây dựng RAG là quản lý nhiều nguồn dữ liệu, lựa chọn kiểu vector phù hợp để chuyển đổi tài liệu sang dữ liệu số, và nỗ lực xây dựng mô hình/hệ thống. Knowledge Base của Bedrock: Cung cấp khả năng quản lý hoàn toàn bởi AWS, cho phép truy cập Foundation Model và Agent một cách bảo mật, dễ dàng truy cập dữ liệu liên quan Bảo mật của Bedrock sử dụng Guardrails: Giúp sàng lọc, không tiết lộ dữ liệu nhạy cảm (PII) Định nghĩa các hành vi để block (vd: Không được gen ra các nội dung bạo lực, nhạy cảm) Giới hạn nội dung được cho phép sinh ra để tránh ảo tưởng Các model mới trên Bedrock: Nova Canvas (sinh ảnh độ phân giải 2k x 2k) Nova Reel (sinh video từ text và ảnh) Bài học rút ra Có cái nhìn toàn diện về cách AWS hỗ trợ các doanh nghiệp tận dụng sức mạnh của AI/ML và GenAI. LLM là một dạng Deep Learning Deep Learning là một nhánh của Machine Learning Machine Learning là một phần của Trí tuệ nhân tạo (AI) "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/5-workshop/5.1-workshop-overview/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu về VPC Endpoint Điểm cuối VPC (endpoint) là thiết bị ảo. Chúng là các thành phần VPC có thể mở rộng theo chiều ngang, dự phòng và có tính sẵn sàng cao. Chúng cho phép giao tiếp giữa tài nguyên điện toán của bạn và dịch vụ AWS mà không gây ra rủi ro về tính sẵn sàng. Tài nguyên điện toán đang chạy trong VPC có thể truy cập Amazon S3 bằng cách sử dụng điểm cuối Gateway. Interface Endpoint PrivateLink có thể được sử dụng bởi tài nguyên chạy trong VPC hoặc tại TTDL. Tổng quan về workshop Trong workshop này, bạn sẽ sử dụng hai VPC.\n\u0026ldquo;VPC Cloud\u0026rdquo; dành cho các tài nguyên cloud như Gateway endpoint và EC2 instance để kiểm tra. \u0026ldquo;VPC On-Prem\u0026rdquo; mô phỏng môi trường truyền thống như nhà máy hoặc trung tâm dữ liệu của công ty. Một EC2 Instance chạy phần mềm StrongSwan VPN đã được triển khai trong \u0026ldquo;VPC On-prem\u0026rdquo; và được cấu hình tự động để thiết lập đường hầm VPN Site-to-Site với AWS Transit Gateway. VPN này mô phỏng kết nối từ một vị trí tại TTDL (on-prem) với AWS cloud. Để giảm thiểu chi phí, chỉ một phiên bản VPN được cung cấp để hỗ trợ workshop này. Khi lập kế hoạch kết nối VPN cho production workloads của bạn, AWS khuyên bạn nên sử dụng nhiều thiết bị VPN để có tính sẵn sàng cao. "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/1-worklog/",
	"title": "Nhật ký công việc",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTrong trang này bạn sẽ cần giới thiệu worklog của bạn như thế nào? Bạn hoàn thành chương trình trong vòng bao nhiêu tuần? Bạn đã làm gì trong các tuần đó?\nThông thường và cũng là tiêu chuẩn, một worklog được thực hiện trong khoảng 3 tháng (trong suốt thời gian thực tập) với nội dung các tuần như sau:\nTuần 1: Làm quen với AWS và các dịch vụ cơ bản trong AWS\nTuần 2: Làm công việc A\u0026hellip;\nTuần 3: Làm công việc B\u0026hellip;\nTuần 4: Làm công việc C\u0026hellip;\nTuần 5: Làm công việc D\u0026hellip;\nTuần 6: Làm công việc E\u0026hellip;\nTuần 7: Làm công việc G\u0026hellip;\nTuần 8: Làm công việc H\u0026hellip;\nTuần 9: Làm công việc I\u0026hellip;\nTuần 10: Làm công việc L\u0026hellip;\nTuần 11: Làm công việc M\u0026hellip;\nTuần 12: Làm công việc N\u0026hellip;\n"
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/5-workshop/5.3-s3-vpc/5.3.1-create-gwe/",
	"title": "Tạo một Gateway Endpoint",
	"tags": [],
	"description": "",
	"content": " Mở Amazon VPC console Trong thanh điều hướng, chọn Endpoints, click Create Endpoint: Bạn sẽ thấy 6 điểm cuối VPC hiện có hỗ trợ AWS Systems Manager (SSM). Các điểm cuối này được Mẫu CloudFormation triển khai tự động cho workshop này.\nTrong Create endpoint console: Đặt tên cho endpoint: s3-gwe Trong service category, chọn aws services Trong Services, gõ \u0026ldquo;s3\u0026rdquo; trong hộp tìm kiếm và chọn dịch vụ với loại gateway Đối với VPC, chọn VPC Cloud từ drop-down menu. Đối với Route tables, chọn bảng định tuyến mà đã liên kết với 2 subnets (lưu ý: đây không phải là bảng định tuyến chính cho VPC mà là bảng định tuyến thứ hai do CloudFormation tạo). Đối với Policy, để tùy chọn mặc định là Full access để cho phép toàn quyền truy cập vào dịch vụ. Bạn sẽ triển khai VPC endpoint policy trong phần sau để chứng minh việc hạn chế quyền truy cập vào S3 bucket dựa trên các policies. Không thêm tag vào VPC endpoint. Click Create endpoint, click x sau khi nhận được thông báo tạo thành công. "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/1-worklog/1.1-week1/",
	"title": "Worklog Tuần 1",
	"tags": [],
	"description": "",
	"content": " Mục tiêu tuần 1: Kết kết nối, tìm kiếm thành viên cho nhóm. Tìm hiểu các dịch vụ AWS. Tạo tài khoản AWS đầu tiên, làm quen với console, quản lý chi phí. Tìm hiểu về các dịch vụ hổ trợ, cách gửi yêu cầu hổ trợ. Tìm hiểu về quản lý các truy cập, học cách thiết lập quản lý. Tìm hiểu về VPC, học cách thiết kế, triển khai và quản lý. Tìm hiểu về EC2, và triển khai ứng dụng Node.js trên EC2. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen các thành viên trong FCJ và tạo nhóm - Ghi nhớ các nội quy, quy định của văn phòng, và các hướng dẫn trong kỳ training đã được thông báo 08/08/2025 11/08/2025 3 - Tìm hiểu các dịch vụ AWS + Compute + Storage + Networking \u0026amp; Content Delivery + Database + Analysis + Management Tools + Developer Tools + Developer Tools + Machine Learning 09/08/2025 09/08/2025 https://cloudjourney.awsstudygroup.com/vi/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console\n- Tìm hiểu dịch vụ AWS support\n- Thực hành: + Tạo AWS account (Thiết lập MFA cho tài khoản) + Làm quen các thao tác trên console (Cài region mặc định, sử dụng thanh tìm kiếm dịch vụ, bookmark các dịch vụ thường dùng, cách sử dụng widgets) 09/08/2025 09/08/2025 https://000001.awsstudygroup.com/vi/ 5 - Tìm hiểu quản trị quyền truy cập với AWS IAM - Thực hành: + Tạo IAM Group, IAM Role, IAM User + Chuyển đổi IAM Role 10/08/2025 10/08/2025 https://000002.awsstudygroup.com/vi/ 6 - Tìm hiểu về VPC - Thực hành: + Học cách thiết kế, triển khai, quản lý môi trường trên AWS + Thiết lập kết nối Site-to-site VPN - Tìm hiểu về EC2 - Thực hành: + Khởi tạo các instance + Triển khai ứng dụng trên các instance vừa tạo 11/08/2025 12/08/2025 https://000003.awsstudygroup.com/vi/ 7 - Tìm hiểu về EC2 - Thực hành: + Khởi tạo các instance + Triển khai ứng dụng trên các instance vừa tạo 13/08/2025 14/08/2025 https://000004.awsstudygroup.com/vi/ Kết quả đạt được tuần 1: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking \u0026amp; Content Delivery Database Analysis Management Tools Developer Tools Developer Tools Machine Learning Đã tạo và cấu hình AWS Free Tier account thành công.\nBiết được 4 gói hổ trợ của AWS Support và những dịch vụ của từng gói.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nHiểu được IAM là gì: IAM dùng để định danh và phân quyền xem ai hoặc dịch vụ nào có thể truy cập như thế nào vào các tài nguyên trên AWS\nPhân biệt được các thành phần chính trong IAM:\nIAM User: Là 1 người dùng đăng nhập vào AWS Console để thực hiện các tác vụ quản trị hằng ngày IAM Group: Đại diện cho 1 nhóm user trên hệ thống thường Dùng để phân chia quyền theo vai trò của dự án hoặc phòng ban \u0026hellip; Group này không thể chứa group khác 1 user có thể thuộc nhiều group hoặc không thuộc group nào IAM Role: Dùng để gán quyền truy cập tạm thời cho 1 thực thể có thể tương tác với các tài nguyên khác (thường gắn vào EC2, Lambda, \u0026hellip;) ** Một số tài nguyên không thể tương tác được tới tài nguyên khác trên AWS nếu không được gán role (trong role có policies để xác định tài nguyên này được phép làm gì)\nIAM Policies: Quy định user, nhóm, vai trò có thể hoặc không thể làm gì (là văn bản viết bằng JSON) Inline Policy: Policy được tạo và gán trực tiếp trong thực thể Managed Policy: Policy tạo riêng, gán được nhiều thực thể IAM Switch Role: Thực thể sẽ tạm thời bỏ những quyền hiện tại của mình và sẽ sử dụng những quyền của thực thể mình đã switch tới Hiểu được VPC là gì, kiến trúc và các thành phần chính của VPC:\nSubnet: Mạng con trong VPC, chia thành Public - Private Subnet Route Table: Bảng định tuyến, điều hướng lưu lượng mạng (mỗi subnet phải được liên kết với 1 Route Table) (có thì EC2 mới ra internet được) Internet Gateway: Cho phép các Public Subnet truy cập internet NAT Gateway: Cho phép các Private Subnet kết nối ra internet nhưng không cho kết nối vào Biết cách tạo 1 VPC, tạo các Subnet, Internet Gateway, Route Table, tạo Security Group\nTriển khai EC2 instance trong Subnet vừa tạo trước đó và thực hiện kết nối\nTạo NAT Gateway để kết nối EC2 instance được tạo trong private Subnet ra internet\nBiết cách thiết lập CloudWatch và Alerting các chỉ số VPC\nTạo thành công môi trương VPN gồm VPC và EC2\nThiết lập kết nối Site to Site VPN giữa hai VPC thông qua Virtual Private Gateway và Customer Gateway\nKhởi tạo Windows instance, Linux instance và kết nối thành công\nCài đặt LAMP và XAMPP để triển khai ứng dụng AWS FCJ Management trên Window instance và Linux instance\n"
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/1-worklog/1.2-week2/",
	"title": "Worklog Tuần 2",
	"tags": [],
	"description": "",
	"content": " Mục tiêu tuần 2: Biết cách triển khai, quản lý cơ sở dữ liệu trên RDS Biết cách cấp quyền cho ứng dụng EC2 và hiểu được nên sử dụng cách nào Tìm hiểu về dịch vụ lưu trữ dạng đối tượng S3 Tìm hiểu về Lightsail và xây dựng ứng dụng trên đó Làm quen với giao diện Amazon CloudWatch và cách sử dụng để quản lý cung cấp dữ liệu Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Triển khai hệ thống backend sử dụng Amazon EC2, Amazon RDS và Node.js - Thực hành: + Tạo VPC, subnet, security group cho EC2 và RDS + Tạo EC2 instance, SSH bằng MobaXterm + Cài Git, Node.js, MySQL client trên EC2 + Clone source code từ GitHub + Cài đặt npm packages, cấu hình .env kết nối RDS + Thực hiện backup, restore, monitoring RDS 15/09/2025 15/09/2025 https://000005.awsstudygroup.com/vi/ 3 - Cấp quyền cho ứng dụng truy cập dịch vụ AWS bằng IAM Role - Thực hành: + Tạo EC2, S3 bucket, IAM User với Access Key + Upload file lên S3 bằng access key (không an toàn) + Tạo IAM Role gán vào EC2 để upload lên S3 (an toàn) - Sử dụng AWS Cloud9 cho lập trình - Thực hành: + Tạo Cloud9 instance + Dùng terminal, tạo file, chỉnh sửa văn bản, chạy AWS CLI 16/09/2025 16/09/2025 https://000048.awsstudygroup.com/vi/ https://000049.awsstudygroup.com/vi/ 4 - Triển khai website tĩnh trên Amazon S3 và tăng tốc bằng CloudFront - Thực hành: + Tạo S3 bucket và upload dữ liệu website + Bật Static Website Hosting và cấu hình index.html + Cấu hình Block Public Access và thiết lập truy cập công khai cho đối tượng cần thiết + Kiểm tra website qua S3 endpoint + Tích hợp CloudFront để tăng tốc và giữ bucket private + Bật S3 Versioning, thực hành thay đổi file index.html và khôi phục phiên bản cũ + Kiểm tra nội dung website qua CloudFront 17/09/2025 17/09/2025 https://000057.awsstudygroup.com/vi/ 5 - Triển khai hệ thống ứng dụng mã nguồn mở trên Amazon Lightsail - Thực hành: + Tạo Lightsail Database instance + Triển khai 3 ứng dụng: WordPress, PrestaShop và Akaunting + Cấu hình Networking (gán Static IP cho từng instance) + Kết nối database Lightsail + Cấu hình domain và Apache cho Akaunting + Tạo cơ sở dữ liệu MySQL riêng cho từng ứng dụng + Cấu hình tài khoản quản trị trong từng ứng dụng + Cấu hình bảo mật: · Tắt SSH (Port 22) · Thiết lập Firewall Rules - Triển khai container với Amazon Lightsail Containers - Thực hành: + Tạo Lightsail Container + Triển khai container từ public image Nginx + Tạo Lightsail Container + Tạo Lightsail Instance, cài Docker và AWS CLI + Build container image, push lên Lightsail, deploy container image 18/09/2025 18/09/2025 https://000045.awsstudygroup.com/vi/ https://000046.awsstudygroup.com/vi/ 6 - Làm quen sử dụng CloudWatch Dashboards Thực hành: + Dùng CloudFormation tạo EC2 instances với ứng dụng mẫu để sinh metrics và logs + Xem, lọc, tính toán và hiển thị metrics từ ứng dụng trên EC2 + Quan sát logs, tạo log groups/streams, metric filters + Tạo alarm dựa trên metrics và nhận thông báo qua SNS 19/09/2025 19/09/2025 https://000008.awsstudygroup.com/vi/ Kết quả đạt được tuần 2: Biết cách cài đặt môi trường EC2 và kết nối RDS bằng ứng dụng Node.js. Biết dùng Git để pull mã nguồn và cấu hình file .env Biết cách khôi phục database từ Snapshot Biết cách sử dụng IAM role để đảm bảo bảo mật cho ứng dụng chạy trên EC2 Triển khai thành công 3 ứng dụng trên Lightsail (WordPress, PrestaShop, Akaunting) Cấu hình DB, static IP, bảo mật SSH, và thao tác thành thạo giao diện Lightsail Hiểu và vận dụng Lightsail Container, Docker, AWS CLI Build, push và deploy container image thành công Truy cập public endpoint kiểm tra nội dung hiển thị đúng Tạo và cấu hình S3 bucket lưu trữ website tĩnh, bật versioning và quản lý quyền truy cập Tích hợp CloudFront để phân phối nhanh, bảo mật bucket, website hiển thị chính xác và load nhanh Làm quen với Amazon CloudWatch để giám sát hệ thống Thu thập và phân tích metrics Biết tạo alarms để nhận cảnh báo khi hệ thống gặp sự cố "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/1-worklog/1.3-week3/",
	"title": "Worklog Tuần 3",
	"tags": [],
	"description": "",
	"content": " Mục tiêu tuần 3: Làm các bài lab:\nThiết lập Hybrid DNS với Route 53 Resolver Thao tác dòng lệnh với AWS CLI Cơ sở dữ liệu NoSQL với Amazon DynamoDB Bộ nhớ đệm trong bộ nhớ với Amazon ElastiCache Workshop về mạng trên AWS Phân phối nội dung với Amazon CloudFront Điện toán biên với CloudFront và Lambda@Edge Ứng dụng Windows trên AWS Dịch vụ thư mục với AWS Managed Microsoft AD Xây dựng ứng dụng web có tính sẵn sàng cao Dịch chuyển máy chủ ảo với AWS VM Import/Export Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Triển khai kiến trúc DNS hybrid - Thực hành + Tạo một AWS Managed Microsoft Active Directory bằng dịch vụ AWS Directory Service để mô phỏng cho hệ thống DNS on-prem + Tạo Outbound Endpoint (forward truy vấn DNS đến DNS nội bộ) + Tạo Resolver Rules + Tạo Inbound Endpoint (cho phép DNS nội bộ gửi truy vấn DNS đến Route 53) - Làm quen với AWS CLI - Thực hành + Cài đặt, cấu hình AWS CLI + Thực hành sử dụng các lệnh cli với các dịch vụ AWS - Tìm hiểu và nắm vững khái niệm, cấu trúc, khả năng của DynamoDB cùng cách thao tác qua AWS CLI, Console, CloudShell và SDK Python - Thực hành + CRUD + Truy vấn + Quét dữ liệu + Sử dụng index 22/09/2025 22/09/2025 https://000010.awsstudygroup.com/vi/https://000011.awsstudygroup.com/vi/https://000060.awsstudygroup.com/vi/ 3 - Cơ sở dữ liệu NoSQL với Amazon DynamoDB - Bộ nhớ đệm trong bộ nhớ với Amazon ElastiCache\n- Workshop về mạng trên AWS 23/09/2025 23/09/2025 https://000060.awsstudygroup.com/vi/https://000061.awsstudygroup.com/vi/https://000092.awsstudygroup.com/vi/ 4 - Phân phối nội dung với Amazon CloudFront\n- Điện toán biên với CloudFront và Lambda@Edge\n- Ứng dụng Windows trên AWS 24/09/2025 24/09/2025 https://000094.awsstudygroup.com/vi/https://000130.awsstudygroup.com/vi/https://000093.awsstudygroup.com/ 5 - Dịch vụ thư mục với AWS Managed Microsoft AD\n- Xây dựng ứng dụng web có tính sẵn sàng cao 25/09/2025 25/09/2025 https://000095.awsstudygroup.com/https://000101.awsstudygroup.com/vi/ 6 - Dịch chuyển máy chủ ảo với AWS VM Import/Export\n26/09/2025 Kết quả đạt được tuần 3: Hiểu cách Route 53 hoạt động trong môi trường tích hợp Nắm được cách sử dụng các công cụ như Outbound/Inbound Endpoints và Resolver Rules để kiểm soát luồng truy vấn DNS Biết cách sử dụng aws configure để cấu hình cli Biết cách sử dụng script CLI để tổng hợp và quản lý tài nguyên sử dụng Hiểu các khái niệm và cấu trúc của DynamoDB Biết cách sử dụng CLI, console để thao tác với DynamoDB Nắm được khái niệm về cluster, node, shard và cách hoạt ododnjg của Redis Phân biệt được cluster-mode-enabled và cluster-mode-disabled Hiểu rõ mô hình AWS VPC, các thành phần chính và cách hoạt động của:\n- Subnet, Route Table, Internet Gateway, NAT Gateway\n- Security Group vs NACL\n- Elastic Network Interface (ENI) và Elastic IP (EIP) Phân biệt được các loại kết nối mạng:\n- VPC Peering: kết nối 1-1 giữa các VPC (không hỗ trợ transit routing)\n- Transit Gateway (TGW): kết nối nhiều VPC theo mô hình hub-and-spoke\n- VPN Site-to-Site: thiết lập mạng hybrid giữa AWS và on-prem\n- AWS Direct Connect: kết nối chuyên dụng, độ trễ thấp đến AWS Bảo vệ và tăng tốc S3 với CloudFront Có thể tự cấu hình CloudFront Distribution hoàn chỉnh Thực hành sử dụng dịch vụ VM Import/Export để import VM từ on-premises vào ec2 và ngược lại "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/1-worklog/1.4-week4/",
	"title": "Worklog Tuần 4",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/1-worklog/1.5-week5/",
	"title": "Worklog Tuần 5",
	"tags": [],
	"description": "",
	"content": " Mục tiêu tuần 5: Tìm hiểu về tối ưu hóa: vận hành, bảo mật, độ tin cậy, hiệu suất, tối ưu chi phí Làm các bài lab liên quan Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Lab 22: Bật tắt máy chủ tự động và nhắn tin qua Slack với AWS\n- Thực hành:\n+ Tạo EC2 instance\n+ Tạo lambda function, add webhook vào slack, lấy url của webhook để nhận được thông báo từ lambda url\n- Lab 29: Tạo bảng theo dõi hệ thống với Amazon Cloudwatch và Grafana\n- Thực hành:\n+ Tạo ec2 instance\n+ Tạo IAM User để cấu hình Grafana, tạo IAM role gán cho EC2 instance\n+ Cài đặt, cấu hình Grafana để xem thống kê CPUUtilization của instance ec2\n- Lab 27: Quản lý tài nguyên theo nhóm bằng Tag và Resouce Groups\n- Thực hành:\n+ Thêm tags khi khởi tạo các tài nguyên\n+ Tạo resource group để gom các tài nguyên liên quan\n- Lab 28: Quản lý truy cập dịch vụ EC2 bằng Tag thông qua IAM\n- Thực hành:\n+ Tạo các policy với các quyền quyền: Liệt kê EC2, gắn tag khi tạo ec2, gắn tags lên ec2 đã tồn tại, tạo ec2, quản lý instance state\n\u0026amp;emspl; + Gán Tạo role chứa các policy đó\n+ Gán role đó lên user - Lab 31: Quản lý dịch vụ và tự động hóa tác vụ sử dụng AWS System Manager\n- Thực hành:\n+ Tạo 2 windows instance làm ví dụ\n+ Gán quyền AmazonSSMManagedInstanceCore cho 2 instance này\n+ Cập nhật bản vá, bảo mật cho 2 instance cùng lúc bằng Patch manager\n+ Sử dụng Run command để gửi lệnh command từ xa\n- Lab 58: Làm việc với AWS System Manager - Session Manager\n- Thực hành: + Gán role AmazonSSMManageInstanceCore cho instance\n+ Kết nối đến instance Ec2 ra được internet\n+ Kết nối với instance Ec2 không ra được internet (thông qua 3 endpoint ssm, ssmmessages, ec2messages)\nSử dụng S3 bucket để lưu lại session log để xem lịch sử command 06/10/2025 06/10/2025 https://000022.awsstudygroup.com/vi/\nhttps://000029.awsstudygroup.com/vi\nhttps://000027.awsstudygroup.com/vi/\nhttps://000028.awsstudygroup.com/vi/\nhttps://000031.awsstudygroup.com/vi/\nhttps://000058.awsstudygroup.com/vi/ 3 - Lab 30: Giới hạn Quyền của User với IAM Permission Boundary\n- Thực hành:\n+ Tạo policy giới hạn quyền tối đa\n+ Tạo user sau đó set policy boudary\n- Lab 44: Giới hạn chuyển Role theo Condition\n- Thực hành: Tạo các IAM user, group user, cấu hình IAM Role, giới hạn các quyền truy cập cho IAM User\n- Lab 18: Kiểm tra đánh giá tiêu chuẩn bảo mật với AWS Security Hub\n- Lab 26: (NOT DONE) Bảo mật Ứng dụng và API với Web Application Firewall (AWS WAF)\n- Thực hành:\n+ - Lab 33: Quản lý Khóa với dịch vụ Key Management Service (AWS KMS)\n- Thực hành:\n+ Tạo các Policy, IAM User, User Group để phân quyền truy cập\n+ Tạo khóa đối xứng để\n+ Tạo Bucket S3, tải dữ liệu lên S3 và cấu hình mã hóa bằng key vừa tạo cho file\n+ Cấu hình Cloud Trail để ghi lại log hoạt động của S3 và Athena để truy vấn log được ghi trực tiếp trong S3 07/10/2025 07/10/2025 https://000030.awsstudygroup.com/vi/ https://000044.awsstudygroup.com/vi/ https://000018.awsstudygroup.com/vi/ https://000033.awsstudygroup.com/vi/ 4 - Lab 13: Triển khai kế hoạch sao lưu hệ thống với AWS Backup\n- Thực hành:\n+ Tạo Backup Plan, cấu hình lịch và tài nguyên cần sao lưu\n+ Cài đặt SNS Notification nhận thông báo về việc sau lưu\n- Lab 19: Liên kết các Virtual Private Cloud (VPC) với VPC Peering - Thực hành:\n+ Tạo 2 VPC\n+ Tạo VPC Peering để tạo kết nối giữa 2 VPC\n+ Cấu hình Route Table, VPC này thêm route đến VPC kia bằng Peering connection\n+ Cấu hình Networks ACL, chặn tất cả chỉ allow mỗi CIDR\n- Lab 20: Quản lý tập trung các kết nối với AWS Transit Gateway\n- Thực hành:\n+ Chuẩn bị 4 instance ec2 bằng CloudFormation\n+ Tạo Transit Gateway, sử dụng TGW Attachment để gắn liên kết giữa các VPC, sử dụng TGW Route Table để xác định đường đi 08/10/2025 08/10/2025 https://000013.awsstudygroup.com/vi/\nhttps://000019.awsstudygroup.com/vi/\nhttps://000020.awsstudygroup.com/vi/ 5 - Lab 15: Triển khai Ứng dụng với Docker\n- Thực hành:\n+ Triển khai ứng dụng trên local\n+ Triển khai bằng Docker Image\n+ Đóng gói từng service thành image\n+ Tạo một container network làm trung gian để các container chứa image này có thể giao tiếp với nhau\n\u0026amp;emsp + Triển khai từng container chứa các image\n+ Triển khai bằng Docker Compose\n+ Đóng gói các service thành image\n+ Cấu hình file .yml, sử dụng docker compose để cùng lúc các container được cấu hình trong file .yml\n+ Push các image lên ECR hoặc Docker Hub để lưu trữ các image\n- Xem lại lí thuyết của các dịch vụ 09/10/2025 11/10/2025 https://000015.awsstudygroup.com/vi/\nhttps://www.youtube.com/playlist?list=PL4NoNM0L1m72HCTkOQUiIsHT8LRxdjeKJ 6 Xem lại lí thuyết của các dịch vụ 10/10/2025 11/10/2025 https://www.youtube.com/playlist?list=PL4NoNM0L1m72HCTkOQUiIsHT8LRxdjeKJ Kết quả đạt được tuần 5: Biết cách sử dụng dịch vụ lambda để tự động hóa việc bật/tắt các instances ec2 và cách cấu hình để nhận được thông báo bên slack -\u0026gt; Mục tiêu là giảm chi phí cho các instances chỉ hoạt động trong 1 khoảng 1 gian ngắn.\nBiết cài đặt, cấu hình 1 dashboard bằng grafana để theo dõi các tài nguyên sử dụng trên aws.\nTạo tags khi khởi tạo các tài nguyên, lọc tài nguyên theo tags, thêm tag cho tài nguyên bằng CLI\nSử dụng resource group để gom nhóm các tài nguyên có các tags liên quan lại với nhau\nLuôn phải đặc quyền IAM ở mức tối thiểu, chỉ cấp quyền cần thiết khi sử dụng.\nSử dụng Patch manager để tự động cập nhật các bản vá hệ điều hành hoặc tự động cập nhật bảo mật\nSử dụng Run command để gửi lệnh command từ xa đến cùng lúc nhiều instance\nHiểu khái niệm, cách hoạt động, các ưu điểm của Session manager và tại sao nên sử dụng Session manager để quản lý máy chủ thay vì cách truyền thống.\nHiểu sự khác nhau giữa attach policy trực tiếp và sử dụng permissions boundary\nHiểu rõ hơn về các hoạt động của IAM, các request tới các service, authen các request đó và cách assumeRole hoạt động\nNắm được các tiêu chuẩn bảo mật và làm quen với giao diện console của AWS Security Hub\nHiểu được khái niệm về khóa đối xứng và bất đói xứng trong dịch vụ KMS, cách sử dụng để mã hóa dữ liệu được tải lên Bucket S3\nBiết cách sử dụng Cloud Trail để ghi lại log các hoạt động trong S3 và sử dụng Athena để truy vấn các log đó.\nBiết cách cấu hình AWS Backup để bảo vệ dữ liệu, tự động hóa quá trình sao lưu và phục hồi\nCấu hình được SNS Notification để nhận các thông báo liên quan đến việc sao lưu\nHiểu các khái niệm VPC Peering, Network ACL, Cross-Peering DNS\nBiết cách cấu hình ACl và tạo VPC Peering để kết nối 2 VPC\nBiết cách cấu hình Transit Gatewway để khi kết nối nhiều VPC thì đỡ phức tạp hơn VPC Peering\nLàm quen được các thao tác để triển khai một ứng dụng sử dụng AWS bằng Docker\n"
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/1-worklog/1.6-week6/",
	"title": "Worklog Tuần 6",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 5: Chuẩn bị proposal cho project 1 Tham gia các buổi workshop chia sẽ kiến thức Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu dịch vụ phù hợp cho project 1, ước tính các chi phí 11/08/2025 13/08/2025 https://tai-isme.github.io/workshop-template/vi/2-proposal/ 3 - Vẽ kiến trúc các dịch vụ sử dụng trong project 1 12/08/2025 13/08/2025 https://tai-isme.github.io/workshop-template/vi/2-proposal/ 4 - Vẽ kiến trúc các dịch vụ sử dụng trong project 1 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tham gia Workshop \u0026ldquo;DATA SCIENCE ON AWS\u0026quot;\n- Viết bài thu hoạch cho workshop DATA SCIENCE ON AWS\n- Tham gia workshop “Reinventing DevSecOps with AWS Generative AI”” - Viết bài thu hoạch cho workshop “Reinventing DevSecOps with AWS Generative AI 16/10/2025 16/10/2025 https://tai-isme.github.io/workshop-template/vi/4-eventparticipated/4.2-event2/ https://tai-isme.github.io/workshop-template/vi/4-eventparticipated/4.1-event1/ 6 - Chỉnh sửa lại kiến trúc sau khi nhận góp ý từ nhóm\n- Các điểm cẩm sửa:\n+ Đặt cloudfront + s3 ra ngoài region + Vẽ detail diagram cho từng flow + Đánh số cho từng bước\n+ Description từng bước + Xem lại hướng mũi của mũi tên (khi nào dùng 2 chiều - 1 chiều)\n+ Đặt Secret Manager chung 1 góc vs Guard Duty\n+ Đặt Cloudtrail gần với Cloud Watch cho monitoring nó đẹp hơn\n17/10/2025 17/10/2025 https://tai-isme.github.io/workshop-template/vi/2-proposal/ Kết quả đạt được tuần 5: Cân nhắc được các chi phí khi sử dụng các dịch vụ cho dự án. Các thành viên trong nhóm đều nắm được kiến trúc cho dự án sắp tới. Có một cái nhìn rõ ràng về các thành phần và cấu trúc hệ thống. Nắm được cách dữ liệu được lưu trữ và di chuyển trong hệ thống. Sau workshop \u0026ldquo;DATA SCIENCE ON AWS\u0026rdquo;:\nNắm được khái niệm cơ bản và phân biệt các lớp công nghệ AI/ML. Hiểu công dụng từng dịch vụ AWS phù hợp cho các tác vụ xử lý ngôn ngữ, nhận diện ảnh, chuyển giọng nói, trích xuất văn bản, recommendation. Nắm quy trình triển khai một pipeline ML điển hình (từ dữ liệu thô tới mô hình triển khai). Sau workshop \u0026ldquo;Reinventing DevSecOps with AWS Generative AI\u0026rdquo;:\nNắm được luồng tích hợp security từ giai đoạn planning đến monitoring. Cách sử dụng Amazon Q để tăng tốc phát hiện, phân tích và phản ứng với các lỗ hỏng. Biết bộ côn cụ phù hợp cho từng phase (SAST/DAST, dependency/IaC scanning, monitoring). Cách tối ưu chi phí và vận hành trên cloud bằng auto scale và các tool AWS hổ trợ. "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/1-worklog/1.7-week7/",
	"title": "Worklog Tuần 7",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 7: Học các 4 nhóm nội dung chính cho thi giữa kì Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Thiết kế kiến trúc bảo mật\n+ IAM, MFA, SCP, Encryption (KMS, TLS/ACM)\n+ Security Groups, NACLs, GuardDuty, Shield, WAF, Secret Manager 18/10/2025 /10/2025 Docs IAM, SCP:Viet-AWS, AWS IAM Basic, Docs, LAB 2\nMFA: LAB 1\nKMS:Viet-AWS, TLS: F5 DevCentral, ACM: AWS\nSG, NACL: Viet-AWS, AWSStudyGroup, GuarDuty: Lab 98\nShield, WAF: AWS\nSecrets Manager: AWS 3 - Thiết kế kiến trúc linh hoạt và bền vững (Resilient Architectures)\n+ Multi-AZ, Multi-Region, DR Strategies, Auto Scaling\n+ Route 53, Load Balancing, Backup \u0026amp; Restore\n- Chỉnh sửa lại 8 nội dung trong proposal, ước tính lại chi phí(tăng API GateWay, giảm DynamoDB) 12/08/2025 12/08/2025 Docs 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 7: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/1-worklog/1.8-week8/",
	"title": "Worklog Tuần 8",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 8: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 8: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/1-worklog/1.9-week9/",
	"title": "Worklog Tuần 9",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 9: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 9: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/2-proposal/",
	"title": "Bản đề xuất",
	"tags": [],
	"description": "",
	"content": "Teaching Center Management System Giải pháp AWS Serverless cho dự án quản lý trung tâm dạy học 1. Tóm tắt điều hành Để giải quyết các thách thức trong vận hành trung tâm giáo dục, hệ thống Teaching Center Management System được thiết kế nhằm tích hợp toàn bộ nghiệp vụ cốt lõi: Quản lý nhân sự (HRM), quản lý học viên (SIS), quản lý khách hàng (CRM), quản lý tài chính (Education Payment), và kết nối phụ huynh. Mục tiêu là tối ưu hóa quy trình quản lý, nâng cao hiệu suất vận hành và trải nghiệm học tập tổng thể.\nTrong tương lai, hệ thống định hướng mở rộng với các công nghệ tiên tiến như Trí tuệ nhân tạo (AI) và Internet vạn vật (IoT) để cá nhân hóa lộ trình học, phát triển trợ lý ảo học tập, đồng thời hiện đại hóa hạ tầng với lớp học thông minh và quản lý cơ sở vật chất tự động.\n2. Tuyên bố vấn đề Vấn đề hiện tại\nCác trung tâm giáo dục hiện nay gặp khó khăn trong việc quản lý đồng bộ giữa lớp học online và offline. Các quy trình như đăng ký khóa học, điểm danh, theo dõi tiến độ, hay thống kê kết quả vẫn chủ yếu thực hiện thủ công hoặc qua nhiều nền tảng riêng lẻ, gây thiếu nhất quán và khó kiểm soát dữ liệu.\nBên cạnh đó, thiếu một hệ thống tập trung để lưu trữ và phân tích dữ liệu học tập theo thời gian thực. Việc phụ thuộc vào các giải pháp bên thứ ba không chỉ tốn kém mà còn phức tạp, khó tùy chỉnh theo nhu cầu. Khi quy mô học viên và lớp học tăng, hệ thống hiện tại thiếu khả năng mở rộng và tự động hóa, làm giảm hiệu quả vận hành cũng như trải nghiệm của người học.\nGiải pháp\nNền tảng Teaching Center Management System được triển khai dựa trên kiến trúc AWS Serverless, giúp tối ưu chi phí, tự động mở rộng và đảm bảo tính sẵn sàng cao.\nNgười dùng truy cập hệ thống thông qua Amazon Route 53 và Amazon CloudFront, tăng tốc độ tải trang và bảo vệ khỏi tấn công DDoS. Giao diện web được lưu trữ tĩnh trên Amazon S3, cung cấp nội dung nhanh và ổn định.\nXác thực người dùng được thực hiện qua Amazon Cognito, đảm bảo an toàn cho tài khoản học viên, giảng viên, phụ huynh và quản trị viên. Sau khi đăng nhập, yêu cầu từ người dùng được xử lý qua Amazon API Gateway, kích hoạt AWS Lambda để thực thi các logic nghiệp vụ chính như quản lý tài khoản, lớp học, đăng ký khóa, điểm danh, cập nhật kết quả và tra cứu lịch học. Toàn bộ dữ liệu được lưu trữ trong Amazon DynamoDB.\nCác tài liệu, video bài giảng và bài tập được lưu trong Amazon S3; log hệ thống được gửi tới Amazon CloudWatch Logs để giám sát. CloudWatch Alarms và Amazon SNS tự động gửi cảnh báo khi phát hiện lỗi hoặc hoạt động bất thường. AWS Secrets Manager bảo vệ thông tin nhạy cảm như API key hoặc thông tin kết nối dịch vụ.\nQuy trình phát triển và triển khai được tự động hóa thông qua chuỗi AWS CodePipeline – CodeBuild – CloudFormation, đảm bảo CI/CD liền mạch, giảm lỗi cấu hình và rút ngắn thời gian triển khai. AWS CloudTrail và Amazon GuardDuty ghi nhận hoạt động API, phát hiện mối đe dọa và bảo vệ hệ thống khỏi rủi ro bảo mật.\nGiải pháp mang lại một nền tảng thống nhất, bảo mật, dễ mở rộng và tối ưu chi phí, giúp trung tâm giáo dục quản lý hiệu quả cả hoạt động đào tạo trực tuyến lẫn tại chỗ, nâng cao trải nghiệm học tập và hiệu suất làm việc của giảng viên.\nLợi ích và hoàn vốn đầu tư (ROI)\nTăng tốc độ phát triển và triển khai: CI/CD tự động (CodePipeline, CodeBuild, CloudFormation) giúp giảm thời gian phát hành tính năng mới từ vài ngày xuống còn vài giờ. Tối ưu chi phí vận hành: Kiến trúc Serverless (Lambda, DynamoDB, API Gateway) chỉ tính phí khi có request, tiết kiệm 40–60% chi phí so với EC2 truyền thống. Bảo mật toàn diện: GuardDuty, CloudTrail và Secrets Manager giúp phát hiện sớm rủi ro, giảm thiểu nguy cơ rò rỉ dữ liệu hoặc tấn công. Hiệu suất truy cập cao: CloudFront CDN và Route 53 giúp tăng tốc độ truy cập, giảm độ trễ 50–70% so với hosting thông thường. Khả năng mở rộng linh hoạt: Hệ thống tự động mở rộng theo lưu lượng, không cần can thiệp thủ công. Giám sát chủ động: CloudWatch + SNS cung cấp cảnh báo real-time, giúp đội ngũ kỹ thuật xử lý sự cố kịp thời. 3. Kiến trúc giải pháp Mô tả chi tiết\nApplication Flow\nNgười dùng truy cập vào hệ thống thông qua tên miền, Route53 phân giải tên miền thành địa chỉ IP để ánh xạ đến CloudFront CloudFront phân phối nội dung web tĩnh (frontend) từ Amazon S3 đến người dùng một cách nhanh chóng. API Gateway tiếp nhận, quản lý tất cả các yêu cầu API từ CloudFront. API Gateway tích hợp với Amazon Cognito để xác thực người dùng thông qua JWT token. API Gateway sẽ dùng Cognito để xác thực JWToken mà người dùng gửi kèm trong request để xác thực người dùng trước khi cho phép sử dụng API. Sau khi xác thực thành công, API Gateway kích hoạt hàm Lambda (nơi xử lý chính của ứng dụng). Nếu Lambda cần truy cập những thông tin nhạy cảm (như mật khẩu database, API key bên thứ 3), Lambda sẽ gọi đến Secret Manager để lấy những thông tin bí mật này. Hàm Lambda thực thi logic, truy vấn và lưu trữ dũ liệu vào Amazon DynamoDB (cơ sở dữ liệu NoSQL). Lambda tự động ghi lại log thực thi và gửi về CloudWatch Logs. Các log này bao gồm request, error, metrics giúp giám sát và khắc phục sự cố. Security Flow\nAWS CloudTrail ghi lại mọi hành động API trong tài khoản. AWS GuardDuty liên tục phân tích các nguồn logs như CloudTrail, VPC Flow Logs và DNS Logs từ Route 53 để phát hiện hành vi độc hại (ví dụ: IAM bị xâm nhập, IP lạ truy cập). Khi phát hiện, GuardDuty tạo Finding và kích hoạt cảnh báo hoặc phản ứng tự động qua SNS hoặc Lambda. Monitoring Flow\nCloudWatch Logs tập trung logs từ Lambda. CloudWatch Metrics được tạo ra từ CloudWatch Logs bằng Metric Filter, CloudWatch Alarms được cấu hình từ dựa trên metric để phát hiện lỗi và gửi cảnh báo. SNS gửi thông báo tự động qua email hoặc các endpoint đăng ký khi có sự cố. CloudTrail ghi lại mọi lệnh gọi API (API calls) xảy ra trong tài khoản(ví dụ: ai đã xóa S3 bucket, ai đã truy cập Secrets Manager). Dữ liệu này được dùng để theo dõi hoạt động quản trị và truy vết sự cố bảo mật. CloudTrail hoạt động song song với CloudWatch để ghi lại toàn bộ hành động API nhằm phục vụ audit và bảo mật. CI/CD Flow\nSource code của toàn ứng dụng sẽ được lưu trên repository Github Sau khi kết nối và cấu hình Github với Code Pipeline, khi source code trên GitHub được cập nhật, CodePipeline tự động nhận event webhook để lấy mã nguồn mới nhất. Đây là trung tâm điều phối toàn bộ quá trinh CI/CD, đinh nghĩa các stage: Source - Build - Deploy. CodeBuild lấy source từ CodePipeline. CodeBuild chạy file buildspec.yml để cài đặt dependencies, chạy unit tests và build ứng dụng thành artifact (zip, image, v.v.). Sau khi CodeBuild hoàn tất, CodePipeline kích hoạt CloudFormation để tự động tạo hoặc cập nhật toàn bộ tài nguyên (vd: API Gateway, Lambda, DynamoDB, S3, IAM Role, v.v.) lên môi trường AWS. Dịch vụ AWS sử dụng\nServices Description Frontend \u0026amp; Routing Route 53, CloudFront, S3 Định tuyến tên miền, phân phối nội dung, lưu trữ tĩnh Backend \u0026amp; Logic API Gateway, Lambda, DynamoDB, Secrets Manager, Cognito Serverless logic, dữ liệu, xác thực Security \u0026amp; Monitoring GuardDuty, CloudWatch Logs, CloudWatch Alarms, CloudWatch Metrics, SNS, CloudTrail Phát hiện mối đe dọa, cảnh báo, kiểm toán CI/CD \u0026amp; IaC CodePipeline, CodeBuild, CloudFormation, SAM Triển khai tự động và quản lý cơ sở hạ tầng 4. Triển khai kỹ thuật Các giai đoạn triển khai\nGiai đoạn phát triển (Development) Hoàn thiện các logic nghiệp vụ và main flow cho các hàm Lambda. Viết file template.yaml mô tả tài nguyên: API Gateway, Lambda Functions, DynamoDB, Cognito. Sử dụng AWS SAM CLI triển khai mã và template.yaml lên LocalStack để kiểm thử cục bộ. Giai đoạn deploy: Dùng AWS SAM CLI để triển khai mã và template.yaml lên môi trường AWS thật. Cấu hình AWS CodePipeline và AWS CodeBuild để tự động hóa quy trình CI/CD. Yêu cầu kỹ thuật\nCó tài khoản AWS sử dụng Free Tier triển khai và sử dụng các tài nguyên bình thường. File template.yaml phải được cấu hình chính xác để mô tả đầy đủ các dịch vụ. Hệ thống cần có cơ chế rollback tự động khi xảy ra lỗi triển khai. 5. Lộ trình \u0026amp; Mốc triển khai *Trước thực tập (Tuần 0): Học các dịch vụ AWS để chuẩn bị cho project. Khảo sát, phân tích yêu cầu và các bộ phận liên quan của các trung tâm thật (Nhân sự, Đào tạo, Tuyển sinh). Thực tập (Tuần 1-12): Tuần 1–3: Thiết kế hệ thống, giao diện, kiến trúc tổng thể và chuẩn bị tài liệu (proposal, diagram, template SAM). Tuần 4–8: Phát triển các module cốt lõi (quản lý học viên, giảng viên, lớp học, xác thực người dùng). Kiểm thử cục bộ bằng LocalStack. Tuần 9–11: Tích hợp các module, hoàn thiện CI/CD pipeline, triển khai hệ thống lên môi trường AWS thật. Tuần 12: Kiểm thử tổng thể, đánh giá kết quả, hoàn thiện báo cáo và đề xuất hướng phát triển tiếp theo. Sau thực tập (Định hướng mở rộng – Tuần 12 về sau): Nâng cấp hệ thống, tối ưu hiệu năng, và tích hợp công nghệ AI (phân tích học tập cá nhân hóa) cùng IoT (quản lý lớp học thông minh). 6. Ước tính ngân sách Có thể xem chi phí trên AWS Pricing Calculator\nHoặc tải tệp ước tính ngân sách pdf | csv | json\nChi phí hạ tầng\nS3 Standard: 0.32 USD/tháng (10 GB, 5.000 PUT requests, 100.000 GET requests). CloudFront: 1.33 USD/tháng (10 GB, Data transfer out to origin 0.1 GB, Number of requests (HTTPS) 100.000). Amazon API Gateway: 0,38 USD/tháng (300.000 request). AWS Lambda Function - Include Free Tier: 0.00 USD/tháng (100.000 request, 512 MB lưu trữ). Amazon DynamoDB: 0.62 USD/tháng (Data storage 2 GB, 50.000 Write/, 200.000 Read) Amazon Cognito Lite Tier: 0.00 USD/tháng (500 MAUs) Amazon CloudWatch: 2.10 USD/tháng (3 custom metric, Log 1GB, 1 dashboard, 2 alarms) Amazon GuardDuty: 0.0 USD/tháng (Free 30days/region) Amazon Route53: 0.9 USD/tháng (1 hosted zone, 1M standard DNS queries) AWS Secrets Manager: 0.4 USD/tháng (1 secret) AWS CloudTrail: 0.0 USD/tháng (1 trail) Amazon SNS: 0.0 USD/tháng (1M request, 1M lambda deliveries) AWS CloudFormation: 0.0 USD/tháng AWS CodeBuild: 0.25 USD/tháng (on-demand ec2 general1.small, 5 build/month) AWS CodePipeline: 0.0 USD/tháng (100 minute/month) Tổng: 6.30 USD/tháng, 75.60 USD/12 tháng\n7. Đánh giá rủi ro Ma trận rủi ro\nLỗi cấu hình AWS (IAM, Lambda, API Gateway, Cognito): Ảnh hưởng cao, xác suất trung bình Quá giới hạn Free Tier AWS: Ảnh hưởng trung bình, xác suất thấp. Mất dữ liệu trên S3/DynamoDB: Ảnh hưởng cao, xác suất thấp. Lỗi tích hợp giữa các dịch vụ AWS: Ảnh hưởng trung bình, xác suất thấp. Chiến lược giảm thiểu\nCấu hình AWS: Kiểm tra kỹ file template.yaml, thử triển khai trên LocalStack trước khi deploy thật. Vượt giới hạn Free Tier: Theo dõi chi phí thường xuyên, thiết lập cảnh báo chi tiêu (Billing Alert), tối ưu tài nguyên. Mất dữ liệu: Bật S3 Versioning, sao lưu định kỳ dữ liệu DynamoDB. Lỗi tích hợp dịch vụ: Đảm bảo các dịch vụ hoạt động cùng Region, kiểm tra IAM Role và quyền truy cập chéo giữa các service. Kế hoạch dự phòng\nKhi gặp lỗi deploy: rollback bằng AWS SAM CLI hoặc khôi phục version Lambda trước đó. Khi vượt ngân sách: tạm dừng các dịch vụ không thiết yếu, tối ưu lại kiến trúc và tài nguyên sử dụng. 8. Kết quả kỳ vọng Hệ thống quản lý trung tâm dạy học được triển khai thành công trên nền tảng AWS Serverless, đảm bảo hoạt động ổn định, bảo mật, dễ mở rộng. Tối ưu chi phí vận hành nhờ tận dụng AWS Free Tier và kiến trúc serverless, giảm chi phí đầu tư hạ tầng ban đầu. Đảm bảo hiệu suất truy cập cao, thời gian phản hồi nhanh và khả năng mở rộng linh hoạt. Đảm bảo an toàn dữ liệu với các cơ chế backup, versioning, và kiểm soát truy cập chặt chẽ. Tích hợp CI/CD giúp tự động hóa triển khai, kiểm thử và rollback, đảm bảo quy trình phát triển hiệu quả và đáng tin cậy. "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/5-workshop/5.2-prerequiste/",
	"title": "Các bước chuẩn bị",
	"tags": [],
	"description": "",
	"content": "IAM permissions Gắn IAM permission policy sau vào tài khoản aws user của bạn để triển khai và dọn dẹp tài nguyên trong workshop này.\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cloudformation:*\u0026#34;, \u0026#34;cloudwatch:*\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:AllocateAddress\u0026#34;, \u0026#34;ec2:AssociateAddress\u0026#34;, \u0026#34;ec2:AssociateIamInstanceProfile\u0026#34;, \u0026#34;ec2:AssociateRouteTable\u0026#34;, \u0026#34;ec2:AssociateSubnetCidrBlock\u0026#34;, \u0026#34;ec2:AssociateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:AssociateVpcCidrBlock\u0026#34;, \u0026#34;ec2:AttachInternetGateway\u0026#34;, \u0026#34;ec2:AttachNetworkInterface\u0026#34;, \u0026#34;ec2:AttachVolume\u0026#34;, \u0026#34;ec2:AttachVpnGateway\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:CreateClientVpnEndpoint\u0026#34;, \u0026#34;ec2:CreateClientVpnRoute\u0026#34;, \u0026#34;ec2:CreateCustomerGateway\u0026#34;, \u0026#34;ec2:CreateDhcpOptions\u0026#34;, \u0026#34;ec2:CreateFlowLogs\u0026#34;, \u0026#34;ec2:CreateInternetGateway\u0026#34;, \u0026#34;ec2:CreateLaunchTemplate\u0026#34;, \u0026#34;ec2:CreateNetworkAcl\u0026#34;, \u0026#34;ec2:CreateNetworkInterface\u0026#34;, \u0026#34;ec2:CreateNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:CreateRoute\u0026#34;, \u0026#34;ec2:CreateRouteTable\u0026#34;, \u0026#34;ec2:CreateSecurityGroup\u0026#34;, \u0026#34;ec2:CreateSubnet\u0026#34;, \u0026#34;ec2:CreateSubnetCidrReservation\u0026#34;, \u0026#34;ec2:CreateTags\u0026#34;, \u0026#34;ec2:CreateTransitGateway\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRoute\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:CreateTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:CreateVpc\u0026#34;, \u0026#34;ec2:CreateVpcEndpoint\u0026#34;, \u0026#34;ec2:CreateVpcEndpointConnectionNotification\u0026#34;, \u0026#34;ec2:CreateVpcEndpointServiceConfiguration\u0026#34;, \u0026#34;ec2:CreateVpnConnection\u0026#34;, \u0026#34;ec2:CreateVpnConnectionRoute\u0026#34;, \u0026#34;ec2:CreateVpnGateway\u0026#34;, \u0026#34;ec2:DeleteCustomerGateway\u0026#34;, \u0026#34;ec2:DeleteFlowLogs\u0026#34;, \u0026#34;ec2:DeleteInternetGateway\u0026#34;, \u0026#34;ec2:DeleteNetworkInterface\u0026#34;, \u0026#34;ec2:DeleteNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:DeleteRoute\u0026#34;, \u0026#34;ec2:DeleteRouteTable\u0026#34;, \u0026#34;ec2:DeleteSecurityGroup\u0026#34;, \u0026#34;ec2:DeleteSubnet\u0026#34;, \u0026#34;ec2:DeleteSubnetCidrReservation\u0026#34;, \u0026#34;ec2:DeleteTags\u0026#34;, \u0026#34;ec2:DeleteTransitGateway\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRoute\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:DeleteVpc\u0026#34;, \u0026#34;ec2:DeleteVpcEndpoints\u0026#34;, \u0026#34;ec2:DeleteVpcEndpointServiceConfigurations\u0026#34;, \u0026#34;ec2:DeleteVpnConnection\u0026#34;, \u0026#34;ec2:DeleteVpnConnectionRoute\u0026#34;, \u0026#34;ec2:Describe*\u0026#34;, \u0026#34;ec2:DetachInternetGateway\u0026#34;, \u0026#34;ec2:DisassociateAddress\u0026#34;, \u0026#34;ec2:DisassociateRouteTable\u0026#34;, \u0026#34;ec2:GetLaunchTemplateData\u0026#34;, \u0026#34;ec2:GetTransitGatewayAttachmentPropagations\u0026#34;, \u0026#34;ec2:ModifyInstanceAttribute\u0026#34;, \u0026#34;ec2:ModifySecurityGroupRules\u0026#34;, \u0026#34;ec2:ModifyTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:ModifyVpcAttribute\u0026#34;, \u0026#34;ec2:ModifyVpcEndpoint\u0026#34;, \u0026#34;ec2:ReleaseAddress\u0026#34;, \u0026#34;ec2:ReplaceRoute\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:RunInstances\u0026#34;, \u0026#34;ec2:StartInstances\u0026#34;, \u0026#34;ec2:StopInstances\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsEgress\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsIngress\u0026#34;, \u0026#34;iam:AddRoleToInstanceProfile\u0026#34;, \u0026#34;iam:AttachRolePolicy\u0026#34;, \u0026#34;iam:CreateInstanceProfile\u0026#34;, \u0026#34;iam:CreatePolicy\u0026#34;, \u0026#34;iam:CreateRole\u0026#34;, \u0026#34;iam:DeleteInstanceProfile\u0026#34;, \u0026#34;iam:DeletePolicy\u0026#34;, \u0026#34;iam:DeleteRole\u0026#34;, \u0026#34;iam:DeleteRolePolicy\u0026#34;, \u0026#34;iam:DetachRolePolicy\u0026#34;, \u0026#34;iam:GetInstanceProfile\u0026#34;, \u0026#34;iam:GetPolicy\u0026#34;, \u0026#34;iam:GetRole\u0026#34;, \u0026#34;iam:GetRolePolicy\u0026#34;, \u0026#34;iam:ListPolicyVersions\u0026#34;, \u0026#34;iam:ListRoles\u0026#34;, \u0026#34;iam:PassRole\u0026#34;, \u0026#34;iam:PutRolePolicy\u0026#34;, \u0026#34;iam:RemoveRoleFromInstanceProfile\u0026#34;, \u0026#34;lambda:CreateFunction\u0026#34;, \u0026#34;lambda:DeleteFunction\u0026#34;, \u0026#34;lambda:DeleteLayerVersion\u0026#34;, \u0026#34;lambda:GetFunction\u0026#34;, \u0026#34;lambda:GetLayerVersion\u0026#34;, \u0026#34;lambda:InvokeFunction\u0026#34;, \u0026#34;lambda:PublishLayerVersion\u0026#34;, \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:DeleteLogGroup\u0026#34;, \u0026#34;logs:DescribeLogGroups\u0026#34;, \u0026#34;logs:PutRetentionPolicy\u0026#34;, \u0026#34;route53:ChangeTagsForResource\u0026#34;, \u0026#34;route53:CreateHealthCheck\u0026#34;, \u0026#34;route53:CreateHostedZone\u0026#34;, \u0026#34;route53:CreateTrafficPolicy\u0026#34;, \u0026#34;route53:DeleteHostedZone\u0026#34;, \u0026#34;route53:DisassociateVPCFromHostedZone\u0026#34;, \u0026#34;route53:GetHostedZone\u0026#34;, \u0026#34;route53:ListHostedZones\u0026#34;, \u0026#34;route53domains:ListDomains\u0026#34;, \u0026#34;route53domains:ListOperations\u0026#34;, \u0026#34;route53domains:ListTagsForDomain\u0026#34;, \u0026#34;route53resolver:AssociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:AssociateResolverRule\u0026#34;, \u0026#34;route53resolver:CreateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:CreateResolverRule\u0026#34;, \u0026#34;route53resolver:DeleteResolverEndpoint\u0026#34;, \u0026#34;route53resolver:DeleteResolverRule\u0026#34;, \u0026#34;route53resolver:DisassociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:DisassociateResolverRule\u0026#34;, \u0026#34;route53resolver:GetResolverEndpoint\u0026#34;, \u0026#34;route53resolver:GetResolverRule\u0026#34;, \u0026#34;route53resolver:ListResolverEndpointIpAddresses\u0026#34;, \u0026#34;route53resolver:ListResolverEndpoints\u0026#34;, \u0026#34;route53resolver:ListResolverRuleAssociations\u0026#34;, \u0026#34;route53resolver:ListResolverRules\u0026#34;, \u0026#34;route53resolver:ListTagsForResource\u0026#34;, \u0026#34;route53resolver:UpdateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:UpdateResolverRule\u0026#34;, \u0026#34;s3:AbortMultipartUpload\u0026#34;, \u0026#34;s3:CreateBucket\u0026#34;, \u0026#34;s3:DeleteBucket\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34;, \u0026#34;s3:GetAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;s3:GetBucketOwnershipControls\u0026#34;, \u0026#34;s3:GetBucketPolicy\u0026#34;, \u0026#34;s3:GetBucketPolicyStatus\u0026#34;, \u0026#34;s3:GetBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:GetObjectVersion\u0026#34;, \u0026#34;s3:GetBucketVersioning\u0026#34;, \u0026#34;s3:ListAccessPoints\u0026#34;, \u0026#34;s3:ListAccessPointsForObjectLambda\u0026#34;, \u0026#34;s3:ListAllMyBuckets\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:ListBucketMultipartUploads\u0026#34;, \u0026#34;s3:ListBucketVersions\u0026#34;, \u0026#34;s3:ListJobs\u0026#34;, \u0026#34;s3:ListMultipartUploadParts\u0026#34;, \u0026#34;s3:ListMultiRegionAccessPoints\u0026#34;, \u0026#34;s3:ListStorageLensConfigurations\u0026#34;, \u0026#34;s3:PutAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:PutBucketAcl\u0026#34;, \u0026#34;s3:PutBucketPolicy\u0026#34;, \u0026#34;s3:PutBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;secretsmanager:CreateSecret\u0026#34;, \u0026#34;secretsmanager:DeleteSecret\u0026#34;, \u0026#34;secretsmanager:DescribeSecret\u0026#34;, \u0026#34;secretsmanager:GetSecretValue\u0026#34;, \u0026#34;secretsmanager:ListSecrets\u0026#34;, \u0026#34;secretsmanager:ListSecretVersionIds\u0026#34;, \u0026#34;secretsmanager:PutResourcePolicy\u0026#34;, \u0026#34;secretsmanager:TagResource\u0026#34;, \u0026#34;secretsmanager:UpdateSecret\u0026#34;, \u0026#34;sns:ListTopics\u0026#34;, \u0026#34;ssm:DescribeInstanceProperties\u0026#34;, \u0026#34;ssm:DescribeSessions\u0026#34;, \u0026#34;ssm:GetConnectionStatus\u0026#34;, \u0026#34;ssm:GetParameters\u0026#34;, \u0026#34;ssm:ListAssociations\u0026#34;, \u0026#34;ssm:ResumeSession\u0026#34;, \u0026#34;ssm:StartSession\u0026#34;, \u0026#34;ssm:TerminateSession\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Khởi tạo tài nguyên bằng CloudFormation Trong lab này, chúng ta sẽ dùng N.Virginia region (us-east-1).\nĐể chuẩn bị cho môi trường làm workshop, chúng ta deploy CloudFormation template sau (click link): PrivateLinkWorkshop . Để nguyên các lựa chọn mặc định.\nLựa chọn 2 mục acknowledgement Chọn Create stack Quá trình triển khai CloudFormation cần khoảng 15 phút để hoàn thành.\n2 VPCs đã được tạo 3 EC2s đã được tạo "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/5-workshop/5.3-s3-vpc/5.3.2-test-gwe/",
	"title": "Kiểm tra Gateway Endpoint",
	"tags": [],
	"description": "",
	"content": "Tạo S3 bucket Đi đến S3 management console Trong Bucket console, chọn Create bucket Trong Create bucket console Đặt tên bucket: chọn 1 tên mà không bị trùng trong phạm vi toàn cầu (gợi ý: lab\u0026lt;số-lab\u0026gt;\u0026lt;tên-bạn\u0026gt;) Giữ nguyên giá trị của các fields khác (default) Kéo chuột xuống và chọn Create bucket Tạo thành công S3 bucket Kết nối với EC2 bằng session manager Trong workshop này, bạn sẽ dùng AWS Session Manager để kết nối đến các EC2 instances. Session Manager là 1 tính năng trong dịch vụ Systems Manager được quản lý hoàn toàn bởi AWS. System manager cho phép bạn quản lý Amazon EC2 instances và các máy ảo on-premises (VMs)thông qua 1 browser-based shell. Session Manager cung cấp khả năng quản lý phiên bản an toàn và có thể kiểm tra mà không cần mở cổng vào, duy trì máy chủ bastion host hoặc quản lý khóa SSH.\nFirst cloud journey Lab để hiểu sâu hơn về Session manager.\nTrong AWS Management Console, gõ Systems Manager trong ô tìm kiếm và nhấn Enter: Từ Systems Manager menu, tìm Node Management ở thanh bên trái và chọn Session Manager: Click Start Session, và chọn EC2 instance tên Test-Gateway-Endpoint. Phiên bản EC2 này đã chạy trong \u0026ldquo;VPC cloud\u0026rdquo; và sẽ được dùng để kiểm tra khả năng kết nối với Amazon S3 thông qua điểm cuối Cổng mà bạn vừa tạo (s3-gwe).\nSession Manager sẽ mở browser tab mới với shell prompt: sh-4.2 $\nBạn đã bắt đầu phiên kết nối đến EC2 trong VPC Cloud thành công. Trong bước tiếp theo, chúng ta sẽ tạo một S3 bucket và một tệp trong đó.\nCreate a file and upload to s3 bucket Đổi về ssm-user\u0026rsquo;s thư mục bằng lệnh \u0026ldquo;cd ~\u0026rdquo; Tạo 1 file để kiểm tra bằng lệnh \u0026ldquo;fallocate -l 1G testfile.xyz\u0026rdquo;, 1 file tên \u0026ldquo;testfile.xyz\u0026rdquo; có kích thước 1GB sẽ được tạo. Tải file mình vừa tạo lên S3 với lệnh \u0026ldquo;aws s3 cp testfile.xyz s3://your-bucket-name\u0026rdquo;. Thay your-bucket-name bằng tên S3 bạn đã tạo. Bạn đã tải thành công tệp lên bộ chứa S3 của mình. Bây giờ bạn có thể kết thúc session.\nKiểm tra object trong S3 bucket Đi đến S3 console. Click tên s3 bucket của bạn Trong Bucket console, bạn sẽ thấy tệp bạn đã tải lên S3 bucket của mình Tóm tắt Chúc mừng bạn đã hoàn thành truy cập S3 từ VPC. Trong phần này, bạn đã tạo gateway endpoint cho Amazon S3 và sử dụng AWS CLI để tải file lên. Quá trình tải lên hoạt động vì gateway endpoint cho phép giao tiếp với S3 mà không cần Internet gateway gắn vào \u0026ldquo;VPC Cloud\u0026rdquo;. Điều này thể hiện chức năng của gateway endpoint như một đường dẫn an toàn đến S3 mà không cần đi qua pub lic Internet.\n"
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/5-workshop/5.4-s3-onprem/5.4.2-create-interface-enpoint/",
	"title": "Tạo một S3 Interface endpoint",
	"tags": [],
	"description": "",
	"content": "Trong phần này, bạn sẽ tạo và kiểm tra Interface Endpoint S3 bằng cách sử dụng môi trường truyền thống mô phỏng.\nQuay lại Amazon VPC menu. Trong thanh điều hướng bên trái, chọn Endpoints, sau đó click Create Endpoint.\nTrong Create endpoint console:\nĐặt tên interface endpoint Trong Service category, chọn aws services Trong Search box, gõ S3 và nhấn Enter. Chọn endpoint có tên com.amazonaws.us-east-1.s3. Đảm bảo rằng cột Type có giá trị Interface. Đối với VPC, chọn VPC Cloud từ drop-down. Đảm bảo rằng bạn chọn \u0026ldquo;VPC Cloud\u0026rdquo; và không phải \u0026ldquo;VPC On-prem\u0026rdquo;\nMở rộng Additional settings và đảm bảo rằng Enable DNS name không được chọn (sẽ sử dụng điều này trong phần tiếp theo của workshop) Chọn 2 subnets trong AZs sau: us-east-1a and us-east-1b Đối với Security group, chọn SGforS3Endpoint: Giữ default policy - full access và click Create endpoint Chúc mừng bạn đã tạo thành công S3 interface endpoint. Ở bước tiếp theo, chúng ta sẽ kiểm tra interface endpoint.\n"
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/1-worklog/1.10-week10/",
	"title": "Worklog Tuần 10",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 10: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 10: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/1-worklog/1.11-week11/",
	"title": "Worklog Tuần 11",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 11: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 11: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/1-worklog/1.12-week12/",
	"title": "Worklog Tuần 12",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 12: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 12: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": "Blog 1 - Tối ưu hóa quy trình làm việc HPC với các cụm tự động mở rộng trong Ansys Gateway vận hành bởi AWS Bài blog giới thiệu Ansys Gateway powered by AWS, giải pháp HPC trên nền tảng AWS, cho phép tự động mở rộng tài nguyên tính toán theo nhu cầu mô phỏng kỹ thuật. Bài viết trình bày kiến trúc, quy trình tạo và quản lý cụm HPC, tích hợp các dịch vụ lưu trữ như EFS, FSx for Lustre/OpenZFS, và sử dụng AWS ParallelCluster cùng Slurm để tự động cấp phát/nhả node. Người dùng có thể tối ưu chi phí, tăng hiệu quả mô phỏng với workflow linh hoạt, phù hợp cả cho các ứng dụng Ansys lớn cần hiệu năng cao.\nBlog 2 - Hiện đại hóa hạ tầng Kubernetes của Snowflake Corporate với Bottlerocket và Karpenter Bài blog này trình bày về quá trình hiện đại hóa hạ tầng Kubernetes của Snowflake Corporate bằng cách chuyển đổi từ Amazon Linux 2 sang Bottlerocket – hệ điều hành tối ưu cho container và sử dụng Karpenter để tự động hoá mở rộng node. Quá trình di chuyển được thực hiện theo từng giai đoạn để đảm bảo không gián đoạn dịch vụ, mang lại lợi ích về bảo mật, hiệu năng (tăng tốc khởi động node, giảm thời gian sẵn sàng của pod), giảm tải vận hành và tiết kiệm chi phí. Bài viết tổng kết các bài học thực tiễn và khuyến nghị cho doanh nghiệp khi vận hành EKS ở quy mô lớn.\nBlog 3 - Di chuyển liền mạch: Chuyển đổi bảo mật các đội thiết bị IoT lớn sang AWS Bài blog này mô tả chiến lược và các bước cụ thể để di chuyển quy mô lớn các hệ thống IoT lên AWS IoT Core. Blog tập trung vào các thách thức khi dùng broker tự quản, như chi phí cao, khó mở rộng, bảo mật và đổi mới chậm. AWS IoT Core cung cấp nhiều tính năng hỗ trợ việc chuyển đổi mượt mà mà không cần cập nhật thiết bị, tương thích đa giao thức, xác thực mạnh và khả năng mở rộng lớn. Quy trình di chuyển gồm các pha: chuẩn bị, chuyển backend, chuyển thiết bị và dọn dẹp, giúp giảm rủi ro và đảm bảo liên tục hệ thống khi chuyển sang nền tảng cloud hiện đại.\nBlog 4 - \u0026hellip; Blog 5 - \u0026hellip; Blog 6 - \u0026hellip; "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/5-workshop/5.4-s3-onprem/5.4.3-test-endpoint/",
	"title": "Kiểm tra Interface Endpoint",
	"tags": [],
	"description": "",
	"content": "Lấy regional DNS name (tên DNS khu vực) của S3 interface endpoint Trong Amazon VPC menu, chọn Endpoints.\nClick tên của endpoint chúng ta mới tạo ở mục 4.2: s3-interface-endpoint. Click details và lưu lại regional DNS name của endpoint (cái đầu tiên) vào text-editor của bạn để dùng ở các bước sau.\nKết nối đến EC2 instance ở trong \u0026ldquo;VPC On-prem\u0026rdquo; (giả lập môi trường truyền thống) Đi đến Session manager bằng cách gõ \u0026ldquo;session manager\u0026rdquo; vào ô tìm kiếm\nClick Start Session, chọn EC2 instance có tên Test-Interface-Endpoint. EC2 instance này đang chạy trên \u0026ldquo;VPC On-prem\u0026rdquo; và sẽ được sử dụng để kiểm tra kết nối đến Amazon S3 thông qua Interface endpoint. Session Manager sẽ mở 1 browser tab mới với shell prompt: sh-4.2 $\nĐi đến ssm-user\u0026rsquo;s home directory với lệnh \u0026ldquo;cd ~\u0026rdquo;\nTạo 1 file tên testfile2.xyz\nfallocate -l 1G testfile2.xyz Copy file vào S3 bucket mình tạo ở section 4.2 aws s3 cp --endpoint-url https://bucket.\u0026lt;Regional-DNS-Name\u0026gt; testfile2.xyz s3://\u0026lt;your-bucket-name\u0026gt; Câu lệnh này yêu cầu thông số \u0026ndash;endpoint-url, bởi vì bạn cần sử dụng DNS name chỉ định cho endpoint để truy cập vào S3 thông qua Interface endpoint. Không lấy \u0026rsquo; * \u0026rsquo; khi copy/paste tên DNS khu vực. Cung cấp tên S3 bucket của bạn Bây giờ tệp đã được thêm vào bộ chứa S3 của bạn. Hãy kiểm tra bộ chứa S3 của bạn trong bước tiếp theo.\nKiểm tra Object trong S3 bucket Đi đến S3 console Click Buckets Click tên bucket của bạn và bạn sẽ thấy testfile2.xyz đã được thêm vào s3 bucket của bạn "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/5-workshop/5.3-s3-vpc/",
	"title": "Truy cập S3 từ VPC",
	"tags": [],
	"description": "",
	"content": "Sử dụng Gateway endpoint Trong phần này, bạn sẽ tạo một Gateway endpoint để truy cập Amazon S3 từ một EC2 instance. Gateway endpoint sẽ cho phép tải một object lên S3 bucket mà không cần sử dụng Internet Công cộng. Để tạo endpoint, bạn phải chỉ định VPC mà bạn muốn tạo endpoint và dịch vụ (trong trường hợp này là S3) mà bạn muốn thiết lập kết nối.\nNội dung Tạo gateway endpoint Test gateway endpoint "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/4-eventparticipated/",
	"title": "Các events đã tham gia",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTrong phần này, các bạn cần liệt kê và mô tả chi tiết các sự kiện (event) mà mình đã tham gia trong suốt quá trình thực tập hoặc làm việc.\nMỗi sự kiện nên được trình bày theo định dạng Event 1, Event 2, Event 3…, kèm theo các thông tin:\nTên sự kiện Thời gian tổ chức Địa điểm (nếu có) Vai trò của bạn trong sự kiện (người tham dự, hỗ trợ tổ chức, diễn giả, v.v.) Mô tả ngắn gọn nội dung và hoạt động chính trong sự kiện Kết quả hoặc giá trị đạt được (bài học, kỹ năng mới, đóng góp cho nhóm/dự án) Việc liệt kê này giúp thể hiện rõ sự tham gia thực tế của bạn, cũng như các kỹ năng mềm và kinh nghiệm bạn đã tích lũy qua từng sự kiện. Trong quá trình thực tập, em đã tham gia 2 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEvent 1 Tên sự kiện: GenAI-powered App-DB Modernization workshop\nThời gian: 09:00 ngày 13/08/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: GenAI-powered App-DB Modernization workshop\nThời gian: 09:00 ngày 13/08/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/5-workshop/5.4-s3-onprem/5.4.4-dns-simulation/",
	"title": "Mô phỏng On-premises DNS ",
	"tags": [],
	"description": "",
	"content": "AWS PrivateLink endpoint có một địa chỉ IP cố định trong từng AZ nơi chúng được triển khai, trong suốt thời gian tồn tại của endpoint (cho đến khi endpoint bị xóa). Các địa chỉ IP này được gắn vào Elastic network interface (ENI). AWS khuyến nghị sử dụng DNS để resolve địa chỉ IP cho endpoint để các ứng dụng downstream sử dụng địa chỉ IP mới nhất khi ENIs được thêm vào AZ mới hoặc bị xóa theo thời gian.\nTrong phần này, bạn sẽ tạo một quy tắc chuyển tiếp (forwarding rule) để gửi các yêu cầu resolve DNS từ môi trường truyền thống (mô phỏng) đến Private Hosted Zone trên Route 53. Phần này tận dụng cơ sở hạ tầng do CloudFormation triển khai trong phần Chuẩn bị môi trường.\nTạo DNS Alias Records cho Interface endpoint Click link để đi đến Route 53 management console (Hosted Zones section). Mẫu CloudFormation mà bạn triển khai trong phần Chuẩn bị môi trường đã tạo Private Hosted Zone này. Nhấp vào tên của Private Hosted Zone, s3.us-east-1.amazonaws.com: Tạo 1 record mới trong Private Hosted Zone: Giữ nguyên Record name và record type Alias Button: click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Add another record, và add 1 cái record thứ 2 sử dụng những thông số sau: Record name: *. Record type: giữ giá trị default (type A) Alias Button: Click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Create records Record mới xuất hiện trên giao diện Route 53.\nTạo một Resolver Forwarding Rule Route 53 Resolver Forwarding Rules cho phép bạn chuyển tiếp các DNS queries từ VPC của bạn đến các nguồn khác để resolve name. Bên ngoài môi trường workshop, bạn có thể sử dụng tính năng này để chuyển tiếp các DNS queries từ VPC của bạn đến các máy chủ DNS chạy trên on-premises. Trong phần này, bạn sẽ mô phỏng một on-premises conditional forwarder bằng cách tạo một forwarding rule để chuyển tiếp các DNS queries for Amazon S3 đến một Private Hosted Zone chạy trong \u0026ldquo;VPC Cloud\u0026rdquo; để resolve PrivateLink interface endpoint regional DNS name.\nTừ giao diện Route 53, chọn Inbound endpoints trên thanh bên trái\nTrong giao diện Inbound endpoint, Chọn ID của Inbound endpoint.\nSao chép 2 địa chỉ IP trong danh sách vào trình chỉnh sửa. Từ giao diện Route 53, chọn Resolver \u0026gt; Rules và chọn Create rule Trong giao diện Create rule Name: myS3Rule Rule type: Forward Domain name: s3.us-east-1.amazonaws.com VPC: VPC On-prem Outbound endpoint: VPCOnpremOutboundEndpoint Target IP Addresses: điền cả hai IP bạn đã lưu trữ trên trình soạn thảo (inbound endpoint addresses) và sau đó chọn Submit Bạn đã tạo thành công resolver forwarding rule.\nKiểm tra on-premises DNS mô phỏng. Kết nối đến Test-Interface-Endpoint EC2 instance với Session Manager Kiểm tra DNS resolution. Lệnh dig sẽ trả về địa chỉ IP được gán cho VPC endpoint interface đang chạy trên VPC (địa chỉ IP của bạn sẽ khác): dig +short s3.us-east-1.amazonaws.com Các địa chỉ IP được trả về là các địa chỉ IP VPC enpoint, KHÔNG phải là các địa chỉ IP Resolver mà bạn đã dán từ trình chỉnh sửa văn bản của mình. Các địa chỉ IP của Resolver endpoint và VPC endpoin trông giống nhau vì chúng đều từ khối CIDR VPC Cloud.\nTruy cập vào menu VPC (phần Endpoints), chọn S3 interface endpoint. Nhấp vào tab Subnets và xác nhận rằng các địa chỉ IP được trả về bởi lệnh Dig khớp với VPC endpoint: Hãy quay lại shell của bạn và sử dụng AWS CLI để kiểm tra danh sách các bucket S3 của bạn: aws s3 ls --endpoint-url https://s3.us-east-1.amazonaws.com Kết thúc phiên làm việc của Session Manager của bạn: Trong phần này, bạn đã tạo một Interface Endpoint cho Amazon S3. Điểm cuối này có thể được truy cập từ on-premises thông qua Site-to-Site VPN hoặc AWS Direct Connect. Các điểm cuối Route 53 Resolver outbound giả lập chuyển tiếp các yêu cầu DNS từ on-premises đến một Private Hosted Zone đang chạy trên đám mây. Các điểm cuối Route 53 inbound nhận yêu cầu giải quyết và trả về một phản hồi chứa địa chỉ IP của Interface Endpoint VPC. Sử dụng DNS để giải quyết các địa chỉ IP của điểm cuối cung cấp tính sẵn sàng cao trong trường hợp một Availability Zone gặp sự cố.\n"
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/5-workshop/5.4-s3-onprem/",
	"title": "Truy cập S3 từ môi trường truyền thống",
	"tags": [],
	"description": "",
	"content": "Tổng quan Trong phần này, bạn sẽ tạo một Interface Endpoint để truy cập Amazon S3 từ môi trường truyền thống mô phỏng. Interface Endpoint sẽ cho phép bạn định tuyến đến Amazon S3 qua kết nối VPN từ môi trường truyền thống mô phỏng của bạn.\nTại sao nên sử dụng Interface Endpoint:\nCác Gateway endpoints chỉ hoạt động với các tài nguyên đang chạy trong VPC nơi chúng được tạo. Interface Endpoint hoạt động với tài nguyên chạy trong VPC và cả tài nguyên chạy trong môi trường truyền thống. Khả năng kết nối từ môi trường truyền thống của bạn với aws cloud có thể được cung cấp bởi AWS Site-to-Site VPN hoặc AWS Direct Connect. Interface Endpoint cho phép bạn kết nối với các dịch vụ do AWS PrivateLink cung cấp. Các dịch vụ này bao gồm một số dịch vụ AWS, dịch vụ do các đối tác và khách hàng AWS lưu trữ trong VPC của riêng họ (gọi tắt là Dịch vụ PrivateLink endpoints) và các dịch vụ Đối tác AWS Marketplace. Đối với workshop này, chúng ta sẽ tập trung vào việc kết nối với Amazon S3. "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/5-workshop/5.5-policy/",
	"title": "VPC Endpoint Policies",
	"tags": [],
	"description": "",
	"content": "Khi bạn tạo một Interface Endpoint hoặc cổng, bạn có thể đính kèm một chính sách điểm cuối để kiểm soát quyền truy cập vào dịch vụ mà bạn đang kết nối. Chính sách VPC Endpoint là chính sách tài nguyên IAM mà bạn đính kèm vào điểm cuối. Nếu bạn không đính kèm chính sách khi tạo điểm cuối, thì AWS sẽ đính kèm chính sách mặc định cho bạn để cho phép toàn quyền truy cập vào dịch vụ thông qua điểm cuối.\nBạn có thể tạo chính sách chỉ hạn chế quyền truy cập vào các S3 bucket cụ thể. Điều này hữu ích nếu bạn chỉ muốn một số Bộ chứa S3 nhất định có thể truy cập được thông qua điểm cuối.\nTrong phần này, bạn sẽ tạo chính sách VPC Endpoint hạn chế quyền truy cập vào S3 bucket được chỉ định trong chính sách VPC Endpoint.\nKết nối tới EC2 và xác minh kết nối tới S3. Bắt đầu một phiên AWS Session Manager mới trên máy chủ có tên là Test-Gateway-Endpoint. Từ phiên này, xác minh rằng bạn có thể liệt kê nội dung của bucket mà bạn đã tạo trong Phần 1: Truy cập S3 từ VPC. aws s3 ls s3://\u0026lt;your-bucket-name\u0026gt; Nội dung của bucket bao gồm hai tệp có dung lượng 1GB đã được tải lên trước đó.\nTạo một bucket S3 mới; tuân thủ mẫu đặt tên mà bạn đã sử dụng trong Phần 1, nhưng thêm \u0026lsquo;-2\u0026rsquo; vào tên. Để các trường khác là mặc định và nhấp vào Create. Tạo bucket thành công. Policy mặc định cho phép truy cập vào tất cả các S3 Buckets thông qua VPC endpoint.\nTrong giao diện Edit Policy, sao chép và dán theo policy sau, thay thế yourbucketname-2 với tên bucket thứ hai của bạn. Policy này sẽ cho phép truy cập đến bucket mới thông qua VPC endpoint, nhưng không cho phép truy cập đến các bucket còn lại. Chọn Save để kích hoạt policy. { \u0026#34;Id\u0026#34;: \u0026#34;Policy1631305502445\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Stmt1631305501021\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::yourbucketname-2\u0026#34;, \u0026#34;arn:aws:s3:::yourbucketname-2/*\u0026#34; ], \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34; } ] } Cấu hình policy thành công.\nTừ session của bạn trên Test-Gateway-Endpoint instance, kiểm tra truy cập đến S3 bucket bạn tạo ở bước đầu aws s3 ls s3://\u0026lt;yourbucketname\u0026gt; Câu lệnh trả về lỗi bởi vì truy cập vào S3 bucket không có quyền trong VPC endpoint policy.\nTrở lại home directory của bạn trên EC2 instance cd~ Tạo file fallocate -l 1G test-bucket2.xyz Sao chép file lên bucket thứ 2 aws s3 cp test-bucket2.xyz s3://\u0026lt;your-2nd-bucket-name\u0026gt; Thao tác này được cho phép bởi VPC endpoint policy.\nSau đó chúng ta kiểm tra truy cập vào S3 bucket đầu tiên\naws s3 cp test-bucket2.xyz s3://\u0026lt;your-1st-bucket-name\u0026gt;\nCâu lệnh xảy ra lỗi bởi vì bucket không có quyền truy cập bởi VPC endpoint policy.\nTrong phần này, bạn đã tạo chính sách VPC Endpoint cho Amazon S3 và sử dụng AWS CLI để kiểm tra chính sách. Các hoạt động AWS CLI liên quan đến bucket S3 ban đầu của bạn thất bại vì bạn áp dụng một chính sách chỉ cho phép truy cập đến bucket thứ hai mà bạn đã tạo. Các hoạt động AWS CLI nhắm vào bucket thứ hai của bạn thành công vì chính sách cho phép chúng. Những chính sách này có thể hữu ích trong các tình huống khi bạn cần kiểm soát quyền truy cập vào tài nguyên thông qua VPC Endpoint.\n"
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nĐảm bảo truy cập Hybrid an toàn đến S3 bằng cách sử dụng VPC endpoint Tổng quan AWS PrivateLink cung cấp kết nối riêng tư đến các dịch vụ aws từ VPCs hoặc trung tâm dữ liệu (on-premise) mà không làm lộ lưu lượng truy cập ra ngoài public internet.\nTrong bài lab này, chúng ta sẽ học cách tạo, cấu hình, và kiểm tra VPC endpoints để cho phép workload của bạn tiếp cận các dịch vụ AWS mà không cần đi qua Internet công cộng.\nChúng ta sẽ tạo hai loại endpoints để truy cập đến Amazon S3: gateway vpc endpoint và interface vpc endpoint. Hai loại vpc endpoints này mang đến nhiều lợi ích tùy thuộc vào việc bạn truy cập đến S3 từ môi trường cloud hay từ trung tâm dữ liệu (on-premise).\nGateway - Tạo gateway endpoint để gửi lưu lượng đến Amazon S3 hoặc DynamoDB using private IP addresses. Bạn điều hướng lưu lượng từ VPC của bạn đến gateway endpoint bằng các bảng định tuyến (route tables) Interface - Tạo interface endpoint để gửi lưu lượng đến các dịch vụ điểm cuối (endpoints) sử dụng Network Load Balancer để phân phối lưu lượng. Lưu lượng dành cho dịch vụ điểm cuối được resolved bằng DNS. Nội dung Tổng quan về workshop Chuẩn bị Truy cập đến S3 từ VPC Truy cập đến S3 từ TTDL On-premises VPC Endpoint Policies (làm thêm) Dọn dẹp tài nguyên "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/5-workshop/5.6-cleanup/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Dọn dẹp tài nguyên Xin chúc mừng bạn đã hoàn thành xong lab này! Trong lab này, bạn đã học về các mô hình kiến trúc để truy cập Amazon S3 mà không sử dụng Public Internet.\nBằng cách tạo Gateway endpoint, bạn đã cho phép giao tiếp trực tiếp giữa các tài nguyên EC2 và Amazon S3, mà không đi qua Internet Gateway. Bằng cách tạo Interface endpoint, bạn đã mở rộng kết nối S3 đến các tài nguyên chạy trên trung tâm dữ liệu trên chỗ của bạn thông qua AWS Site-to-Site VPN hoặc Direct Connect. Dọn dẹp Điều hướng đến Hosted Zones trên phía trái của bảng điều khiển Route 53. Nhấp vào tên của s3.us-east-1.amazonaws.com zone. Nhấp vào Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo;. Disassociate Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. 4.Mở console của CloudFormation và xóa hai stack CloudFormation mà bạn đã tạo cho bài thực hành này:\nPLOnpremSetup PLCloudSetup Xóa các S3 bucket Mở bảng điều khiển S3 Chọn bucket chúng ta đã tạo cho lab, nhấp chuột và xác nhận là empty. Nhấp Delete và xác nhận delete. "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTrong suốt thời gian thực tập tại [Tên công ty/tổ chức] từ [ngày bắt đầu] đến [ngày kết thúc], tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia [mô tả ngắn gọn dự án hoặc công việc chính], qua đó cải thiện kỹ năng [liệt kê kỹ năng: lập trình, phân tích, viết báo cáo, giao tiếp…].\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ☐ ✅ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao tính kỹ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ trong một tổ chức nào Cải thiện trong cách tư duy giải quyết vấn đề Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại đây bạn có thể tự do đóng góp ý kiến cá nhân về những trải nghiệm khi tham gia chương trình First Cloud Journey, giúp team FCJ cải thiện những vấn đề còn thiếu sót dựa trên các hạng mục sau:\nĐánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình nghĩ có thể bổ sung thêm một số buổi giao lưu hoặc team bonding để mọi người hiểu nhau hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập? Bạn có muốn tiếp tục chương trình này trong tương lai? Góp ý khác (tự do chia sẻ): "
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://tai-isme.github.io/workshop-template/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]